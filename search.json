[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Biostatistics",
    "section": "",
    "text": "This book is meant to accompany biostatistics courses I teach at Baruch College and the CUNY Graduate Center, but it may offer another perspective to anyone trying to learn statistics, R, or some combination. The class now includes\n\na website housing slides and associated material\n\nthis was the original “home” for the material, and it is being updated to point here\n\ntutorials for many lessons using Swirl\nthis book!\n\nAll of these resources may prove useful in learning the material.\nI say another perspective because an immediate question should be why the world needs another self-published statistics book, especially one focused on introducing R. There are already many, many good ones (some of which are shared at the end of each of relevant chapter and in the list of additonal resources).To this I offer a few responses\n\nAs already noted, this book was designed to accompany courses I teach. Having the material presented in the same order, but with additional context, should help students learn the material.\nThe courses I teach focus on introducing statistics from a biological perspective, so examples, papers, and problems focus on natural systems when possible. Having examples, including from published papers, that introduce the need and use of various tests should aid in helping students learn\n\nwhy various tests exist\nhow they relate to each other\nwhen one should be used as opposed to another\nhow to defend the choices you made or evaluate those of others!",
    "crumbs": [
      "Getting started",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Biostatistics",
    "section": "",
    "text": "This book is meant to accompany biostatistics courses I teach at Baruch College and the CUNY Graduate Center, but it may offer another perspective to anyone trying to learn statistics, R, or some combination. The class now includes\n\na website housing slides and associated material\n\nthis was the original “home” for the material, and it is being updated to point here\n\ntutorials for many lessons using Swirl\nthis book!\n\nAll of these resources may prove useful in learning the material.\nI say another perspective because an immediate question should be why the world needs another self-published statistics book, especially one focused on introducing R. There are already many, many good ones (some of which are shared at the end of each of relevant chapter and in the list of additonal resources).To this I offer a few responses\n\nAs already noted, this book was designed to accompany courses I teach. Having the material presented in the same order, but with additional context, should help students learn the material.\nThe courses I teach focus on introducing statistics from a biological perspective, so examples, papers, and problems focus on natural systems when possible. Having examples, including from published papers, that introduce the need and use of various tests should aid in helping students learn\n\nwhy various tests exist\nhow they relate to each other\nwhen one should be used as opposed to another\nhow to defend the choices you made or evaluate those of others!",
    "crumbs": [
      "Getting started",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#here-there-be-monsters-but-also-opportunities",
    "href": "index.html#here-there-be-monsters-but-also-opportunities",
    "title": "Biostatistics",
    "section": "Here there be monsters, but also opportunities!",
    "text": "Here there be monsters, but also opportunities!\nStatistics is a complex field that is unfortunately often stuffed into the curriculum of other majors (see above). However, my goal is to teach the concepts while also giving students the tools to actually address questions. Given these goals,\n\nwe’ll learn how to use tools and applications including R (through Rstudio), git, and markdown. If this is your first time using any (or all) of these tools, don’t worry. We will start at the very beginning.\n\nThere are many, many ways to do any task in R. I will show you one (sometimes two) for a given concept, but note you may find other approaches online or in other material\nI typically use verbose coding (more words and lines, but easier to read and understand). I know much of what we do could be done in fewer steps, but speed is commonly less of an issue than readability (which is connected to responsibility) for our fields\n\nGiven our focus on concepts, we will not dwell on the proofs or other mathematical components of statistics. I’m happy to point you towards texts to help with those, or discuss them.\nWe will use easy examples to illustrate concepts and applications (toy datasets), which make it easier for you to update in the future (real data are often messy!) while also connecting our class to real-life papers and ideas as much as possible\n\n\n\n\n\n\n\nFigure 1: Old maps rarely stated “Here there be monsters”, but mythical animals did appear on maps! Public domain.\n\n\n\nBe warned: You may encounter some questions as we introduce new material. For example, we’ll talk about normality before fully explaining it. We’ll also use code (to make figures, for example) before you understand it. Feel free to ask questions, but you can also be sure we’ll cycle back (and expand) on many topics. I’ll also add asides/tangents throughout the book to help answer some common questions that pop up.\nHopefully this will open the door to careers in data science (a related term) and statistics to some students who haven’t considered that path before. Jobs in these fields are some of the fastest growing in the country, and the skills you learn in this class, including\n\nCritical thinking\nCoding\n\nR\nmarkdown\ngit\n\nData wrangling\nVisualization and stats\nWriting and communication\n\nwill be some of the most transferable you acquire as an undergraduate.\n\n\n\n\n\n\nFigure 2: Chart from Occupational Outlook Handbook showing fastest growing occupations and median pay. Data from 9.8.22. Screenshot taken 7.26.23.\n\n\n\nI hope you find the book useful and learn to see statistics as more than something you do to finish a project or a course that you are required to take. The book is written in quarto, a derivative/extension of rmarkdown, which allows R code and prose to be easily created and published together. You can see the code for all the material on github, and you will learn early on how to make a copy of the material that you can work on yourself.",
    "crumbs": [
      "Getting started",
      "Welcome"
    ]
  },
  {
    "objectID": "content/swirl_lessons.html",
    "href": "content/swirl_lessons.html",
    "title": "Swirl lessons",
    "section": "",
    "text": "Swirl is a program/package that can help teach you R at your own pace. There are many swirl lessons that are freely available (most of which I have not tried!). Given that, you are free to explore them, but I have developed a set to follow our class (with support of a QUBES working group). To work with them, you’ll need to\n\ninstall swirl\n\nYou can use the Install Packages option in Rstudio or type the following into your console (or copy and paste it)!\n\n\n\ninstall.packages(\"swirl\")\n\n\nload the package and install the lessons for the book\n\nThis will install swirl, load the package, and load the lessons.\n\n\n\nlibrary(swirl)\ninstall_course_github(\"jsgosnell\", \"JSG_swirl_lessons\")\n\n\nstart swirl\n\n\nswirl()\n\n\nFollow the on-screen prompts to select the CUNY_swirl course and the lesson you want to focus on. Lesson names match the chapter names. Note not all chapters have a matching swirl lesson!\n\nOccasionally I update the lessons. If you want the latest version, you’ll need to uninstall the course\n\nuninstall_course(\"JSG_swirl_lessons\")\n\nand then reinstall it following the original instructions.",
    "crumbs": [
      "swirl lessons",
      "swirl lessons"
    ]
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#overview",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#overview",
    "title": "Relationships among numerical variables",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Relationships among numerical variabless lecuture.",
    "crumbs": [
      "Solutions",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#example",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#example",
    "title": "Relationships among numerical variables",
    "section": "Example",
    "text": "Example\nFollowing the iris dataset from class\n\nlibrary(ggplot2)\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(size = 3) +\n  ylab(\"Sepal Length\")+ggtitle(\"Sepal length increases with petal length\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+\n  xlab(\"Petal length (cm)\") +\n  ylab(\"Sepal length (cm)\")\n\n\n\n\n\n\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\npar(mfrow = c(2,2))\nplot(iris_regression)\n\n\n\n\n\n\n\nlibrary(car)\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\ncor.test(~ Sepal.Length + Petal.Length, data = iris,\n         method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\n\nbootstrap_iris &lt;- Boot(iris_regression)\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate     2.5 %    97.5 %\n(Intercept)  4.3066034 4.1659555 4.4644969\nPetal.Length 0.4089223 0.3680317 0.4456184",
    "crumbs": [
      "Solutions",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#practice",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#practice",
    "title": "Relationships among numerical variables",
    "section": "Practice",
    "text": "Practice\n\n1\n\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at\n\nhttp://www.statsci.org/data/oz/ms212.txt\nWith more info at\nhttp://www.statsci.org/data/oz/ms212.html.\nIs there evidence that age, height, or weight impact change in pulse rate for students who ran (Ran column = 1)? For each of these, how much variation in pulse rate do they explain?\n\npulse &lt;- read.table(\"http://www.statsci.org/data/oz/ms212.txt\", header = T, stringsAsFactors = T)\npulse$change &lt;- pulse$Pulse2 - pulse$Pulse1\n#need to make columns entered as numeral change to factor, although it doesn't \n#really matter when only 2 groups (why?)\npulse$Exercise &lt;-as.factor(pulse$Exercise)\npulse$Gender &lt;- as.factor(pulse$Gender)\n\n#age\nexercise &lt;- lm(change ~ Age, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\n\n\n\n\nrequire(car)\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)  3882.7  1  8.6317 0.005242 **\nAge           222.7  1  0.4950 0.485395   \nResiduals   19792.3 44                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Age, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.512 -12.183   2.591  12.893  44.868 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  67.3759    22.9328   2.938  0.00524 **\nAge          -0.7932     1.1274  -0.704  0.48539   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.21 on 44 degrees of freedom\nMultiple R-squared:  0.01113,   Adjusted R-squared:  -0.01135 \nF-statistic: 0.495 on 1 and 44 DF,  p-value: 0.4854\n\n\nFirst we need to make a column that shows change in pulse rate. We also should change Exercise and gender to factors.\nFor age we note the model meets assumptions (no patterns in residuals and residuals follow a normal distribution). We also find no evidence that age impacts change (F1,44 = .4950, p = 0.49). We fail to reject our null hypothesis that there is no relationship between age and change in pulse rate. We also note that age only explains 1.1% of the variation in change in pulse rate (likely due to chance!).\n\n#weight\nexercise &lt;- lm(change ~ Weight, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\n\n\n\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)  3588.9  1  7.9618 0.007143 **\nWeight        181.5  1  0.4027 0.528990   \nResiduals   19833.4 44                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Weight, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.173 -17.343   1.967  13.503  42.760 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  42.1276    14.9300   2.822  0.00714 **\nWeight        0.1381     0.2176   0.635  0.52899   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.23 on 44 degrees of freedom\nMultiple R-squared:  0.009069,  Adjusted R-squared:  -0.01345 \nF-statistic: 0.4027 on 1 and 44 DF,  p-value: 0.529\n\n\nFor weight we note the model meets assumptions. We also find no evidence that weight impacts change (F1,44 = .4027, p = 0.53). We fail to reject our null hypothesis that there is no relationship between weight and change in pulse rate. We also note that weight only explains 1% of the variation in change in pulse rate (likely due to chance!).\n\n#height\nexercise &lt;- lm(change ~ Height, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\n\n\n\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value Pr(&gt;F)\n(Intercept)   243.9  1  0.5503 0.4621\nHeight        511.4  1  1.1536 0.2886\nResiduals   19503.6 44               \n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Height, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.798 -17.012   1.848  12.177  43.861 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  21.0688    28.4017   0.742    0.462\nHeight        0.1773     0.1650   1.074    0.289\n\nResidual standard error: 21.05 on 44 degrees of freedom\nMultiple R-squared:  0.02555,   Adjusted R-squared:  0.003402 \nF-statistic: 1.154 on 1 and 44 DF,  p-value: 0.2886\n\n\nFor height we note the model meets assumptions. We also find no evidence that weight impacts change (F1,44 = 1.15, p = 0.29). We fail to reject our null hypothesis that there is no relationship between height and change in pulse rate. We also note that age only explains 2.5% of the variation in change in pulse rate (likely due to chance!).\n\n\n2\n\n(from OZDASL repository, http://www.statsci.org/data/general/stature.html; reference for more information)\n\nWhen anthropologists analyze human skeletal remains, an important piece of information is living stature. Since skeletons are commonly based on statistical methods that utilize measurements on small bones. The following data was presented in a paper in the American Journal of Physical Anthropology to validate one such method. Data is available @\nhttp://www.statsci.org/data/general/stature.txt\nas a tab-delimted file (need to use read.table!) Is there evidence that metacarpal bone length is a good predictor of stature? If so, how much variation does it account for in the response variable?\n\nheight &lt;- read.table(\"http://www.statsci.org/data/general/stature.txt\", \n                     header = T, stringsAsFactors = T)\nhead(height)\n\n  MetaCarp Stature\n1       45     171\n2       51     178\n3       39     157\n4       41     163\n5       48     172\n6       49     183\n\nmetacarp_relationship &lt;- lm(Stature ~ MetaCarp, height)\nplot(metacarp_relationship)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(metacarp_relationship, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Stature\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept) 515.73  1  28.491 0.001078 **\nMetaCarp    347.29  1  19.186 0.003234 **\nResiduals   126.71  7                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(metacarp_relationship)\n\n\nCall:\nlm(formula = Stature ~ MetaCarp, data = height)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0102 -3.1091 -1.1128  0.3891  7.4880 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   94.428     17.691   5.338  0.00108 **\nMetaCarp       1.700      0.388   4.380  0.00323 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.255 on 7 degrees of freedom\nMultiple R-squared:  0.7327,    Adjusted R-squared:  0.6945 \nF-statistic: 19.19 on 1 and 7 DF,  p-value: 0.003234\n\n\nTo consider the relationship among these continuous variables, we used linear regression. Analysis of model assumptions suggest assumptions are met, although the dataset is small. Analysis suggests there is a significant positive relationship between metacarpal length and stature (F1,7 = 19.19, p = 0.003). The R2 value indicates that metacarpal length explains 73% of the variation in stature. Coefficients indicate that stature increases with increasing metacarpal length.\n\n\n3\n\nData on medals won by various countries in the 1992 and 1994 Olympics is available in a tab-delimited file at\n\nhttp://www.statsci.org/data/oz/medals.txt\nMore information on the data can be found at:\nhttp://www.statsci.org/data/oz/medals.html\nIs there any relationship between a country’s population and the total number of medals they win?\n\nmedals &lt;- read.table(header = T, \"http://www.statsci.org/data/oz/medals.txt\", \n                     stringsAsFactors = T)\nhead(medals)\n\n       Country Summer Winter Population Latitude\n1  UnifiedTeam    112     34      231.5       61\n2 UnitesStates    108     13      260.7       38\n3      Germany     82     24       81.1       51\n4        China     54      3     1190.4       36\n5         Cuba     31      0       11.1       22\n6      Hungary     30      0       10.3       46\n\nmedals$total &lt;- medals$Summer + medals$Winter\npopulation_medals &lt;- lm(total ~ Population, medals)\nplot(population_medals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(population_medals)\n\n\nCall:\nlm(formula = total ~ Population, data = medals)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.470 -12.303  -9.525   4.379 118.141 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 12.01849    3.51123   3.423  0.00112 **\nPopulation   0.06842    0.02117   3.233  0.00199 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.8 on 60 degrees of freedom\nMultiple R-squared:  0.1483,    Adjusted R-squared:  0.1341 \nF-statistic: 10.45 on 1 and 60 DF,  p-value: 0.001994\n\nAnova(population_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: total\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)   7799  1  11.716 0.001122 **\nPopulation    6957  1  10.450 0.001994 **\nResiduals    39942 60                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncor.test(~total + Population, medals, method = \"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  total and Population\nS = 29456, p-value = 0.04271\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2582412 \n\n\nThere is a high leverage point in the dataset (row 4), but residuals appear to be fairly normally distributed and little structure exists in the graph of Residuals vs. Fitted Values. Analysis using linear regression suggests a significant ( F1,60 = 10.45, p = 0.002) positive relationship between population size and medal count that explains ~15% of the variation in the response variable. Rank- correlation analysis also indicated this relationship exists.\n\n\n4\n\nContinuing with the Olympic data, is there a relationship between the latitude of a country and the number of medals won in summer or winter Olympics?\n\n\n#still using medals\nsummer_medals &lt;- lm(Summer ~ Latitude, medals)\nplot(summer_medals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(summer_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Summer\n             Sum Sq Df F value  Pr(&gt;F)  \n(Intercept)     3.6  1  0.0075 0.93143  \nLatitude     2440.3  1  5.0389 0.02848 *\nResiduals   29057.2 60                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(summer_medals)\n\n\nCall:\nlm(formula = Summer ~ Latitude, data = medals)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.707 -10.856  -4.922   0.352  93.827 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   0.5403     6.2531   0.086   0.9314  \nLatitude      0.3588     0.1598   2.245   0.0285 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.01 on 60 degrees of freedom\nMultiple R-squared:  0.07747,   Adjusted R-squared:  0.0621 \nF-statistic: 5.039 on 1 and 60 DF,  p-value: 0.02848\n\nwinter_medals &lt;- lm(Winter ~ Latitude, medals)\nplot(winter_medals)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(winter_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Winter\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   90.07  1  2.2353 0.1401300    \nLatitude     502.29  1 12.4652 0.0008035 ***\nResiduals   2417.71 60                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(winter_medals)\n\n\nCall:\nlm(formula = Winter ~ Latitude, data = medals)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.906 -3.773 -1.383  1.395 26.768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.6967     1.8037  -1.495 0.140130    \nLatitude      0.1628     0.0461   3.531 0.000803 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.348 on 60 degrees of freedom\nMultiple R-squared:  0.172, Adjusted R-squared:  0.1582 \nF-statistic: 12.47 on 1 and 60 DF,  p-value: 0.0008035\n\n\nVisual analysis of residuals from both models show some structure in the residual and deviations from normality, but we continue on with linear regression given the small sample size. Both summer and winter medal counts are positively (surpisingly) and significantly (both p &lt;.05) related to latitude, with latitude explaining ~17% of the variation in winter medal count and ~8% of the data in summer medal count.\n\n\n5\n\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\n\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on age or height? If so, how do these factors impact FEV, and how much variance does each explain?\n\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T, \n                  stringsAsFactors = T)\nhead(fev)\n\n    ID Age   FEV Height    Sex Smoker\n1  301   9 1.708   57.0 Female    Non\n2  451   8 1.724   67.5 Female    Non\n3  501   7 1.720   54.5 Female    Non\n4  642   9 1.558   53.0   Male    Non\n5  901   9 1.895   57.0   Male    Non\n6 1701   8 2.336   61.0 Female    Non\n\nfev_height &lt;- lm(FEV ~ Height, fev)\nplot(fev_height)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_height, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 166.25   1  896.33 &lt; 2.2e-16 ***\nHeight      369.99   1 1994.73 &lt; 2.2e-16 ***\nResiduals   120.93 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_height)\n\n\nCall:\nlm(formula = FEV ~ Height, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.75167 -0.26619 -0.00401  0.24474  2.11936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -5.432679   0.181460  -29.94   &lt;2e-16 ***\nHeight       0.131976   0.002955   44.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4307 on 652 degrees of freedom\nMultiple R-squared:  0.7537,    Adjusted R-squared:  0.7533 \nF-statistic:  1995 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n\nModel assumptions appear to be met. Height appears to have a positive relationship with FEV (F1,652 = 1995, p&lt;.001).\n\nfev_age &lt;- lm(FEV ~ Age, fev)\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)   9.89   1  30.707 4.359e-08 ***\nAge         280.92   1 872.184 &lt; 2.2e-16 ***\nResiduals   210.00 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.57539 -0.34567 -0.04989  0.32124  2.12786 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.431648   0.077895   5.541 4.36e-08 ***\nAge         0.222041   0.007518  29.533  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5675 on 652 degrees of freedom\nMultiple R-squared:  0.5722,    Adjusted R-squared:  0.5716 \nF-statistic: 872.2 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n\nModel assumptions appear to be met. Age appears to have a positive relationship with FEV (F1,652 = 872.2, p&lt;.001).\n\n\n6\n\nContinuing with the FEV data, produce plots that illustrate how height, age, and gender each impact FEV.\n\n\nlibrary(ggplot2)\n#age plot####\nggplot(fev, aes(x=Age, y=FEV)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  ylab(\"FEV (L)\")+ggtitle(\"FEV increases with age\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#height plot####\nggplot(fev, aes(x=Height, y=FEV)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  ylab(\"FEV (L)\")+ggtitle(\"FEV increases with height\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n#gender plot ####\n\n#bar chart with error bars ####\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(fev, measurevar=\"FEV\", groupvars =\n                               c(\"Sex\"))\n\nggplot(function_output, aes(x=Sex, y=FEV)) +\n  geom_col(size = 3) +\n  ylab(\"FEV (L)\") +\n  ggtitle(\"FEV is higher in males \")+\n  geom_errorbar(aes(ymin=FEV-ci, ymax=FEV+ci), size=1.5) +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.",
    "crumbs": [
      "Solutions",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html",
    "href": "content/solutions/6_Compare_means_solutions.html",
    "title": "Compare means among groups",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#overview",
    "href": "content/solutions/6_Compare_means_solutions.html#overview",
    "title": "Compare means among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture.",
    "crumbs": [
      "Solutions",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#examples",
    "href": "content/solutions/6_Compare_means_solutions.html#examples",
    "title": "Compare means among groups",
    "section": "Examples",
    "text": "Examples\nWe will run ANOVA’s using the lm function to connect them to other test. First, build the model\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nThen use the object it created to test assumptions\n\npar(mfrow = c(2,2))\nplot(iris_anova)\n\n\n\n\n\n\n\n\nIf assumptions are met, check the p-value using the summary or Anova function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\nAnova(iris_anova, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the overall test is significant, carry out post hoc tests (Tukey shown here for all pairs, as most common)\n\nlibrary(multcomp)\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nIf assumptions are not met, we can use the Kruskal Wallis non-parametric test and associated post hoc tests.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\nor a bootstrap alternative\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\nFor 2 groups, the boot.t.test function in the MKinfer package is also an option.",
    "crumbs": [
      "Solutions",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#just-for-practice",
    "href": "content/solutions/6_Compare_means_solutions.html#just-for-practice",
    "title": "Compare means among groups",
    "section": "Just for practice",
    "text": "Just for practice\n\n1\nUse the iris dataset in R to determine if petal length differs among species. Do this problems using ANOVA, Kruskal-Wallis, and bootstrapping methods. Make sure you can plot the data and carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n#plot\nlibrary(Rmisc)\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Petal.Length\", groupvars =\n                               c(\"Species\"))\nlibrary(ggplot2)\nggplot(function_output, aes(x=Species, y=Petal.Length)) +\n  geom_col(aes(fill=Species), size = 3) +\n  geom_errorbar(aes(ymin=Petal.Length-ci, ymax=Petal.Length+ci), size=1.5) +\n  ylab(\"Petal Length (cm)\")+ggtitle(\"Petal Length of \\n various iris species\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\npetal &lt;- lm(Petal.Length ~ Species, iris)\nplot(petal)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(petal, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Petal.Length\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 106.87   1   577.1 &lt; 2.2e-16 ***\nSpecies     437.10   2  1180.2 &lt; 2.2e-16 ***\nResiduals    27.22 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#compare to\nsummary(petal)\n\n\nCall:\nlm(formula = Petal.Length ~ Species, data = iris)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.260 -0.258  0.038  0.240  1.348 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        1.46200    0.06086   24.02   &lt;2e-16 ***\nSpeciesversicolor  2.79800    0.08607   32.51   &lt;2e-16 ***\nSpeciesvirginica   4.09000    0.08607   47.52   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4303 on 147 degrees of freedom\nMultiple R-squared:  0.9414,    Adjusted R-squared:  0.9406 \nF-statistic:  1180 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(multcomp)\ncomp_cholest &lt;- glht(petal, linfct = mcp(Species = \"Tukey\"))\nsummary(comp_cholest)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Petal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0     2.79800    0.08607   32.51   &lt;2e-16 ***\nvirginica - setosa == 0      4.09000    0.08607   47.52   &lt;2e-16 ***\nvirginica - versicolor == 0  1.29200    0.08607   15.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n#kw approach\npetal &lt;- kruskal.test(Petal.Length ~ Species, iris)\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n#bootstrap\nlibrary(WRS2)\nt1waybt(Petal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Petal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 1510.684 \np-value: 0 \nVariance explained: 0.71 \nEffect size: 0.843 \n\nbootstrap_post_hoc &lt;- mcppb20(Petal.Length~Species, iris)\n#use p.adjust to correct for FWER\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\n*Answer: We used an ANOVA (a special case of linear models) to investigate how a numerical response variable differed among 3 groups. This was appropriate as evidenced by the residual plots (there is no pattern in the residuals and they are normally distributed), but other methods are demonstrated as well.\nUsing an ANOVA, we found F2,147= 1180.2, which led to a p-value of &lt;.001. Given this, I reject the null hypothesis there is no difference among mean measurements for each species.\nPost-hoc testing indicated all species significantly differed from all others (all p &lt;.05) using a Tukey approach to control for family-wise error rate. Kruskal-Wallis and bootstrapping approaches led to similar conclusions.*\n\n\n2\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv.\nAnalyze this data using the t.test function and the lm function to convince yourself that t-tests are special cases of ANOVAs, which are special cases of linear models!\n\nfertilizer &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv\",\n                       stringsAsFactors = T)\n#note use of var.equal!  assumption of ANOVAs\nt.test(height ~ fertilizer, fertilizer, var.equal = T)\n\n\n    Two Sample t-test\n\ndata:  height by fertilizer\nt = 2.9884, df = 16, p-value = 0.008686\nalternative hypothesis: true difference in means between group new and group old is not equal to 0\n95 percent confidence interval:\n 1.34853 7.93147\nsample estimates:\nmean in group new mean in group old \n            56.55             51.91 \n\nfert_lm &lt;- lm(height ~ fertilizer, fertilizer)\nplot(fert_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(fert_lm)\n\n\nCall:\nlm(formula = height ~ fertilizer, data = fertilizer)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.25  -2.61  -0.21   2.38   6.39 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     56.550      1.157  48.865  &lt; 2e-16 ***\nfertilizerold   -4.640      1.553  -2.988  0.00869 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.273 on 16 degrees of freedom\nMultiple R-squared:  0.3582,    Adjusted R-squared:  0.3181 \nF-statistic: 8.931 on 1 and 16 DF,  p-value: 0.008686\n\nrequire(car)\nAnova(fert_lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: height\n             Sum Sq Df   F value    Pr(&gt;F)    \n(Intercept) 25583.2  1 2387.7612 &lt; 2.2e-16 ***\nfertilizer     95.7  1    8.9308  0.008686 ** \nResiduals     171.4 16                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnswer: t-tests and ANOVA (lm) approaches yield the same results. Note for the tests to match exactly we have to assume equal variances among groups for the t-tests. In both we reject the null hypothesis of no difference among mean height of plants based on fertilizer. Notice the t statistic (2.9884) is the square root of the F statistic (8.931). The t distribution corresponds to the F with only 1 df in the numerator (so its not listed!).",
    "crumbs": [
      "Solutions",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "href": "content/solutions/6_Compare_means_solutions.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "title": "Compare means among groups",
    "section": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.",
    "text": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n3\nData on sugar cane yield for multiple fields is available using\nread.table(“https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv”, header = T, stringsAsFactors = T)\nMore info on the data can be found at http://www.statsci.org/data/oz/cane.html. Is there evidence that location (DistrictPosition column) impacts yield (Tonn.Hect column)? If so, which areas are driving this distance?\n\ncane &lt;- read.table(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv\", header = T, stringsAsFactors = T)\nsummary(cane)\n\n           District                     DistrictGroup  DistrictPosition\n WrightsCreek  : 389   BahanaSouth             : 498   C: 498          \n Highleigh     : 360   Cairns/Mulgrave(dry)    :1517   E: 482          \n PineCreek     : 317   Cairns/Mulgrave(Med-wet): 842   N: 452          \n LittleMulgrave: 308   MulgravetoBahana        : 466   S: 553          \n Aloomba       : 284   NorthCairns             : 452   W:1790          \n Hambledon     : 267                                                   \n (Other)       :1850                                                   \n     SoilID           SoilName         Area           Variety        Ratoon   \n Min.   :442.0   Liverpool: 737   Min.   : 0.020   138    :629   1R     :767  \n 1st Qu.:712.0   Mission  : 399   1st Qu.: 0.880   120    :598   2R     :760  \n Median :801.0   Innisfail: 330   Median : 1.940   152    :513   3R     :692  \n Mean   :757.5   Virgil   : 272   Mean   : 2.578   124    :466   4R     :493  \n 3rd Qu.:816.0   Thorpe   : 237   3rd Qu.: 3.620   113    :358   PL     :360  \n Max.   :838.0   Edmonton : 220   Max.   :38.270   117    :319   RP     :304  \n                 (Other)  :1580                    (Other):892   (Other):399  \n      Age         HarvestMonth  HarvestDuration     Tonn.Hect      \n Min.   :0.000   Min.   : 6.0   Min.   :  0.000   Min.   :   1.45  \n 1st Qu.:1.000   1st Qu.: 7.0   1st Qu.:  0.000   1st Qu.:  75.54  \n Median :2.000   Median : 9.0   Median :  1.000   Median : 173.46  \n Mean   :2.151   Mean   : 8.6   Mean   :  9.175   Mean   : 240.11  \n 3rd Qu.:3.000   3rd Qu.:10.0   3rd Qu.:  3.000   3rd Qu.: 336.40  \n Max.   :8.000   Max.   :11.0   Max.   :155.000   Max.   :1954.01  \n                                                                   \n     Fibre           Sugar           Jul.96          Aug.96      \n Min.   :14.20   Min.   : 6.08   Min.   :  0.0   Min.   : 2.200  \n 1st Qu.:15.38   1st Qu.:10.93   1st Qu.: 42.2   1st Qu.: 4.500  \n Median :15.80   Median :11.84   Median : 46.0   Median : 7.100  \n Mean   :15.87   Mean   :11.82   Mean   : 50.9   Mean   : 9.274  \n 3rd Qu.:16.25   3rd Qu.:12.73   3rd Qu.: 61.0   3rd Qu.: 9.900  \n Max.   :19.10   Max.   :17.36   Max.   :141.5   Max.   :36.000  \n                                                                 \n     Sep.96           Oct.96          Nov.96           Dec.96     \n Min.   : 0.000   Min.   :137.5   Min.   :  6.00   Min.   :128.5  \n 1st Qu.: 0.000   1st Qu.:181.8   1st Qu.: 17.60   1st Qu.:161.9  \n Median : 5.000   Median :224.8   Median : 31.00   Median :239.5  \n Mean   : 5.932   Mean   :219.8   Mean   : 40.39   Mean   :223.6  \n 3rd Qu.:11.200   3rd Qu.:240.3   3rd Qu.: 39.50   3rd Qu.:241.4  \n Max.   :14.000   Max.   :308.0   Max.   :100.60   Max.   :353.5  \n                                                                  \n     Jan.97          Feb.97          Mar.97          Apr.97     \n Min.   :287.5   Min.   :275.8   Min.   :326.0   Min.   :  0.0  \n 1st Qu.:321.8   1st Qu.:284.0   1st Qu.:326.0   1st Qu.: 49.3  \n Median :443.8   Median :386.6   Median :426.0   Median : 87.8  \n Mean   :455.2   Mean   :419.6   Mean   :415.1   Mean   :105.0  \n 3rd Qu.:508.8   3rd Qu.:495.6   3rd Qu.:480.5   3rd Qu.:176.0  \n Max.   :746.5   Max.   :677.5   Max.   :494.3   Max.   :217.5  \n                                                                \n     May.97           Jun.97           Jul.97           Aug.97      \n Min.   : 30.00   Min.   : 34.20   Min.   :  8.60   Min.   : 18.80  \n 1st Qu.: 44.60   1st Qu.: 40.20   1st Qu.: 16.40   1st Qu.: 39.20  \n Median : 63.50   Median : 41.00   Median : 24.00   Median : 68.00  \n Mean   : 89.99   Mean   : 82.62   Mean   : 31.65   Mean   : 70.47  \n 3rd Qu.: 72.60   3rd Qu.:113.80   3rd Qu.: 28.00   3rd Qu.:112.50  \n Max.   :220.00   Max.   :202.00   Max.   :109.00   Max.   :117.50  \n                                                                    \n     Sep.97           Oct.97           Nov.97          Dec.97     \n Min.   :  4.00   Min.   :  2.00   Min.   : 13.5   Min.   : 75.0  \n 1st Qu.: 42.80   1st Qu.: 22.20   1st Qu.: 62.0   1st Qu.:223.0  \n Median : 73.00   Median : 38.10   Median :123.7   Median :278.3  \n Mean   : 70.46   Mean   : 55.53   Mean   :114.3   Mean   :264.4  \n 3rd Qu.:106.00   3rd Qu.: 53.10   3rd Qu.:167.4   3rd Qu.:315.2  \n Max.   :109.20   Max.   :216.50   Max.   :198.0   Max.   :336.6  \n                                                                  \n\ncane_summary &lt;- summarySE(cane, measurevar=\"Tonn.Hect\", groupvars =\n                               c(\"DistrictPosition\"))\n\nggplot(cane_summary, aes(x=DistrictPosition, y=Tonn.Hect)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=Tonn.Hect-ci, ymax=Tonn.Hect+ci), size=1.5) +\n  ylab(\"Production (tonnes per hectare)\") +\n  xlab(\"District Position\") +\n  ggtitle(\"Production differs \\n among locations\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\n\n\n\nimpact_district &lt;- lm(Tonn.Hect ~ DistrictPosition, cane)\nsummary(impact_district)\n\n\nCall:\nlm(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-274.41 -159.66  -66.07   90.26 1754.55 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        242.418      9.993  24.259  &lt; 2e-16 ***\nDistrictPositionE   39.360     14.249   2.762  0.00577 ** \nDistrictPositionN   20.252     14.487   1.398  0.16222    \nDistrictPositionS  -42.955     13.777  -3.118  0.00183 ** \nDistrictPositionW   -7.317     11.298  -0.648  0.51727    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 223 on 3770 degrees of freedom\nMultiple R-squared:  0.0107,    Adjusted R-squared:  0.009652 \nF-statistic:  10.2 on 4 and 3770 DF,  p-value: 3.293e-08\n\nplot(impact_district)#not really normal...lets bootstrap\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrequire(WRS2)\nt1waybt(Tonn.Hect ~ DistrictPosition, cane)\n\nCall:\nt1waybt(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 16.5244 \np-value: 0 \nVariance explained: 0.031 \nEffect size: 0.177 \n\nmcppb20(Tonn.Hect ~ DistrictPosition, cane)\n\nCall:\nmcppb20(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\n           psihat  ci.lower  ci.upper p-value\nS vs. N -56.10126 -94.68921 -19.95174 0.00000\nS vs. E -12.51609 -52.43587  22.15568 0.36060\nS vs. W  39.25821   6.76996  71.71667 0.00000\nS vs. C  -0.97532 -29.40651  27.49520 0.92154\nN vs. E  43.58517   0.71357  80.58648 0.00334\nN vs. W  95.35948  65.12886 128.57460 0.00000\nN vs. C  55.12595  24.21179  86.86894 0.00000\nE vs. W  51.77430  23.93670  84.05836 0.00000\nE vs. C  11.54077 -14.10380  45.11236 0.25042\nW vs. C -40.23353 -59.97274 -14.47447 0.00000\n\np &lt;- mcppb20(Tonn.Hect ~ DistrictPosition, cane)\np.adjust(as.numeric(p$comp[,6]), \"holm\")\n\n [1] 0.0000000 0.8714524 0.0000000 0.8948247 0.0000000 0.0000000 0.0000000\n [8] 0.0000000 0.8714524 0.0000000\n\n#compare to lm apporach\nrequire(car)\nAnova(impact_district, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Tonn.Hect\n                    Sum Sq   Df F value    Pr(&gt;F)    \n(Intercept)       29265733    1 588.476 &lt; 2.2e-16 ***\nDistrictPosition   2028140    4  10.195 3.293e-08 ***\nResiduals        187487281 3770                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nrequire(multcomp)\ncomp_district &lt;- glht(impact_district, linfct = mcp(DistrictPosition = \"Tukey\"))\nsummary(comp_district)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nLinear Hypotheses:\n           Estimate Std. Error t value Pr(&gt;|t|)    \nE - C == 0   39.360     14.249   2.762  0.04406 *  \nN - C == 0   20.252     14.487   1.398  0.62080    \nS - C == 0  -42.955     13.777  -3.118  0.01525 *  \nW - C == 0   -7.317     11.298  -0.648  0.96582    \nN - E == 0  -19.108     14.601  -1.309  0.67822    \nS - E == 0  -82.315     13.896  -5.924  &lt; 0.001 ***\nW - E == 0  -46.677     11.444  -4.079  &lt; 0.001 ***\nS - N == 0  -63.207     14.141  -4.470  &lt; 0.001 ***\nW - N == 0  -27.569     11.739  -2.348  0.12599    \nW - S == 0   35.638     10.850   3.285  0.00894 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nAnswer: For this analysis I used a bootstrap approach as the residual plots suggested a non-normal distribution. Analysis revealed a test statistics of 16.52 and p-value of 0, so I reject the null hypothesis of no difference among Districts. since I rejected the null hypothesis, I have to use post-hoc tsts to determine which groups are different than the others.\nPost-hoc tests reveal all district areas differ from each other except for south and east, south and central, and east and central (using sequential FDR to control for family-wise error rate.)\nNote that a linear model does lead to slightly different findings regarding which districts differ from which others.\n\n\n4\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on gender? If so, which gender has the higher FEV score? How much variance does gender explain?\n\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T,\n                  stringsAsFactors = T)\nfev_summary &lt;- summarySE(fev, measurevar=\"FEV\", groupvars =\n                               c(\"Sex\"))\n\nggplot(fev_summary, aes(x=Sex, y=FEV)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=FEV-ci, ymax=FEV+ci), size=1.5) +\n  ylab(\"FEV (liters)\") +\n  xlab(\"Sex\") +\n  ggtitle(\"FEV differs \\n among males and females\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\n\n\n\nfev_gender &lt;- lm(FEV ~ Sex, fev)\nplot(fev_gender) #anova is fine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_gender, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n             Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 1910.62   1 2652.756 &lt; 2.2e-16 ***\nSex           21.32   1   29.607 7.496e-08 ***\nResiduals    469.60 652                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_gender)\n\n\nCall:\nlm(formula = FEV ~ Sex, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01645 -0.69420 -0.06367  0.58233  2.98055 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.45117    0.04759  51.505  &lt; 2e-16 ***\nSexMale      0.36128    0.06640   5.441  7.5e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8487 on 652 degrees of freedom\nMultiple R-squared:  0.04344,   Adjusted R-squared:  0.04197 \nF-statistic: 29.61 on 1 and 652 DF,  p-value: 7.496e-08\n\n\nI used an ANOVA (or linear model, or t-test, here, all the same since 2 groups!) to consider the impact of sex on FEV. This was appropriate as evidenced by the residual plots (there is no pattern in the residuals and they are normally distributed). Results indicate there is a difference among sexes (F1,652 = 29.607, p&lt;.001). There is no need for post-hoc tests here since there are only 2 groups being considered.\nCoefficients related to the groups (note female is replaced by intercept here, and the SexMale coefficient is relative to that) indicates that males have a higher FEV on average. Graphs also show this relationship.\n\n\n5\nThe following data are human blood clotting times (in minutes) of individuals given one of two different drugs.\n\n\n\nDrug B\nDrug G\n\n\n\n\n8.8\n9.9\n\n\n8.4\n9.0\n\n\n7.9\n11.1\n\n\n8.7\n9.6\n\n\n9.1\n8.7\n\n\n9.6\n10.4\n\n\n\n9.5\n\n\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\n\n\ndrug_b &lt;- c( 8.8, 8.4, 7.9, 8.7, 9.1, 9.6)\ndrug_g &lt;- c(9.9, 9.0, 11.1, 9.6, 8.7, 10.4, 9.5)\nt.test(drug_b, drug_g)\n\n\n    Welch Two Sample t-test\n\ndata:  drug_b and drug_g\nt = -2.5454, df = 10.701, p-value = 0.02774\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.8543048 -0.1314095\nsample estimates:\nmean of x mean of y \n 8.750000  9.742857 \n\n\nUsing a un-paired t-test, since the experimental units were not matched and I assumed the means of each group would follow a normal distribution of unknown variance, I found a test statistics of t10.701=-2.544. This corresponds to a p-value of 0.02. This p-value is &lt;.05, so I reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing rank transform analysis\n\n\nwilcox.test(drug_b, drug_g)\n\nWarning in wilcox.test.default(drug_b, drug_g): cannot compute exact p-value\nwith ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  drug_b and drug_g\nW = 7, p-value = 0.05313\nalternative hypothesis: true location shift is not equal to 0\n\n\nUsing a un-paired rank-based test, which is appropriate when normality assumptions can’t be met and I assumed the means of each group would follow a similar distribution, I found a test statistics of W=7. This corresponds to a p-value of 0.05. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing a permutation test\n\n\nrequire(coin) #requires data_frame\nclotting &lt;- data.frame(drug = c(rep(\"drug_b\", length(drug_b)), rep(\"drug_g\", \n                                                                   length(drug_g))),\n                       clotting = c(drug_b, drug_g))\nclotting$drug &lt;- factor(clotting$drug)\nindependence_test(clotting ~ drug, clotting)\n\n\n    Asymptotic General Independence Test\n\ndata:  clotting by drug (drug_b, drug_g)\nZ = -2.0726, p-value = 0.03821\nalternative hypothesis: two.sided\n\n\nUsing a permutation test, which is not fully appropriate here due to small sample sizes (and that also assumes similar distributions for each group), I found a test statistics of Z=-2.0726.. This corresponds to a p-value of 0.038. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing a bootstrap test\n\n\nlibrary(MKinfer)\nboot.t.test(drug_b, drug_g)\n\n\n    Bootstrap Welch Two Sample t-test\n\ndata:  drug_b and drug_g\nbootstrap p-value = 0.0192 \nbootstrap difference of means (SE) = -0.9969795 (0.3532994) \n95 percent bootstrap percentile confidence interval:\n -1.7072619 -0.3141667\n\nResults without bootstrap:\nt = -2.5454, df = 10.701, p-value = 0.02774\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.8543048 -0.1314095\nsample estimates:\nmean of x mean of y \n 8.750000  9.742857 \n\n\nUsing a bootstrap test with 10000 samples, which is not fully appropriate here due to small sample sizes, I found a p value of 0.0047. This p-value is &lt;.05, so I reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\n\n6\n(Example from Handbook on Biological Statistics) Odd (stunted, short, new) feathers were compared in color to typical feathers in Northern Flickers (Colaptes auratus) (Wiebe and Bortolotti 2002) . Data is at\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\nTest the hypothesis that odd and typical feathers did not differ using\n\na Student’s t test and/or lm\na rank test\nbootstrapping\n\nNote we will return to this question next week!\n\na Student’s t test\n\n\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nt.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  Color_index by Feather\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean difference \n      -0.137125 \n\n\n*I used a paired t-test because feathers were measured on the same bird.\nI also assumed the difference in means was normally distributed given the trait and sample size. The test resulted in a statistic of t15 = -4.06. This corresponds to a p-value of .001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers. Note this equivalent too:\n\nlibrary(car)\nAnova(lm(Color_index ~ Feather+Bird, data=feather))\n\nAnova Table (Type II tests)\n\nResponse: Color_index\n           Sum Sq Df F value   Pr(&gt;F)   \nFeather   0.15043  1 16.5214 0.001017 **\nBird      0.21950 15  1.6072 0.184180   \nResiduals 0.13657 15                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\na rank test\n\n\nwilcox.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  Color_index by Feather\nV = 10, p-value = 0.001312\nalternative hypothesis: true location shift is not equal to 0\n\n\nI used a paired rank-based test because feathers were measured on the same bird. I did not assume the difference in means was normally distributed but did assume it followed a symmetric distribution. The test resulted in a statistic of V = 10. This corresponds to a p-value of .001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers.\n\na binary test\n\n\nlibrary(BSDA)\nSIGN.test(feather[feather$Feather == \"Odd\", \"Color_index\"], \n          feather[feather$Feather == \"Typical\", \"Color_index\"])\n\n\n    Dependent-samples Sign-Test\n\ndata:  feather[feather$Feather == \"Odd\", \"Color_index\"] and feather[feather$Feather == \"Typical\", \"Color_index\"]\nS = 3, p-value = 0.02127\nalternative hypothesis: true median difference is not equal to 0\n95 percent confidence interval:\n -0.24048275 -0.02331055\nsample estimates:\nmedian of x-y \n       -0.114 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level  L.E.pt  U.E.pt\nLower Achieved CI     0.9232 -0.2400 -0.0320\nInterpolated CI       0.9500 -0.2405 -0.0233\nUpper Achieved CI     0.9787 -0.2410 -0.0140\n\n\nI used a sign test (always paired!) because feathers were measured on the same bird. I did not assume the difference in means was normally distributed or that the differences followed a symmetric distribution. The test resulted in a statistic of s = 3. This corresponds to a p-value of .02. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers.\n\nbootstrapping\n\n\nlibrary(MKinfer)\nboot.t.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Bootstrap Paired t-test\n\ndata:  Color_index by Feather\nbootstrap p-value = 0.0008001 \nbootstrap mean of the differences (SE) = -0.1366545 (0.03236595) \n95 percent bootstrap percentile confidence interval:\n -0.20318750 -0.07437188\n\nResults without bootstrap:\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean of the differences \n              -0.137125 \n\n\nSince feathers were measured on the same bird. I used a bootstrap (10,000 samples) focused on the difference in color. This resulted in a p-value of &lt;.001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers.",
    "crumbs": [
      "Solutions",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html",
    "title": "4. Continuous tests for 1 population",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#overview",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#overview",
    "title": "4. Continuous tests for 1 population",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Tests for continuous data from one sample lecture.",
    "crumbs": [
      "Solutions",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#examples",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#examples",
    "title": "4. Continuous tests for 1 population",
    "section": "Examples",
    "text": "Examples\nFrom lecture! Consider if average height of males training at the Australian Institute of Sport is different than average of human population.\nThese are all one sample tests, but they differ in what we know. If we know the variance of our population, we use a z test (function in BSDA package).\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T)\nlibrary(BSDA)\nz.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6, sigma.x=7)\n\n\n    One-sample z-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nz = 14.292, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 184.1474 186.8643\nsample estimates:\nmean of x \n 185.5059 \n\n\nIf we don’t, we use a t-test\n\nt.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059 \n\n\nThese both assume the means of the data are normal! If we want to relax that assumption, we can use the Wilcoxon test (also known as Mann-Whitney test, signed binary transform, or other terms!). This assumes the distribution of means is symmetric.\n\nwilcox.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nV = 5052, p-value = 5.714e-16\nalternative hypothesis: true location is not equal to 175.6\n\n\nor the sign-test/media test.\n\nSIGN.test(sport[sport$Sex == \"male\", \"Ht\"], md = 175.6)\n\n\n    One-sample Sign-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\ns = 90, p-value = 8.882e-16\nalternative hypothesis: true median is not equal to 175.6\n95 percent confidence interval:\n 183.9000 187.4684\nsample estimates:\nmedian of x \n     185.55 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.9406  183.9 187.3000\nInterpolated CI       0.9500  183.9 187.4684\nUpper Achieved CI     0.9629  183.9 187.7000\n\n\nNote this is just transforming data to 1/0 and doing a binomial test!\n\nabove_175.6 &lt;- nrow(sport[sport$Sex == \"male\" & sport$Ht &gt; 175.6,])\nbinom.test(above_175.6, nrow(sport[sport$Sex == \"male\",]))\n\n\n    Exact binomial test\n\ndata:  above_175.6 and nrow(sport[sport$Sex == \"male\", ])\nnumber of successes = 90, number of trials = 102, p-value = 6.125e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.8035103 0.9377091\nsample estimates:\nprobability of success \n             0.8823529 \n\n\nWe can also bootstrap the data.\n\nnumber_of_simulations &lt;- 1000\nlibrary(ggplot2)\nboostrap_data&lt;- sport[sport$Sex == \"male\", \"Ht\"]\nboostrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\niris_bootstrap &lt;-sample(boostrap_data, length(boostrap_data), replace = T)\nboostrap_outcomes$mean[i] &lt;- mean(iris_bootstrap)\nboostrap_outcomes$sd[i] &lt;- sd(iris_bootstrap)\n}\nggplot(boostrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nand find associated quantile-based 95% confidence intervals:\n\nquantile(boostrap_outcomes$mean, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n184.0071 187.0617 \n\n\nor using functions in the boot library\n\nlibrary(boot)\nresults &lt;- boot(data=boostrap_data, statistic = function(x, inds) mean(x[inds]),\n   R=number_of_simulations)\nggplot(data.frame(results$t), aes(x=results.t)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nquantile( results$t, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n183.9903 187.0679 \n\nboot.ci(results)       \n\nWarning in boot.ci(results): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic         \n95%   (184.0, 187.0 )   (183.9, 187.1 )  \n\nLevel     Percentile            BCa          \n95%   (184.0, 187.1 )   (183.9, 187.0 )  \nCalculations and Intervals on Original Scale\n\n\nAnother option (recommended) is the boot.t.test function in the MKinfer package.\n\nlibrary(MKinfer)\nboot.t.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Bootstrap One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nbootstrap p-value &lt; 2.2e-16 \nbootstrap mean of x (SE) = 185.508 (0.7757956) \n95 percent bootstrap percentile confidence interval:\n 183.9804 187.0186\n\nResults without bootstrap:\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059",
    "crumbs": [
      "Solutions",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#lets-practice",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#lets-practice",
    "title": "4. Continuous tests for 1 population",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nRecognizing and assessing normality\n\n1\nUsing the qqplot_example.R code, examine the following distributions and, for the continuous distributions (marked with a “*”), observe how a normal probability plot (qqplot) can be used to visually test for approximate normality.\n\n*Normal (u= 0; σ2= 1, 10, 100)\n*Student’s t (df = 1, 10, 30, & 100)\n*Chi-square (df= 1, 2, 5, 30, 50)\nBernoulli (P=0.1, 0.5, & 0.9)\nBinomial (P=0.05; N= 2, 5, 25, & 50); (P=0.25; N= 2, 5, 25, & 50); (P=0.50; N= 2, 5, 25, & 50); (P=0.75; N= 2, 5, 25, & 50); (P=0.95; N= 2, 5, 25, & 50)\nPoisson ( u= 2, 5, 10, 30, & 50)\n\nFor this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R”)\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R\")\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nNotice the spread of DATA of every distribution tend towards normality as sample size increases\n\n\n2\nReview the central_limit_theorem.R code if you need to convince/remind yourself how common normality of means is for even non-normal data. You can source the code using the same approach noted in Question 1.\nHere we are focused on how the means look as sample size increases\n\n#make sure you have VGAM library installed\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with data (note some sample sizes may be too small for these to all be good ideas!)\nMake sure you are comfortable with null and alternative hypotheses for all examples. You should also feel comfortable graphing the data.\n\n3\nSeven observers were shown, for a brief period, a grill with 161 flies impaled and were asked to estimate the number. The results are given by Cochran (1954). Based on five estimates, they were 183.2, 149.0, 154.0, 167.2, 187.2, 158.0, and 143.0. Test the null hypothesis that the mean of the estimates is 161 flies.\n\nAssuming variance = 275\n\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0)\nlibrary(BSDA)\nz.test(x=flies, mu = 161, sigma.x=sqrt(275))\n\n\n    One-sample z-Test\n\ndata:  flies\nz = 0.33276, p-value = 0.7393\nalternative hypothesis: true mean is not equal to 161\n95 percent confidence interval:\n 150.8010 175.3704\nsample estimates:\nmean of x \n 163.0857 \n\n\nUsing a z-test, I found a test statistics of z~=0.33 .This corresponds to a p-value of 0.73. This p value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nEstimating the variance from the data\n\n\nt.test(x=flies,mu = 161)\n\n\n    One Sample t-test\n\ndata:  flies\nt = 0.32656, df = 6, p-value = 0.7551\nalternative hypothesis: true mean is not equal to 161\n95 percent confidence interval:\n 147.4576 178.7138\nsample estimates:\nmean of x \n 163.0857 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t6=0.32. This corresponds to a p-value of 0.76. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nUsing rank transform analysis\n\n\nwilcox.test(flies, mu=161)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  flies\nV = 15, p-value = 0.9375\nalternative hypothesis: true location is not equal to 161\n\n\nUsing a Wilcoxon signed rank test, which is appropriate when normality assumptions can’t be met and the distribution of the data appears to be symmetric, I found a test statistics of V = 15 .This corresponds to a p-value of 0.94. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nUsing binary transform analysis\n\n\nSIGN.test(flies, md=161)\n\n\n    One-sample Sign-Test\n\ndata:  flies\ns = 3, p-value = 1\nalternative hypothesis: true median is not equal to 161\n95 percent confidence interval:\n 144.8857 185.9429\nsample estimates:\nmedian of x \n        158 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level   L.E.pt   U.E.pt\nLower Achieved CI     0.8750 149.0000 183.2000\nInterpolated CI       0.9500 144.8857 185.9429\nUpper Achieved CI     0.9844 143.0000 187.2000\n\n\nUsing a sign test, which is appropriate when the data is continuous and other assumptions can’t be met, I found a test statistics of s = 3 .This corresponds to a p-value of 1. This p-value is &gt;.05, so I fail to reject the null hypothesis that the median (Note change here) of the estimates is 161 flies.\nNote there are several ways to load the data! You can make a list (since the list is short):\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0 )\n\nor make a dataframe in a spreadsheet software (eg, Excel, Google Sheets) and then upload using a read.csv command. We did this in the introduction to R!\n\n\n4\nYields of 10 strawberry plants in a uniformity trial are given by Baker and Baker (1953) as 239, 176, 235, 217, 234, 216, 318, 190, 181, and 225 g. Test the hypothesis that µ = 205 * Assuming variance = 1500\n\nstrawberries &lt;- c(239, 176, 235, 217, 234, 216, 318, 190, 181, 225)\nz.test(x=strawberries,mu = 205, sigma.x=sqrt(1500))\n\n\n    One-sample z-Test\n\ndata:  strawberries\nz = 1.4779, p-value = 0.1394\nalternative hypothesis: true mean is not equal to 205\n95 percent confidence interval:\n 199.0954 247.1046\nsample estimates:\nmean of x \n    223.1 \n\n\nUsing a z-test, I found a test statistics of z=1.48. This corresponds to a p-value of 0.14. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nEstimating the variance from the data\n\n\nt.test(x=strawberries,mu = 205)\n\n\n    One Sample t-test\n\ndata:  strawberries\nt = 1.4164, df = 9, p-value = 0.1903\nalternative hypothesis: true mean is not equal to 205\n95 percent confidence interval:\n 194.1922 252.0078\nsample estimates:\nmean of x \n    223.1 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t9=1.42. This corresponds to a p-value of 0.19. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nUsing rank transform analysis\n\n\nwilcox.test(strawberries, mu=205)\n\nWarning in wilcox.test.default(strawberries, mu = 205): cannot compute exact\np-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  strawberries\nV = 40.5, p-value = 0.2023\nalternative hypothesis: true location is not equal to 205\n\n\nUsing a Wilcoxon signed rank test, which is appropriate when normality assumptions can’t be met and the distribution of the data appears to be symmetric, I found a test statistics of V=40.5. This corresponds to a p-value of 0.20. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nUsing binary transform analysis\n\n\nSIGN.test(strawberries, md=205)\n\n\n    One-sample Sign-Test\n\ndata:  strawberries\ns = 7, p-value = 0.3437\nalternative hypothesis: true median is not equal to 205\n95 percent confidence interval:\n 183.9200 237.7022\nsample estimates:\nmedian of x \n        221 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.8906 190.00 235.0000\nInterpolated CI       0.9500 183.92 237.7022\nUpper Achieved CI     0.9785 181.00 239.0000\n\n\nUsing a sign test, which is appropriate when the data is continuous and other assumptions can’t be met, I found a test statistics of s= 7. This corresponds to a p-value of 0.34. This p-value is &gt;.05,so I fail to reject the null hypothesis that the population median (Note change here) is equal to 205.\n\n\n5\nEvolutionary geneticists predicts the family sex ratio will be 80% female in broods of eagles that successfully fledge &gt;3 young. Nests that fledge 3 or more chicks are very rare but a sample of 30 chicks are obtained from such nests and they yield 25 females and 5 males. Test the hypotheses that that: * a) the sex ratio is 50% females\n\n#a\nbinom.test(25,30, p=.5)\n\n\n    Exact binomial test\n\ndata:  25 and 30\nnumber of successes = 25, number of trials = 30, p-value = 0.0003249\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6527883 0.9435783\nsample estimates:\nprobability of success \n             0.8333333 \n\n\nA binomial test was used as we are comparing an observed proportion against a set value. Given a p-value of &lt;.001, I reject the null hypothesis that the proportion of sons is equal to .5.\n\n\nthe sex ratio is 80% females.\n\n\n\nbinom.test(25,30, .8)\n\n\n    Exact binomial test\n\ndata:  25 and 30\nnumber of successes = 25, number of trials = 30, p-value = 0.8205\nalternative hypothesis: true probability of success is not equal to 0.8\n95 percent confidence interval:\n 0.6527883 0.9435783\nsample estimates:\nprobability of success \n             0.8333333 \n\n\nA binomial test was used as we are comparing an observed proportion against a set value. Given a p-value of &lt;.001, I fail to reject the null hypothesis that the proportion of sons is equal to .8.\n\n\n6\nStudies of flying snakes have led researchers to posit the mean undulation rate is 1.4 Hz. You wish to test this hypothesis using the small sample of undulation rates shown below. Create a small dataset of the paradise tree snake undulation rates and choose and justify a test you can use to assess the data.\nUndulation rates (in Hz): 0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6\n\nsnakes &lt;- c(0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6)\nt.test(snakes, mu=1.4)\n\n\n    One Sample t-test\n\ndata:  snakes\nt = -0.21822, df = 7, p-value = 0.8335\nalternative hypothesis: true mean is not equal to 1.4\n95 percent confidence interval:\n 1.104098 1.645902\nsample estimates:\nmean of x \n    1.375 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t7=-.22. This corresponds to a p-value of 0.83. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean undulation rate is 1.4 Hz.\n\n\n7\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques. Data at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)\n\n\nlibrary(MKinfer)\nboot.t.test(sport[sport$Sex == \"male\", \"Wt\"], mu= 85.9)\n\n\n    Bootstrap One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Wt\"]\nbootstrap p-value = 0.008801 \nbootstrap mean of x (SE) = 82.53494 (1.219815) \n95 percent bootstrap percentile confidence interval:\n 80.09049 84.93775\n\nResults without bootstrap:\nt = -2.7487, df = 101, p-value = 0.007089\nalternative hypothesis: true mean is not equal to 85.9\n95 percent confidence interval:\n 80.08671 84.96035\nsample estimates:\nmean of x \n 82.52353 \n\n\nUsing a bootstrap test wtih 10,000 samples, we found a p-value of .007; we thus reject the null hypothesis that males training at the AIS have the same weight as the average Australian male. Data indicated they weigh less.",
    "crumbs": [
      "Solutions",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html",
    "title": "Estimation and ggplot2",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#overview",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#overview",
    "title": "Estimation and ggplot2",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Estimation lecture and the use of ggplots (lots of ggplot2 example code in the Summarizing data lecture\n\nggplot2 basics\nggplot2 is a great plotting package that allows a lot of control over your output. Let’s do some examples using the sleep dataset that we left off with last week. Load the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nggplot2 works in layers so you can or subtract as needed. Provided code is verbose here so you can see what its doing. First, install and call the package.\n\nlibrary(ggplot2)\n\nTo make a plot, first set a base layer using the ggplot function.\n\ndreaming_sleep_relationship &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming))\n\nHere we are naming a dataframe to use (first argument), then noting which columns to use for the x and y axis (under the aes argument, stands for aesthetics).\nNote when we do this we get a blank graph (if we name the ggplot output, we have to call it to see it!)\n\ndreaming_sleep_relationship\n\n\n\n\n\n\n\n\nNext we add data layers using geom_ commands. Let’s start with a scatter plot, which we make using the geom_point command.\n\ndreaming_sleep_relationship_scatter &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming)) + \n  geom_point()\n\nAgain, nothing is shown, but not the object is saved! We can call it\n\ndreaming_sleep_relationship_scatter\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe can also just call it directly, but when/if we do this the object is not saved in the environment.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point()\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf nothing extra is given, the geom_commands inherit everything from the ggplot command. So here we get a scatter plot of the relationship between TotalSleep and Dreaming. Note the axis labels are the column titles, which may not be what we want in the end in regards to readability.\nHowever, now you have a basic plot. You can also use other arguments in geom_layer commands to add to it. For example, let’s color these by primate\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Primate))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNow we’ve added information on primates. Since that require us to get more data from the dataset, we had to add another aes argument. Note this is different from (not evaluated in code, as it causes an error!)\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"Primate\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nError in `geom_point()`:\n! Problem while converting geom to grob.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! Unknown colour name: Primate\n\n\nand this\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"blue\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe first causes an error as primate isn’t a color. The second makes all points blue! Also note the 2nd method loses the legend as color now conveys no information.\nIn general, you have to put things you want to plot in the aes argument area and anything outside of that changes the entire plot. For example, we can change the size of all points using\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(size = 4)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis is also a good time to talk about renaming factor labels. You may want to change Primate levels to Yes and No for your graph. Lots of ways to do this, but the revalue function in the plyr package is nice (and we’ll use this suite of packages often, same person developed ggplot2, plyr, and reshape)\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\n\nNotice what I did above. I made a new column from an existing one using a name I might want on a legend. Now I can use it in a graph.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nI can also just change the legend title directly or change legend text, but often workign with the dataframe is easier for me.\nIf we wanted the levels of Primate in a different order, we can use the relevel function in the plyr package to set one as the “first” level (and then do this sequentially to get them in the right order if needed). You can also change level orders using the factor or ordered functions for multiple levels at once.\n\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\" )\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nFinally, we can use the theme or related functions (like xlab, ylab, ggtitle) to change how the graph looks. Note, all the code here is verbose so you can change as needed, but you rarely need all this.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou can also directly change legend title and colours with the scale_ commands\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn general scale_[whatever you had aes commands]_manual lets you set colors or codes. To see color codes go to this chart\nYou can also facet a graph by another column. For example, I can split the graph I already made by Taxa\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\")) +\n  facet_wrap(~Taxa, ncol = 1)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNotice doing this and having legend may be redundant, so I can remove the legend\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\")) +\n  facet_wrap(~Taxa, ncol = 1) +\n  guides(colour=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nI also added a theme section to change the facet label. All this shows how you are focused on adding or layering levels in ggplot2.\nYou can save the most recent plot directly to your working directory using\n\nggsave(\"Fig1.jpg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nThis is useful when we need to send just an image to someone (or add it to a document). You can also just save using rstudio functionality.\nggplot2 is a great example of needing to undertand basic functionality without having to remember everything. The intro class lecture and accompanying code should help you get started. A few other points that often come up are noted below.\n\n\nHistograms\nFor histograms, you only need one axis (frequency is calculated automatically)\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nNote we can just copy our theme info from above and modify as needed (or ggplot2 will largely skip un-needed info). You can also save and name a theme so you don’t have to do all this everytime.\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nFinally, remember you can subset the dataframes you feed to the ggplot functions (or any other function for that matter). For example, let’s just do a histogram of just primate sleep.\n\nggplot(sleep[sleep$Taxa == \"Primate\",], aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nNot interesting, but you get the idea.\n\n\nBarcharts and confidence intervals\nEstimating is a key part of statistics and should include the value you are estimating and an estimate of uncertainty. Graphs typically show this using confidence intervals, which rely on samples of means following a normal distribution that we can describe. If we assume the estimate (not the data!) is normally distributed, we can assume things about uncertainty. Namely, we can build a 95% confidence interval around our estimate (meaning the true mean is in the range 95 out of 100 times we create a sample).\nNow’s let do these in R. Confidence intervals are often tied to barcharts. Although these are common in practice, they are not easy by default in R as statisticians don’t love them. That’s because they use a lot of wasted color. I’ll show this in a moments. However, since they are common I’ll show you how to build them.\nLet’s go back to the sleep dataset and consider the average total sleep time speed for each exposure level. First, lets change exposure to factors and label them\n\nstr(sleep) #just a reminder\n\n'data.frame':   62 obs. of  13 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n $ Taxa       : Factor w/ 2 levels \"Primate\",\"Non-primate\": 2 2 2 2 2 2 2 2 2 1 ...\n\nsleep$Exposure &lt;- factor(sleep$Exposure)\n\nCheck levels\n\nlevels(sleep$Exposure)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nand relabel if you want (just for example here)\n\nlevels(sleep$Exposure)&lt;- c(\"Least\",\"Less\", \"Average\", \"More\", \"Most\") \n\nNext, we need to get the average and standard deviation for each group (remember this is tied to the normal distribution!). If we wanted to this by hand, we could do something like thi (let’s just focus on least for an example, and note we have to remove NA data)\n\nmean(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T)\n\n[1] 12.94615\n\n\nThis is our estimate. The standard deviation of this estimate is\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(sleep[sleep$Exposure == \"Least\" & is.na(sleep$TotalSleep) == F, \"TotalSleep\"]))\n\n[1] 0.7833111\n\n\nwhich is equivalent to\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(na.omit(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"])))\n\n[1] 0.7833111\n\n\nWe also call this the standard error of the mean.\nFortunately, we can also do this using a function from the Rmisc package in R, as ggplot2 doesn’t have it built in (maybe because bar charts are a bad idea?).\n\nlibrary(Rmisc)\nsleep_by_exposure &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Exposure\", na.rm = T)\n\nInspect the table\n\nsleep_by_exposure\n\n  Exposure  N TotalSleep       sd        se       ci\n1    Least 26   12.94615 3.994119 0.7833111 1.613259\n2     Less 13   11.11538 3.957029 1.0974823 2.391209\n3  Average  4    8.57500 1.808084 0.9040419 2.877065\n4     More  5   10.72000 1.663430 0.7439086 2.065421\n5     Most 10    4.19000 1.776670 0.5618323 1.270953\n\n\nNow we can use this summarized data to make a graph that shows uncertainty (95% confidence intervals)\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nNow to show why barplots waste ink. Note we can show the same information with\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\n\n\n\n\nAll the exta color is nice, but its not really adding anything!",
    "crumbs": [
      "Solutions",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#lets-practice",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#lets-practice",
    "title": "Estimation and ggplot2",
    "section": "Let’s practice!",
    "text": "Let’s practice!\nLet’s return to the mammal sleep dataset that we left off with last week (Make sure you did the first assignment!).\nLoad the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nLast time you used the built-in plot functions to do some plots. Let’s replace those with ggplot2 and do some more.\n\n1\n\nFirst plot how TotalSleep is explained by BrainWt (remember the issues with the data). Use ggplot2 to plot the relationship.\n\n\nlibrary(ggplot2)\nggplot(sleep[sleep$BrainWt &lt;1000, ], aes(x=BrainWt, y = TotalSleep)) +\n  geom_point(size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent \\n sleeping daily\") +\n  xlab(\"Brain weight (g)\") +\n  ggtitle(\"Time spent sleeping \\n decreases with brain \\n weight\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n2\n\nNext color code each plot point by whether or not its a primate. In order to do this you can use the Primate column or (following class code) make a new column called Taxa to represent the information (hint:search for ” revalue”). Make sure axes are well-labeled.\n\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\")\n\nggplot(sleep[sleep$BrainWt &lt;1000, ], aes(x=BrainWt, y = TotalSleep)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent \\n sleeping daily\") +\n  xlab(\"Brain weight (g)\") +\n  ggtitle(\"Time spent sleeping \\n decreases with brain \\n weight\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n\n\n3\n\nLet’s work with histograms.\n\n\nWhat type of variation do we see in total time spent sleeping? Create a histogram to explore this issue.\n\n\nggplot(sleep\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\nFacet the graph you created based on whether or not the animal is a primate (Primate column).\n\n\nggplot(sleep\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+ \n  facet_wrap(~Taxa)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\n\nNow only graph the data for primates.\n\n\nggplot(sleep[sleep$Taxa == \"Primate\",]\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n4\n\nDevelop a properly-labeled bar graph with error bars to explore how total sleep changes with\n\n\nPrimate (relabeled as yes/no as Primate/Non-Primate; note there are multiple ways to do this!) – use a 95% confidence interval for the bar\n\n\n#use summarySE function from Rmisc package\nsleep$Primate &lt;- revalue(sleep$Primate, c(Y = \"Yes\", N = \"No\"))\nsleep$Primate &lt;- relevel(sleep$Primate, \"No\")\nlibrary(Rmisc)\nsleep_by_primate &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Primate\", na.rm = T)\n#look at it\nsleep_by_primate\n\n  Primate  N TotalSleep       sd        se       ci\n1      No 51   10.44510 4.810335 0.6735817 1.352929\n2     Yes  7   11.17143 2.870955 1.0851189 2.655190\n\nlibrary(ggplot2)\nggplot(sleep_by_primate\n       , aes(x=Primate, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep \\n (hours per day\")+ \n  xlab(\"Primate?\")+ \n  ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32)) \n\n\n\n\n\n\n\n\n\nPredation risk (as a factor!) – use 1 standard error for the bar. Note the difference!\n\n\nsleep$Predation &lt;- as.factor(sleep$Predation)\nsleep_by_predation &lt;- summarySE(sleep, measurevar = \"TotalSleep\", \n                                groupvars = \"Predation\", na.rm = T)\n#look at it\nsleep_by_predation\n\n  Predation  N TotalSleep       sd       se       ci\n1         1 14  12.050000 4.602299 1.230016 2.657288\n2         2 15  12.720000 3.931957 1.015227 2.177445\n3         3 10   9.120000 4.525680 1.431146 3.237476\n4         4  7  10.228571 2.437700 0.921364 2.254496\n5         5 12   7.383333 4.807727 1.387871 3.054684\n\nrequire(ggplot2)\nggplot(sleep_by_predation\n       , aes(x=Predation, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-se, ymax=TotalSleep+se), size=1.5) +\n  ylab(\"Total sleep \\n (hours per day)\") + \n  ggtitle(\"Sleep across different \\n predation levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))",
    "crumbs": [
      "Solutions",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#estimates-and-certainty-concepts",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#estimates-and-certainty-concepts",
    "title": "Estimation and ggplot2",
    "section": "Estimates and Certainty Concepts",
    "text": "Estimates and Certainty Concepts\n\n5\n\nWhat does a 95% confidence interval mean?\n\nA 95% confidence interval means the true population parameter value will be in the created interval 95% of the time we create it.\n\n\n6\n\nTo make sure you understand the ideas of sampling, confidence intervals, and the central limit theorem, review the visualizations produced by UBC:\n\n\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CLT.htm\n\nKey outcomes here are understanding that, regardless of the distribution of the data, the distribution of the means of the data (what we typically consider), will follow a normal distribution if the sample size is large enough.\n\n\n7\n\nFor this question you’ll need the central_limit_theorem.R script from the code_examples folder. Download it to your computer and open it. Alternatively, go ahead and make a copy of the CUNY-Biostats repository. You won’t have write access but can keep one up-to-date on your machine/cloud (pull occassionally!).\n\nOnce you get the script, open it in Rstudio (it will be in another tab!). Make sure you have the VGAM library installed (if you open the script n Rstudio, it will likely prompt you at the top). Then use the Source button (next to the Run command we’ve been using for lines or segments). Source runs the entire code at once (similar to knitting an Rmd file) without showing any console output, but graphs and objects are still produced!\nYou can also do this from the web (included here). When you knit the file, output will appear in your final file. However, its nice to know what Source does in general.\n\nlibrary(VGAM)\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nThis script follows the UBC tutorial to show you how well the CLT (central limit theorem) works (and how it functions). This will be useful in coming to understand when you can trust tests based on the normality of means. The script produces output (graphs) that allow you to examine 6 distributions that differ in shape (skewness and kurtosis) and how those traits interact with sample size to influence the normality of means.\nSource it (or look for the graphs produced in your knitted file) and and then review the plots and consider how sample size interacts with the shape of underlying distributions to influence how quickly sample means approach normality. The noted distributions are:\n\nNormal(Z) (0,1) {no Kurtosis / no skewness / no truncation}\nDouble exponential (0,2) {high Kurtosis / no skewness / no truncation}\nUniform(0,1) {moderate Kurtosis / no skewness / double truncation}\nExponential(1,1) {high asymmetric Kurtosis / high skewness / single truncation}\nChi-square(df=4) {low Kurtosis / moderate skewness / single truncation}\nBinomial distribution (p=.7) {discrete distribution]\n\nThis allows you to visualize what we noted in question 6 and begin to develop a sense for what “large sample size” and “odd distribution” really mean.",
    "crumbs": [
      "Solutions",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/solutions/12_Bayes_standalone_answers.html",
    "href": "content/solutions/12_Bayes_standalone_answers.html",
    "title": "All about the Bayes answers",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nMake sure you can describe the main differences between Frequentist, Likelihood, and Bayesian approaches.\n\n*Answer should focus on differences in perception of “data” and tests. Frequentists consider real world parameters to be absolute but focus on “noise” in our samples of it (sampling error) so that tests rely on infinite samples (p-value). Bayesians consider real world parameters probabilistically. They fit a distribution to what they think the world looks like (prior), collect data to consider how likely it would be if that were true, and focus on combining those to update their beliefs (posterior).\n\nReview the video we watched in class to make sure you understand the Bayesian connection. You can also read a related post @ https://brilliant.org/wiki/monty-hall-problem/.\n\n\nhttps://www.youtube.com/watch?v=mhlc7peGlGg\n\n\nI’ve shared a script in R that lets you test the Monty Hall idea (like in the video!). It’s the chivers_monty_hall_script from the code_examples foldercode_examples\non github. For this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/chivers_monty_hall_script.R”) , then test out the idea here using the following functions which calculate outcomes under each strategy.\n\n\nmonty(strat=“stay”, print_games=F)\nmonty(strat=“switch”, print_games=F)\nmonty(strat=“random”, print_games=F)\n\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/chivers_monty_hall_script.R\")\nmonty(strat=\"stay\", print_games=F)\nmonty(strat=\"switch\", print_games=F)\nmonty(strat=\"random\", print_games=F)\n\n\nSetup the Monty Hall problem as probabilities and convince yourself how it works. You may want to remember to think about prior and new information (likelihoods).\nRun the frog analysis (14/18 frogs are right-pawed) assuming an “uninformed” prior (is this really possible?) and priors that predict frogs are likely to be left- or right-handed (look under Bayesian analysis in script for functions such as triplot and qbeta). Vary both the relationship among the shape variables and the magnitude (weighting) to understand how the prior impacts your posterior.\n\n\nlibrary(LearnBayes)\n#even, uniform (uninformed) prior\ntriplot(prior = c(1,1), data = c(14,4), where = \"topleft\")\n#prior assumes left handed\ntriplot(prior = c(5,20), data = c(14,4), where = \"topleft\")\n#prior assumes right handed \ntriplot(prior = c(20,5), data = c(14,4), where = \"topleft\")\n#less sure right handed\ntriplot(prior = c(4,2), data = c(14,4), where = \"topleft\")\n\nThis is the “big picture” of Bayesian analysis. We combined our prior beliefs and data to update our beliefs (the posterior). We sample/describe the posterior for our answer. Everything else is “how do we do that?”.\n\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques and a Bayesian approach. For the Bayesian approach, compare approaches that give the null more and less weight.\n\nData at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)\n\nYou can source the bootstrapjsg function using\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/bootstrapjsg.R\")\n\nAnswer\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T)\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/bootstrapjsg.R\")\nbootstrapjsg(data1=sport[sport$Sex == \"male\", \"Wt\"], null=85.9)\n#to get estimates!\nsummary(sport[sport$Sex == \"male\",])\nhist(sport[sport$Sex == \"male\", \"Wt\"])\n\n\nlibrary(BayesFactor)\nttestBF(sport[sport$Sex == \"male\", \"Wt\"], mu=85.9)\nttestBF(sport[sport$Sex == \"male\", \"Wt\"], mu=85.9, rscale = \"ultrawide\")\n\nBoth answers give a Bayes Factor &gt;1, which is evidence against the null. However, support is fairly weak (2.12-3.8, largely anecdotal), and you can see the “ultrawide” option gives even more weight to the null.”\n\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\n\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/fertilizer.csv\nUse the data to test the hypothesis that there is no difference in mean plant heights for the two groups A) Using frequentist methods B) Using Bayesian approaches.\n\n#fertilizer####\nfertilizer &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/fertilizer.csv\")\n\nt.test(height ~ fertilizer, fertilizer)\nlibrary(BayesFactor)\nttestBF(formula = height ~ fertilizer, data = fertilizer)\n\nUsing a frequentist t-test (since the data focuses on a continuous response variable and differences among 2 groups), we find t15.559=3.013, p&lt;.01, so we reject the null hypothesis of no difference among groups. We can also we find a Bayes Factor &gt;1, which is substantial evidence against the null. However, support is not as strong as might expect given the very low p-value\n8.Develop a Bayesian model to determine if sepal width (from the iris dataset in R) differs among populations.\n\ncompare models that parameterize each population as different vs one that only examines difference between I. setosa and other species.\n\nmaking a new dummy variable is one way to do this!\n\n\n\n#ANOVA example####\n#with stan for all species\nlibrary(rstanarm)\nbayesian_iris_anova &lt;- stan_aov(Sepal.Width~Species, data = iris, \n                                prior = R2(what = \"median\", location = 0.5), adapt_delta = 0.9999)\n\n#check sampling outcomes####\nlaunch_shinystan(bayesian_iris_anova)\n\n#check model#### \n#check residuals for patterns\nrequire(ggplot2)\nresid = resid(bayesian_iris_anova)\nfit = fitted(bayesian_iris_anova)\nggplot() + geom_point(data = NULL, aes(y = resid, x = fit))\n\n#can also look at  posterior predictive checks in shinystan\n\n#does model predict observed data?\n#http://www.flutterbys.com.au/stats/tut/tut7.4b.html\ny_pred = posterior_predict(bayesian_iris_anova)\n#just getting all simulated outcomes into a column\nrequire(tidyr)\nnewdata = iris[,c(\"Sepal.Width\", \"Species\")] %&gt;% cbind(t(y_pred)) %&gt;% gather(key = \"Rep\", value = \"Sepal.Width\",\n                                                                              -\"Species\":-\"Sepal.Width\")\nrequire(ggplot2)\nggplot(newdata) + \n  geom_violin(aes(y = Sepal.Width, x = Species, fill = \"Model\"),\n              alpha = 0.5) + \n  geom_violin(data = iris, aes(y = Sepal.Width, x = Species,fill = \"Obs\"), alpha = 0.5) + \n  geom_point(data = iris, aes(y = Sepal.Width, x= Species), \n             position = position_jitter(width = 0.1, height = 0),\n             color = \"black\")\n\n\n#analyze posterior####\n#have to call certainty interval by dummy variable!\nsummary(bayesian_iris_anova)\n\nci95 &lt;- posterior_interval(bayesian_iris_anova, prob = 0.95, pars = \"Speciesversicolor\")\nround(ci95, 2)\nci95 &lt;- posterior_interval(bayesian_iris_anova, prob = 0.95, pars = \"Speciesvirginica\")\nround(ci95, 2)\nci95 &lt;- posterior_interval(bayesian_iris_anova, prob = 0.95, pars = \"(Intercept)\")\nround(ci95, 2)\n\n#make model with virginican and versicolor as same species####\n\niris$combined.species &lt;- iris$Species\nlevels(iris$combined.species) &lt;- c(\"setosa\", \"combined\", \"combined\")\nbayesian_iris_anova_combined &lt;- stan_aov(Sepal.Width~combined.species, data = iris, \n                                prior = R2(what = \"median\", location = 0.5), adapt_delta = 0.9999)\n\n#check sampling outcomes####\nlaunch_shinystan(bayesian_iris_anova_combined)\n\n#check model#### \n#check residuals for patterns\nresid = resid(bayesian_iris_anova_combined)\nfit = fitted(bayesian_iris_anova_combined)\nggplot() + geom_point(data = NULL, aes(y = resid, x = fit))\n\n#can also look at  posterior predictive checks in shinystan\n\n#does model predict observed data?\n#http://www.flutterbys.com.au/stats/tut/tut7.4b.html\ny_pred = posterior_predict(bayesian_iris_anova_combined)\n#just getting all simulated outcomes into a column\nnewdata = iris[,c(\"Sepal.Width\", \"combined.species\")] %&gt;% cbind(t(y_pred)) %&gt;% gather(key = \"Rep\", value = \"Sepal.Width\",\n                                                                             -\"combined.species\":-\"Sepal.Width\")\nggplot(newdata) + \n  geom_violin(aes(y = Sepal.Width, x = combined.species, fill = \"Model\"),\n              alpha = 0.5) + \n  geom_violin(data = iris, aes(y = Sepal.Width, x = combined.species,fill = \"Obs\"), alpha = 0.5) + \n  geom_point(data = iris, aes(y = Sepal.Width, x= combined.species), \n             position = position_jitter(width = 0.1, height = 0),\n             color = \"black\")\n\n\n#analyze posterior####\n#have to call certainty interval by dummy variable!\nsummary(bayesian_iris_anova_combined)\n\nci95 &lt;- posterior_interval(bayesian_iris_anova_combined, prob = 0.95, pars = \"combined.speciescombined\")\nround(ci95, 2)\n\nci95 &lt;- posterior_interval(bayesian_iris_anova, prob = 0.95, pars = \"(Intercept)\")\nround(ci95, 2)\n\n\n#compare models using loo\n#leave one out cross validation #not in lecture\nloo_bayesian_iris_anova &lt;- loo(bayesian_iris_anova)\nprint(loo_bayesian_iris_anova)\nloo_bayesian_iris_anova_combined &lt;- loo(bayesian_iris_anova_combined)\nprint(loo_bayesian_iris_anova_combined)\nloo_compare(loo_bayesian_iris_anova,loo_bayesian_iris_anova_combined)\n\n#or using an information criterion\nwaic_bayesian_iris_anova &lt;- waic(bayesian_iris_anova)\nprint(waic_bayesian_iris_anova)\nwaic_bayesian_iris_anova_combined &lt;- waic(bayesian_iris_anova_combined)\nprint(waic_bayesian_iris_anova_combined)\nloo_compare(waic_bayesian_iris_anova,waic_bayesian_iris_anova_combined) #model\n\nSample code provided. Major point is using Shinystan to visually access that burn-in period is sufficient and chains converger prior to analyzing the posterior."
  },
  {
    "objectID": "content/solutions/10_Linear_model_extensions_solutions.html",
    "href": "content/solutions/10_Linear_model_extensions_solutions.html",
    "title": "Linear model extensions",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nIn a study considering how the presence of sea stars changed snail growth patterns, ~25 snails were grown in containers containing 0,1, or 2 seastars.\nSince non-consumptive effects are often threshold based, these treatments levels should be considered as groups (not as a continuous variable!). The data is available at\n\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/snail_modified_for_class.csv\nFL is the final length of measured snails, and the treatment (coded 1-3) correspond to [1=Control (no predators). 2=1 predator treatment,3=2 predator treatment).\nWhat method would you use to analyze this data and why? Carry out your test, stating your null hypothesis, test assumptions, p-value, and interpretation.\nDescribe any necessary steps and provide graphics and values as needed. If needed, can you determine which treatments differ from each other?\n\nsnail &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/snail_modified_for_class.csv\")\nhead(snail)\n\n  Container Treatment    FL\n1         1         3 22.50\n2         1         3 20.61\n3         1         3 23.13\n4         1         3 23.71\n5         1         3 24.40\n6         1         3 23.62\n\nsnail$Treatment &lt;- as.factor(snail$Treatment)\nlibrary(plyr)\nsnail$Treatment_new &lt;- revalue(snail$Treatment, c(\"1\" = \"Control\", \"2\" = \"Single predator\",\n                                                  \"3\" = \"Two predators\"))\n\nlibrary(lme4)\nsnail_mm &lt;- lmer(FL ~ Treatment_new + (1|Container), snail)\nsummary(snail_mm)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: FL ~ Treatment_new + (1 | Container)\n   Data: snail\n\nREML criterion at convergence: 1163.4\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.62147 -0.68438  0.04799  0.62360  2.93899 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n Container (Intercept) 0.6509   0.8068  \n Residual              8.2124   2.8657  \nNumber of obs: 234, groups:  Container, 12\n\nFixed effects:\n                             Estimate Std. Error t value\n(Intercept)                   23.7426     0.5178  45.857\nTreatment_newSingle predator  -2.2159     0.7295  -3.037\nTreatment_newTwo predators    -1.8844     0.7353  -2.563\n\nCorrelation of Fixed Effects:\n            (Intr) Trt_Sp\nTrtmnt_nwSp -0.710       \nTrtmnt_nwTp -0.704  0.500\n\nplot(snail_mm)\n\n\n\n\n\n\n\ncheck_mixed_model &lt;- function (model, model_name = NULL) {\n  #collection of things you might check for mixed model\n  par(mfrow = c(2,3))\n  #not sure what this does with mutliple random effects, so stop with 1 for now\n  if(length(names(ranef(model))&lt;2)){\n    qqnorm(ranef(model, drop = T)[[1]], pch = 19, las = 1, cex = 1.4, main= paste(model_name, \n                                                                                  \"\\n Random effects Q-Q plot\"))\n  }\n  plot(fitted(model),residuals(model), main = paste(model_name, \n                                                    \"\\n residuals vs fitted\"))\n  qqnorm(residuals(model), main =paste(model_name, \n                                       \"\\nresiduals q-q plot\"))\n  qqline(residuals(model))\n  hist(residuals(model), main = paste(model_name, \n                                      \"\\nresidual histogram\"))\n}\n\ncheck_mixed_model(snail_mm)\n\n\nlibrary(car)\nAnova(snail_mm, type = \"III\")\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: FL\n                 Chisq Df Pr(&gt;Chisq)    \n(Intercept)   2102.876  1  &lt; 2.2e-16 ***\nTreatment_new   10.681  2   0.004792 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\nsnail_comparison &lt;- glht(snail_mm, linfct = mcp(Treatment_new = \"Tukey\"))\nsummary(snail_comparison)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lmer(formula = FL ~ Treatment_new + (1 | Container), data = snail)\n\nLinear Hypotheses:\n                                     Estimate Std. Error z value Pr(&gt;|z|)   \nSingle predator - Control == 0        -2.2159     0.7295  -3.037  0.00671 **\nTwo predators - Control == 0          -1.8844     0.7353  -2.563  0.02791 * \nTwo predators - Single predator == 0   0.3315     0.7326   0.453  0.89328   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n#graph using Rmisc\nlibrary(Rmisc)\nlibrary(ggplot2)\ngraph_output &lt;- summarySE(snail, measurevar = \"FL\", groupvars = \"Treatment_new\")\nbar_graph_with_error_bars &lt;- ggplot(graph_output, \n                                     aes_string(x=\"Treatment_new\", \n                                                y = \"FL\")) +\n  geom_col() + \n  geom_errorbar(aes(ymin = FL - ci, \n                    ymax = FL + ci))+\n  xlab(\"Treatment\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+\nylim(c(0, 30))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\nbar_graph_with_error_bars\n\n\n\n\n\n\n\n\nSince multiple oysters were measured in each cage, we need to use a random effect to account for cages. You could also block by cages- it takes up more degrees of freedom, but you have plenty here. Results show a significant differce among treatments (Chi^2~2=10.681, p &lt;.01), so I used a Tukey post hoc test to determine which groups differed from others while controlling for the family wise error rate. REsults indicate the presence of a predator impacts length but not the density.\n\n(From OZDasl) The data give the ambient temperature and the number of primary O-rings damaged for 23 of the 24 space shuttle launches before the launch of the space shuttle Challenger on January 20, 1986. (Challenger was the 25th shuttle. One engine was lost at sea and could not be examined.) Each space shuttle contains 6 primary O-rings.\n\nNote these are counts. We can analyze this data using a Poisson distribution or binomial. Make sure you understand why each one is possible, which one is better, and carry out the analysis. Data is available @\nhttp://www.statsci.org/data/general/challenger.txt\n\nrings &lt;- read.table(\"http://www.statsci.org/data/general/challenger.txt\", \n                    header = T)\n#can do as poisson\nrings_poisson &lt;- glm(Damaged ~ Temp, rings, family = \"poisson\")\nsummary(rings_poisson)\n\n\nCall:\nglm(formula = Damaged ~ Temp, family = \"poisson\", data = rings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)   5.9691     2.7628   2.161   0.0307 *\nTemp         -0.1034     0.0430  -2.405   0.0162 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 22.434  on 22  degrees of freedom\nResidual deviance: 16.834  on 21  degrees of freedom\nAIC: 36.061\n\nNumber of Fisher Scoring iterations: 6\n\n#note dispersion is ok\nlibrary(car)\nAnova(rings_poisson, type = \"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: Damaged\n     LR Chisq Df Pr(&gt;Chisq)  \nTemp   5.6004  1    0.01796 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#or binomial (preffered as we can add info (number damaged and not!))\nrings_binomial &lt;- glm(cbind(Damaged, 6 - Damaged) ~ Temp, rings, family = \"binomial\")\nsummary(rings_binomial)\n\n\nCall:\nglm(formula = cbind(Damaged, 6 - Damaged) ~ Temp, family = \"binomial\", \n    data = rings)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  5.08498    3.05247   1.666   0.0957 .\nTemp        -0.11560    0.04702  -2.458   0.0140 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 24.230  on 22  degrees of freedom\nResidual deviance: 18.086  on 21  degrees of freedom\nAIC: 35.647\n\nNumber of Fisher Scoring iterations: 5\n\n#note dispersion is ok\nAnova(rings_binomial, type = \"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(Damaged, 6 - Damaged)\n     LR Chisq Df Pr(&gt;Chisq)  \nTemp    6.144  1    0.01319 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#compare to lm\nrings_lm &lt;- lm(Damaged ~ Temp, rings)\nsummary(rings_lm)\n\n\nCall:\nlm(formula = Damaged ~ Temp, data = rings)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.5608 -0.3944 -0.0854  0.1056  1.8671 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  3.69841    1.21951   3.033  0.00633 **\nTemp        -0.04754    0.01744  -2.725  0.01268 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5774 on 21 degrees of freedom\nMultiple R-squared:  0.2613,    Adjusted R-squared:  0.2261 \nF-statistic: 7.426 on 1 and 21 DF,  p-value: 0.01268\n\n#note dispersion is ok\nAnova(rings_lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Damaged\n            Sum Sq Df F value  Pr(&gt;F)   \n(Intercept) 3.0667  1  9.1973 0.00633 **\nTemp        2.4762  1  7.4264 0.01268 * \nResiduals   7.0021 21                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince these are counts we need to use a glm to model the data. We could use a Poisson, but the binomial actually includes more information (like how many did not fail!). Both models indicate a significant relationship between temperature and the number or proportion of failed rings. Results are compared to a linear model.\n\nReturning to the whelk length-mass relationship from class, try fitting an exponential curve to the data. As a hint, try\n\n\nnls(Mass ~ exp(b0 + b1 * Shell.Length), whelk, \n                   start = list(b0 =1, b1=0), na.action = na.omit)\n\nCompare this model to those that assume a linear and power relationship. Data is available @\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/whelk.csv\n\nwhelk &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/whelk.csv\")\nhead(whelk)\n\n   Location   Mass Sex Shell.Length\n1 San Diego 126.10   F           NA\n2 San Diego 119.92   M       106.21\n3 San Diego  40.07   M        75.58\n4 San Diego 140.82   F       107.59\n5 San Diego  49.70   M        76.23\n6 San Diego     NA   M        70.10\n\nsummary(whelk)\n\n   Location              Mass             Sex             Shell.Length   \n Length:473         Min.   :  9.906   Length:473         Min.   : 43.58  \n Class :character   1st Qu.: 87.352   Class :character   1st Qu.: 90.50  \n Mode  :character   Median :150.325   Mode  :character   Median :109.89  \n                    Mean   :152.590                      Mean   :106.56  \n                    3rd Qu.:209.476                      3rd Qu.:122.30  \n                    Max.   :403.892                      Max.   :155.28  \n                    NA's   :28                           NA's   :33      \n\nlibrary(ggplot2)\nwhelk_plot &lt;- ggplot(whelk, aes_string(x=\"Shell.Length\", y = \"Mass\")) +\n  geom_point(aes_string(colour = \"Location\")) + \n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\nwhelk_plot\n\nWarning: Removed 61 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n#power fit\nwhelk_lm &lt;- lm(Mass ~ Shell.Length, whelk, na.action = na.omit)\n\nwhelk_power &lt;- nls(Mass ~ b0 * Shell.Length^b1, whelk, \n                   start = list(b0 = 1, b1=3), na.action = na.omit)\nwhelk_exponential &lt;- nls(Mass ~ exp(b0 + b1 * Shell.Length), whelk, \n                         start = list(b0 =1, b1=0), na.action = na.omit)\nlibrary(MuMIn)\nAICc(whelk_lm, whelk_power, whelk_exponential)\n\n                  df     AICc\nwhelk_lm           3 3947.579\nwhelk_power        3 3800.106\nwhelk_exponential  3 3841.422\n\n#plot\nwhelk_plot + geom_smooth(method = \"lm\", se = FALSE, size = 1.5, color = \"orange\")+ \n  geom_smooth(method=\"nls\", \n              # look at whelk_power$call\n              formula = y ~ b0 * x^b1, \n              method.args = list(start = list(b0 = 1, \n                                              b1 = 3)), \n              se=FALSE, size = 1.5, color = \"blue\") +\n  geom_smooth(method=\"nls\", \n              # look at whelk_exponential$call\n              formula = y ~ exp(b0 + b1 * x), \n              method.args = list(start = list(b0 = 1, \n                                              b1 = 0)), \n              se=FALSE, size = 1.5, color = \"green\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 61 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 61 rows containing non-finite values (`stat_smooth()`).\nRemoved 61 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 61 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe can use the nls model to consider exponential curve to the data. Various fits may be compared using AIC methods. In this case it appears that the power fit is the best (lowest AIC value).\n\nGoing back to the TEAM dataset, remember we found that elevation had no impact on carbon storage. But that was a linear fit. Use a gam (generalized additive model) to see if elevation can be related to carbon storage in an additive model. Note we can use the gamm (generalized additive mixed model) function in the mgcv package to denote mixed effects. For example (from help file)\n\n\nb2 &lt;- gamm(y~s(x0)+s(x1)+s(x2),family=poisson,\n           data=dat,random=list(fac=~1))\n\nTeam data is available @\nhttps://raw.github.com/jsgosnell/CUNY-BioStats/blob/master/datasets/team_data_no_spaces.csv\n\nlibrary(mgcv)\nlibrary(MuMIn) #for AICc\nteam &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/team_data_no_spaces.csv\", stringsAsFactors = T)\nelevation_linear &lt;- gam(PlotCarbon.tonnes ~ Elevation, data = team)\nelevation_gam &lt;- gam(PlotCarbon.tonnes ~ s(Elevation), data = team)\nelevation_gamm &lt;- gamm(PlotCarbon.tonnes ~s(Elevation), random = list(Site.Name = ~ 1), data = team)\nAICc(elevation_gam, elevation_gamm, elevation_linear)\n\n                 df     AICc\nelevation_gam     3 648.2139\nelevation_gamm    5 634.4652\nelevation_linear  3 648.2139\n\n\nA generalized additive model fits a curve to the dataset (spline in this case). AIC comparison indicates the gam model with a random effect for site is the best fit.",
    "crumbs": [
      "Solutions",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html",
    "href": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#overview",
    "href": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#overview",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the lecture on combining numerical and continous predictors.",
    "crumbs": [
      "Practice problems",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#example",
    "href": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#example",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Example",
    "text": "Example\nFollowing the iris example from class\n\nset.seed(3)\niris_example_species &lt;-data.frame(\n  Species = c(rep(\"baruch\",25), rep(\"hunter\", 25), rep(\"york\", 25)),\n  Petal_Length = runif(75,2,4 ))\nset.seed(31)\niris_example_species$Sepal_interaction &lt;- \n  iris_example_species$Petal_Length * c(rep(-2, 25),rep(0,25), rep(5,25)) + \n  c(rep(2,25), rep(3,25), rep(4,25)) + rnorm(75)\n\nPlot the data\n\nlibrary(ggplot2)\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_interaction, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(lm( Sepal_interaction~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n                      Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)            7.076  1   8.0267  0.006038 ** \nPetal_Length          38.452  1  43.6177  6.88e-09 ***\nSpecies                3.353  2   1.9015  0.157092    \nPetal_Length:Species 227.334  2 128.9368 &lt; 2.2e-16 ***\nResiduals             60.828 69                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ninteractions do exist. This means we can’t interpret the “general” relationship, so we need to look for each species using regression.\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"baruch\", ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7194 -0.5504 -0.1860  0.4736  1.7067 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.9734     0.9767   3.044  0.00576 ** \nPetal_Length  -2.3663     0.3335  -7.097 3.14e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8738 on 23 degrees of freedom\nMultiple R-squared:  0.6865,    Adjusted R-squared:  0.6728 \nF-statistic: 50.36 on 1 and 23 DF,  p-value: 3.144e-07\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   7.076  1  9.2676  0.005758 ** \nPetal_Length 38.452  1 50.3604 3.144e-07 ***\nResiduals    17.561 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"hunter\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"hunter\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89221 -0.58055  0.00876  0.47006  2.49756 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    1.2564     1.1463   1.096    0.284\nPetal_Length   0.4962     0.3895   1.274    0.215\n\nResidual standard error: 0.9902 on 23 degrees of freedom\nMultiple R-squared:  0.06589,   Adjusted R-squared:  0.02528 \nF-statistic: 1.622 on 1 and 23 DF,  p-value: 0.2155\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"hunter\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value Pr(&gt;F)\n(Intercept)   1.1779  1  1.2014 0.2844\nPetal_Length  1.5907  1  1.6224 0.2155\nResiduals    22.5503 23               \n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"york\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"york\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.45150 -0.69660  0.02717  0.83006  1.64698 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    4.0617     0.9550   4.253    3e-04 ***\nPetal_Length   4.9642     0.3024  16.417  3.4e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9491 on 23 degrees of freedom\nMultiple R-squared:  0.9214,    Adjusted R-squared:  0.918 \nF-statistic: 269.5 on 1 and 23 DF,  p-value: 3.401e-14\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"york\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   16.292  1  18.087 0.0002998 ***\nPetal_Length 242.770  1 269.527 3.401e-14 ***\nResiduals     20.717 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere we see that there is a significant negative relationship (F1,23 = 50.36, p&lt;0.001) between sepal and petal length for I. baruch, a significant positive relationship (F1,23 = 269.53, p&lt;0.001) between sepal and petal length for I. york,and no relationship (F1,23 = 1.63, p&lt;-0.21) between sepal and petal length for I. hunter.",
    "crumbs": [
      "Practice problems",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#practice",
    "href": "content/practice_problems/9_Combining_numerical_and_categorical_predictors.html#practice",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Practice",
    "text": "Practice\n\n1\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nDoes the impact of age on FEV differ among genders? Consider how your answer to this differs from the previous assignment!\n\n\n2\nData on home gas consumption at various temperatures before and after new insulation was installed has been collected @\nhttp://www.statsci.org/data/general/insulgas.txt\nMore information on the data is available @\nhttp://www.statsci.org/data/general/insulgas.html\nIs there any relationship between these factors? How would you test this, and what type of plot would you produce to accompany your analysis?\n\n\n3\nData on the height, diameter, and volume of cherry trees was collected for use in developing an optimal model to predict timber volume. Data is available @\nhttp://www.statsci.org/data/general/cherry.txt\nUse the data to justify an optimal model.\n\n\n4\nOver the course of five years, a professor asked students in his stats class to carry out a simple experiment. Students were asked to measure their pulse rate, run for one minute, then measure their pulse rate again. The students also filled out a questionnaire. Data include:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nHeight\nHeight (cm)\n\n\nWeight\nWeight (kg)\n\n\nAge\nAge (years)\n\n\nGender\nSex (1 = male, 2 = female)\n\n\nSmokes\nRegular smoker? (1 = yes, 2 = no)\n\n\nAlcohol\nRegular drinker? (1 = yes, 2 = no)\n\n\nExercise\nFrequency of exercise (1 = high, 2 = moderate, 3 = low)\n\n\nChange\nPercent change in pulse (pulse after experiment/pulse before experiment)\n\n\nYear\nYear of class (93 - 98)\n\n\n\nUsing the available data (available at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vToN77M80enimQglwpFroooLzDtcQMh4qKbOuhbu-eVmU9buczh7nVV1BdI4T_ma-PfWUnQYmq-60RZ/pub?gid=942311716&single=true&output=csv )\ndetermine the optimal subset of explanatory variables that should be used to predict change pulse rate (Change) (focusing on main effects only, no interactions) and explain your choice of methods. Interpret your results. Make sure you can explain any changes you needed to make to the dataset or steps you used in your analysis.\n\n\n5\nFind one example of model selection from a paper in your field. It may be more complicated (see next question!) than what we have done, but try to identify the approach (F/AIC, top-down/bottom-up/not nested) they used. Review how they explained their approach (methods) and reported outcomes (results). Be prepared to discuss in class next week.\n\n\n6\nFind one example of a linear model selection (e.g., generalized linear models, mixed-effects models, beta regression) from a paper in your field. Be prepared to name the technique in class next week.",
    "crumbs": [
      "Practice problems",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html",
    "href": "content/practice_problems/7_More_ANOVAs.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#overview",
    "href": "content/practice_problems/7_More_ANOVAs.html#overview",
    "title": "More ANOVAs",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the More ANOVAs lecuture.",
    "crumbs": [
      "Practice problems",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#examples",
    "href": "content/practice_problems/7_More_ANOVAs.html#examples",
    "title": "More ANOVAs",
    "section": "Examples",
    "text": "Examples\n\nIf interaction is significant\nFollowing the memory example from class, read in and check data\n\nmemory &lt;- read.table(\"http://www.statsci.org/data/general/eysenck.txt\", header = T,\n                     stringsAsFactors = T)\nstr(memory)\n\n'data.frame':   100 obs. of  3 variables:\n $ Age    : Factor w/ 2 levels \"Older\",\"Younger\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Process: Factor w/ 5 levels \"Adjective\",\"Counting\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Words  : num  8 6 4 6 7 6 5 7 9 7 ...\n\n\nLet’s put younger level first\n\nlibrary(plyr)\nmemory$Age &lt;- relevel(memory$Age, \"Younger\")\n\nand graph\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nfunction_output &lt;- summarySE(memory, measurevar=\"Words\", groupvars =\n                               c(\"Age\", \"Process\"), na.rm = T)\nlibrary(ggplot2)\nggplot(function_output, aes(x=Age, y=Words,color=Process, \n                                   shape = Process)) +\n  geom_line(aes(group=Process, linetype = Process), size=2) +\n    geom_point(size = 5) +\n  ylab(\"Words remembered\")+ \n  xlab(\"Age\") + \n  ggtitle(\"Process type interacts with age to impact memory\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nThere appears to be some interactions. Let’ build a model\n\nmemory_interactions &lt;- lm(Words ~ Age * Process, memory)\n\nand check assumptions.\n\npar(mfrow=c(2,2))\nplot(memory_interactions)\n\n\n\n\n\n\n\n\nThese appear to be met, so look at output\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(memory_interactions, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 272.9281 &lt; 2.2e-16 ***\nAge           72.2  1   8.9963 0.0034984 ** \nProcess     1353.7  4  42.1690 &lt; 2.2e-16 ***\nAge:Process  190.3  4   5.9279 0.0002793 ***\nResiduals    722.3 90                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince interaction is significant, analyze subsets. For example,\n\nmemory_interactions_young &lt;- lm(Words ~ Process, memory[memory$Age == \"Younger\",])\nplot(memory_interactions_young)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(memory_interactions_young, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 343.442 &lt; 2.2e-16 ***\nProcess     1353.7  4  53.064 &lt; 2.2e-16 ***\nResiduals    287.0 45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant difference in words recalled based on process, but why? Investigate with post-hoc tests.\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncomp_young &lt;- glht(memory_interactions_young, linfct = mcp(Process = \"Tukey\"))\nsummary(comp_young)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Words ~ Process, data = memory[memory$Age == \"Younger\", \n    ])\n\nLinear Hypotheses:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \nCounting - Adjective == 0      -8.300      1.129  -7.349  &lt; 1e-04 ***\nImagery - Adjective == 0        2.800      1.129   2.479  0.11375    \nIntentional - Adjective == 0    4.500      1.129   3.984  0.00222 ** \nRhyming - Adjective == 0       -7.200      1.129  -6.375  &lt; 1e-04 ***\nImagery - Counting == 0        11.100      1.129   9.828  &lt; 1e-04 ***\nIntentional - Counting == 0    12.800      1.129  11.333  &lt; 1e-04 ***\nRhyming - Counting == 0         1.100      1.129   0.974  0.86545    \nIntentional - Imagery == 0      1.700      1.129   1.505  0.56457    \nRhyming - Imagery == 0        -10.000      1.129  -8.854  &lt; 1e-04 ***\nRhyming - Intentional == 0    -11.700      1.129 -10.359  &lt; 1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nBlocking example\nFollowing feather color example from class:\n\n# more than 2? ####\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nstr(feather)\n\n'data.frame':   32 obs. of  3 variables:\n $ Bird       : Factor w/ 16 levels \"A\",\"B\",\"C\",\"D\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Feather    : Factor w/ 2 levels \"Odd\",\"Typical\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Color_index: num  -0.255 -0.213 -0.19 -0.185 -0.045 -0.025 -0.015 0.003 0.015 0.02 ...\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather = \"Special\", \n                      Color_index= feather[feather$Feather == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather &lt;- merge(feather, special, all = T)\n\n\nAnova(lm(Color_index ~ Feather + Bird, data=feather), type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.36392  1  59.9538 1.224e-08 ***\nFeather     1.67906  2 138.3093 7.208e-16 ***\nBird        0.34649 15   3.8055 0.0008969 ***\nResiduals   0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\ncompare &lt;- glht(lm(Color_index ~ Feather + Bird, data=feather), linfct = mcp(\"Feather\" = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather + Bird, data = feather)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nTypical - Odd == 0      0.13712    0.02755   4.978   &lt;1e-04 ***\nSpecial - Odd == 0      0.44712    0.02755  16.232   &lt;1e-04 ***\nSpecial - Typical == 0  0.31000    0.02755  11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n#note comparison doesn't work\nAnova(lm(Color_index ~ Feather * Bird, data=feather), type= \"III\")\n\nError in Anova.lm(lm(Color_index ~ Feather * Bird, data = feather), type = \"III\"): residual df = 0",
    "crumbs": [
      "Practice problems",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#practice",
    "href": "content/practice_problems/7_More_ANOVAs.html#practice",
    "title": "More ANOVAs",
    "section": "Practice",
    "text": "Practice\n\n1\nA survey was conducted to see if athletes and non-athletes deal with anger in the same way. Data is @\nangry &lt;- read.csv(“https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv”, stringsAsFactors = T)\nand more information is at\nhttp://onlinestatbook.com/case_studies/angry_moods.html.\nFocus on the following variables:\nSports 1 = athletes, 2 = non-athletes Gender 1 = males, 2 = females Expression (AE) index of general anger expression: (Anger-Out) + (Anger-In) - (Control-Out) - (Control-In) + 48\nIs there any evidence that gender or athlete status impact how anger is expressed?\n\n\n2\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at http://www.statsci.org/data/oz/ms212.txt With more info at http://www.statsci.org/data/oz/ms212.html. Is there evidence that frequency of exercise (Exercise column) and gender impact change in pulse rate for students who ran (Ran column = 1)?\n\n\n3\nData from Valdez et al 2023 is available @ https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv.\nImport it into to R and\n\ndetermine how the snail grazing and nitrogen levels impact number of flowering shoots ( Shoot.density..m2)\nconstruct a plot to showcase your analysis\n\n\n\n4\nFind an example of a factorial ANOVA from a paper that is related to your work. Make sure you understand the connections between the methods, results, and graphs. Briefly answer the following questions\n\nWhat was the dependent variable?\nWhat were the independent variables?\nWas the interaction significant?\n\nIf so, how did they interpret findings\nIf not, were the main effects significant?",
    "crumbs": [
      "Practice problems",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html",
    "href": "content/practice_problems/5_Contingency_analysis.html",
    "title": "Compare proportions among groups",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#overview",
    "href": "content/practice_problems/5_Contingency_analysis.html#overview",
    "title": "Compare proportions among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture.",
    "crumbs": [
      "Practice problems",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#examples",
    "href": "content/practice_problems/5_Contingency_analysis.html#examples",
    "title": "Compare proportions among groups",
    "section": "Examples",
    "text": "Examples\nIssue is we often get data in spreadsheet format (expanded/long or wide/summarized, each shown below), but we need to get a vector or matrix for chisq.test and related functions.\n\nThe data\nFollowing the Everest example from class. Assume data is in a dataframe where each row is a group data point.\n\neverest &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\"),\n                      Oxygen = c(\"Used\", \"Used\", \"Not used\", \"Not used\"),\n                      Number = c(1045, 32, 88, 8))\n\nAssume data is in a dataframe where each row is an individual data point.\n\nlibrary(mirt)\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\neverest_expand &lt;- expand.table(everest)\n\n\n\ntests\nFirst, let’s ask if the same amount of people used or did not use oxygen. WE can use the table command to summarize. Note the chisq.test, by default, assumes each group is equally likely!\n\ntable(everest_expand$Oxygen)\n\n\nNot used     Used \n      96     1077 \n\nchisq.test(table(everest_expand$Oxygen)) \n\n\n    Chi-squared test for given probabilities\n\ndata:  table(everest_expand$Oxygen)\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nDong this with summarized data is actually harder\n\naggregate(Number~Oxygen, everest, sum)$Number\n\n[1]   96 1077\n\nchisq.test(aggregate(Number~Oxygen, everest, sum)$Number) \n\n\n    Chi-squared test for given probabilities\n\ndata:  aggregate(Number ~ Oxygen, everest, sum)$Number\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nBut this is better!\n\nbinom.test(table(everest_expand$Oxygen))\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we wanted to compare to past years where 10% of climbers did not use oxygen? Note table function splits into alphabetical order.\n\nbinom.test(table(everest_expand$Oxygen), p=.1)\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value = 0.04075\nalternative hypothesis: true probability of success is not equal to 0.1\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we want to determine if using oxygen impacts surival?\n\nchisq.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\nWarning in chisq.test(table(everest_expand$Oxygen, everest_expand$Survived)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nIssue (which we’ll address), but note same as\n\nchisq.test(table(everest_expand$Survived, everest_expand$Oxygen))\n\nWarning in chisq.test(table(everest_expand$Survived, everest_expand$Oxygen)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Survived, everest_expand$Oxygen)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 32, 88,  8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nKey is first argument must be all the info. This is different from (incorrect) approach like\n\nchisq.test(everest$Survived,everest$Oxygen)\n\nWarning in chisq.test(everest$Survived, everest$Oxygen): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  everest$Survived and everest$Oxygen\nX-squared = 0, df = 1, p-value = 1\n\n\nThis is comparing split among Survived and not to split (expected) using Oxygen!\nSo order has minimal input with 2 groups. Other test options necessitated by the warning\n\nfisher.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\np-value = 0.01284\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 1.144791 6.826869\nsample estimates:\nodds ratio \n  2.964765 \n\nlibrary(DescTools)\nGTest(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nG = 5.7466, X-squared df = 1, p-value = 0.01652\n\n\nWhat if we added another group? Like Enriched, Regular, None for oxygen.\n\neverest_enriched &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\", \"Y\", \"N\"),\n                      Oxygen = c(\"Regular\", \"Regular\", \"None\", \"None\", rep(\"Enriched\", 2)),\n                      Number = c(1045, 32, 88, 8, 15, 2))\neverest_enriched_expand &lt;- expand.table(everest_enriched)\n\nNow we compare\n\ntable(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\n\n   \n    Enriched None Regular\n  N        2    8      32\n  Y       15   88    1045\n\nchisq.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(table(everest_enriched_expand$Survived,\neverest_enriched_expand$Oxygen)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\nX-squared = 10.879, df = 2, p-value = 0.004343\n\n\nFisher again due to size\n\nfisher.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\np-value = 0.00586\nalternative hypothesis: two.sided\n\n\nNow we follow-up, and rows/columns matter. Note default is row and fdr method. I order results for ease of view\n\nlibrary(rcompanion)\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n  Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq p.adj.Chisq\n1      N : Y  0.00586      0.00586  0.0189      0.0189 0.00434     0.00434\n\n\nNot quite what we wanted. How about\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1430  0.1080      0.1620  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.2560\n1      1.0000\n\n\nand you can change methods\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\",\n                                                          method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1910  0.1080      0.2160  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.3420\n1      1.0000\n\n\nTo put in manually, we need a few extra things\n\neverest_table &lt;- as.table(matrix(c(2,8,32,15,88,1045), nrow = 2, byrow = T))\nrownames(everest_table) = c(\"N\", \"Y\")\ncolnames(everest_table) = c(\"Enriched\", \"None\", \"Regular\")\neverest_table\n\n  Enriched None Regular\nN        2    8      32\nY       15   88    1045",
    "crumbs": [
      "Practice problems",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#lets-practice",
    "href": "content/practice_problems/5_Contingency_analysis.html#lets-practice",
    "title": "Compare proportions among groups",
    "section": "Let’s practice",
    "text": "Let’s practice\n\nHeart attacks\n\n1\nLet’s look at some heart attack data. Read in the data using\n\nheart_attacks &lt;- read.table(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/heartatk4R.txt\",header=T, stringsAsFactors = T)\n\nEvery entry is a person that has suffered a heart attack. More information on the dataset can be found at\nhttp://statland.org/Software_Help/DataDesk/datafile.htm\nWe want to again test if heart attacks occur equally across genders.\n\nWhat if we know that males actually make up 50.8% of the population?\n\n\n\n2\nStill using the heart attack data, is survival independent of gender?\n\n\n3\nFor people that have a heart attack before they turn 30, is survival independent of gender?\n\n\n\nDolphins\n\n4\nData on dolphin behavior was collected off the coast of Iceland. Data is @\nhttp://www.statsci.org/data/general/dolpacti.txt\nSince this is a .txt file, not a .csv, you’ll need to use something like\n\ndolphin &lt;- read.table(\"http://www.statsci.org/data/general/dolpacti.txt\", sep=\"\", header = T, stringsAsFactors = T)\n\nMore info on data @\nhttp://www.statsci.org/data/general/dolpacti.html\nIs travelling independent of time of day? You’ll need to consider traveling vs not traveling due to different number of groups observed in each period. Carry out post-hoc tests if needed.\n\n\n\nSmoking\n\n5\nUse data on smoking and exercise from\nhttp://www.r-tutor.com/elementary-statistics/goodness-fit/chi-squared-test-independence\nto determine if smoking is independent of exercise. You’ll need to input data manually. Carry out post-hoc tests if needed.",
    "crumbs": [
      "Practice problems",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#overview",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#overview",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Hypothesis testing starting with binomial tests lecture.",
    "crumbs": [
      "Practice problems",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#hypothesis-testing-and-the-binomial-distribution",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#hypothesis-testing-and-the-binomial-distribution",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Hypothesis Testing and the Binomial Distribution",
    "text": "Hypothesis Testing and the Binomial Distribution\n\nExample\nUsing the bat paper from class (Geipel et al. 2021), let’s consider how to analyze data showing all 10 bats chose the walking over the motionless model.\n\nbinom.test(10,10)\n\n\n    Exact binomial test\n\ndata:  10 and 10\nnumber of successes = 10, number of trials = 10, p-value = 0.001953\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6915029 1.0000000\nsample estimates:\nprobability of success \n                     1 \n\n\nWe use the binom.test function. We only need arguments for # of succeses and # of trials. By default it runs a 2-sided test against a null hypothesis value of p = .5. You can see how to update thee options by looking at the help file.\n\n?binom.test\n\nNote the confidence interval is assymetric since its estimated to be 1! We can see other options using the binom.confint function from the binom package.\n\nlibrary(binom)\nbinom.confint(10,10)\n\n          method  x  n      mean     lower    upper\n1  agresti-coull 10 10 1.0000000 0.6791127 1.043355\n2     asymptotic 10 10 1.0000000 1.0000000 1.000000\n3          bayes 10 10 0.9545455 0.8292269 1.000000\n4        cloglog 10 10 1.0000000 0.6915029 1.000000\n5          exact 10 10 1.0000000 0.6915029 1.000000\n6          logit 10 10 1.0000000 0.6915029 1.000000\n7         probit 10 10 1.0000000 0.6915029 1.000000\n8        profile 10 10 1.0000000 0.7303058 1.000000\n9            lrt 10 10 1.0000000 0.8252466 1.000000\n10     prop.test 10 10 1.0000000 0.6554628 1.000000\n11        wilson 10 10 1.0000000 0.7224672 1.000000\n\n\nAll of these correct for the fact that most intervals use a normal approximation, which as you remember from our earlier discussions is not good when sample sizes are small and/or the p parameter is extreme (close to 0 or 1).",
    "crumbs": [
      "Practice problems",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#practice",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#practice",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Practice!",
    "text": "Practice!\nMake sure you are comfortable with null and alternative hypotheses for all examples.\n\n1\nAre people eared (do they prefer one ear or another)? Of 25 people observed while in conversation in a nightclub, 19 turned their right ear to the speaker and 6 turn their left ear to the speaker. How strong is the evidence for eared-ness given this data (adapted from Analysis of Biological Data)? * state a null and alternative hypothesis * calculate a test statistic (signal) for this data * Make you understand how to construct a null distribution + using sampling/simulation (code or written explanation) + by using an appropriate distribution (code or written explanation) * Calculate and compare p-values obtained using + simulation (calculation won’t be required on test, but make sure you understand!) (code or written explanation) + equations for binomial distribution (code or written explanation) + R functions (required)(code) * Calculate a 95% confidence interval for the proportion of people who are right-eared * How do your 95% confidence interval and hypothesis test compare?\n\n\n2\nA professor lets his dog take every multiple-choice test to see how it compares to his students (I know someone who did this). Unfortunately, the professor believes undergraduates in the class tricked him by helping the dog do better on a test. It’s a 100 question test, and every questions has 4 answer choices. For the last test, the dog picked 33 questions correctly. How likely is this to happen, and is there evidence the students helped the dog?\nMAKE SURE TO THINK ABOUT YOUR TEST OPTIONS",
    "crumbs": [
      "Practice problems",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/practice_problems/1_Getting_used_to_R.html",
    "href": "content/practice_problems/1_Getting_used_to_R.html",
    "title": "Getting used to R",
    "section": "",
    "text": "Overview\nThe focus of this overview is to get you used to tools we will be using in class. Before completing it you should have a basic understanding of using R. We will do an introduction in class (download help file). You should also be comfortable using Rstudio and github (see help file).\n\nRmd basics\nRmd files differ from R files in that they combine regular text with code chunks. This is a code chunk\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nCode chunks combine code with output. When combined with regular text/prose, this makes it easier to produce a range of documents. You set the output in the YAML header (the stuff between the 3 dashes you see at top of this document).\nAfter you write the file, you Knit it to turn the Rmd file into the selected output. Try it now. Note the first time you do this in a project you may be prompted to install a number of packages! If you are using a webservice you may also need to allow pop-ups in your browser. Don’t be surprised if a new window pops up (it should).\n\n\n\nThe knit button turns your .rmd file into other products\n\n\nThe Knit button saves the .Rmd file and renders a new version whose output depends on what you selected in the header. Here we have html_document, so if everything works a preview of a webpage like document should appear. The file also produces a github friendly .md file. This means you should only edit the Rmd file (leave the md and output files alone! They are automatically produced any changes you make there will be overwritten by your next knit).\nWhen you Knit a file, it runs in a totally new R instance. this means anything you only added in your instance (like working in the console) won’t be available. In other words, its the best way to see what a “new” user gets when they use your code.\nhowever, you don’t have to knit the file every time. if you just want to see output, note you can press the green button next to an R chunk.\n\n\n\nThe green arrows just runs the chunk in the console and shows the output\n\n\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nNow we’ll start changing the file to show you how rmarkdown works. First, amend the file by replacing the NAME and DATE spots in the header (top of the file between the — markers) with your name and the real date. Then Knit the file again. You should see your name in the new preview.\nRstudio has a Markdown Quick Reference guide (look under the help tab), but some general notes.\n\nPound/Hashtag signs denote headers\nyou can surround something double asterisks for bold or single asterisks for italics\nlists are denoted by numbers or asterisks at beginning of line (followed by space!)\n\nand can be indented for sublevels\n\nR code can be done inline, but is generally placed in stand-alone chunks\n\nthese will, by default, show the code and output\n\nlots of other options exist!\n\nThe main idea is Rmd files allow you to combine code, text, graphs, etc into multiple outputs that you can share (including with coding illiterate colleagues who just want output).\nTo practice working with Rmd files and R, work through the questions below. You can also get more help with this video\n\n\n\nPractice in R\n\n1\nLet x be defined by\n\nx &lt;- 5:15\n\nTry executing this chunk (in R studio, not the webview) by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter.\nThis will run the code in the Console. You may need to switch to Console (from Rmarkdown) in the lower right window area to see this. The executed code is also displayed in your processed file (hit Knit again to see this!).\nNote running this chunk has added an object named x to the Environment tab area (top right area of screen). But nothing was “returned” in the console. You prove this by typing x in the console. What does it return?\nDetermine what the “:” does! Complete the following sentence:\nThe : means FILL THIS IN.\n\n\n2\nNow try to guess the output of these commands\n\nlength(x)\nmax(x)\nx[x &lt; 10]\nx^2\nx[ x &lt; 12 & x &gt; 7]\n\nINSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. Then state what each of these does.\n\n\n3\nIs -1:2 the same as (-1):2 or -(1:2)? INSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Then state what each of these does.\n\n\n\nData input, plotting, and tests\nYou can read in a dataset from the internet following this protocol.\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nRun this chunk and note it has added an object named sleep to the environment.\nInfo on the dataset is viewable @ http://www.statsci.org/data/general/sleep.html.\n\n4\nHow many rows does the sleep data set have (hint: ?dim)? What kind of data is stored in each variable?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n5\nChange the column named BodyWt to Body_weight”* in the sleep dataset.\nADD ANY R CHUNKS YOU USED TO COMPLETE THE TASK.\n\n\n6\nProduce a plot of how TotalSleep differs between primates and other species. What is this plot showing?\nNote, as of early 2020 R no longer reads in strings as factors! This means the Primate column, which is full of “Yes”s and “No”s, reads in as words and R doesn’t know how to plot them. There are many ways to handle this. You can modify the read.csv command (add stringsAsFactors = T option), eg\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nIf you do this, you’ll need to rechange anything you previously updated to the object (like renaming the BodyWt column).\nYou can also modify a single column for the actual object\n\nsleep$Primate &lt;- factor (sleep$Primate)\n\nor for a single command, eg (plot not actually shown!)\n\nplot(BodyWt ~ factor(Primate), data = sleep)\n\nNOTE YOU CAN ADD A PLOT TO THE DOCUMENT TOO! AMEND THE BELOW AS NEEDED.\n\nplot(cars)\n\n\n\n\n\n\n\n\n\n\n7\nThe sleep dataset begs to have a linear model fit for it. Let’s consider. First plot how TotalSleep is explained by BrainWt. Are there any issues with the data? Exclude any outlier and fit a linear model to obtain the p-value for the model (hint: summary()). What does this imply?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n\nEXTRA QUESTIONS\nnot required\n Dow Puffin Matthew Zalewski / CC BY (https://creativecommons.org/licenses/by/3.0)\n\n8\nSometimes data doesn’t have headers (column names),so you have to add them. Download a dataset on alcids (birds like puffins and auklets) from https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv.\nYou’ll need to modify the read.csv function by specifying header = False, then use the names function to name the columns [“year”, “a1_abund”, “NAO”, “a2_abund”, “a3_abund”, “a4_abund”, “a5_abund”, “a6_abund”]. Try it and check your input using the head command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n9\nHere’s a sample dataset:\n\n\n\nDate\ngreenness\nRichness\nhabitat\n\n\n\n\n12-25-2009\n13766\n46\nforest\n\n\n01-01-2010\n50513\n60\nforest\n\n\n01-15-2010\n25084\n60\ngrassland\n\n\n\nEnter it into R (manually or via a .csv). (Hint: you have a piece of this in the code already). Check your input using the head() command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.",
    "crumbs": [
      "Practice problems",
      "Getting used to R"
    ]
  },
  {
    "objectID": "content/practice_problems/11_Multivariate_methods.html",
    "href": "content/practice_problems/11_Multivariate_methods.html",
    "title": "Multivariate methods",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nA pharmaceutical company has a drug that may help an illness that causes fever (temperature in degrees Celsius), blood pressures, and “aches” (scored on an index). Data is collected for several patients. To determine if the drug actually helps, test for differences in multivariate means for the fever, pressure and aches column, against the grouping variable treatment.\n\n\nillness &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRlcjpU0XHfXF1WId1C5ZYX0YdY53KI9Nv91_tNCMj4z4iTjr-XMW1L_Ln8j3ahk5GUPZy4kGzSlA96/pub?gid=1322236994&single=true&output=csv\",\n                    stringsAsFactors = T)\n\n\nDarlingtonia californica is a partly carnivorous pitcher plant that grows in fens and along seeps and streams in the mountains of Oregon and California. Its pitchers are tubular l eaves with a round hood and a mouth at the base of the hood (see figure below). A “fishtail” appendage hangs from the mouth. Wasps and other prey are attracted to nectar secreted by extrafloral nectaries along the hood, mouth, and fishtail. Plants absorb nutrients excreted by a food web of bacteria, protozoa, mites, and fly larvae that break down the prey.\n\nMeasurements of 87 plants from four sites were made by Ellison and Farnsworth (2005, The cost of carnivory for Darlingtonia californica (Sarraceniaceae): evidence from relationships among leaf traits. Am. J. Botany 92: 1085-1093). Their measurements are available using\n\npitcher &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQZf2mS4NmfBUUsn7lY2RTpuVjuWvRYN4MdLNt2XdS4WepolrxvWCKBI5diKBMWPLhdbEGwP-hfWOnz/pub?gid=1427497144&single=true&output=csv\",\n                    stringsAsFactors = T)\n\nI obtained them from the web page (http://harvardforest.fas.harvard.edu/personnel/web/aellison/publications/primer/primer.html) of A. M. Ellison for the book by Gotelli and Ellison (2004, A primer of ecological statistics. Sinauer, Sunderland, Mass.). To simplify, outliers have been removed. Most plant traits in the file are illustrated in the image below, and trait labels are fairly self-explanatory. Keel width measures the span of the pitcher tube. “Wing” traits refer to the lengths of the fishtail appendage.\n\n\n\n\nPhotograph of a Darlingtonia californica pitcher with morphological measurements indicated (lower diameter at ground level not shown). Note the translucent hood and the pronounced fishtail appendage attached to the proximal side of the mouth\n\n\n\n\nUse a MANOVA to consider differences in plant traits (do not follow-up with almost 20 ANOVA’s! Just consider why PCA might be useful with large datasets!\nUse principal component analysis to investigate variation among individual plants in their dimensions. Along the way, make sure you\n\nconstruct screeplots\ndetermine how many principal components to retain (and why)\nUse biplots and/or loadings to see if you can understand/interpret the first few principal components\n\n\n\nUsing the same plant dataset, use linear discriminant analysis to classify the various sites.\nUsing the same plant dataset, use cluster analysis to determine how many clusters are supported by the data.\nThe data for this exercise are rodent species abundance from 28 sites in California (Bolger et al. 1997, Response of rodents to habitat fragmentation in coastal Southern California, Ecological Applications 7: 552–563).\n\nThis data comes from the (website)[http://www.zoology.unimelb.edu.au/qkstats/data.htm) of Quinn and Keough (2002, Experimental Design and Data Analysis for Biologists, Cambridge Univ. Press, Cambridge, UK). Data is available via\n\nrodents &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTLRwuI1cQ61RZOVJFwi0jhO85fonqR7oZHzy_9A5fVwxuZQ2A6iBnlLG2Z-33rwNnycqNUUh1_XuMU/pub?gid=1403553505&single=true&output=csv\", \n                    stringsAsFactors = T)\n\nThe 9 species are indicated by variable (column) names. Genus abbreviations are: Rt (Rattus), Rs (Reithrodontomys), Mus (Mus), Pm (Peromyscus), Pg (Perognathus), N (Neotoma) and M (Microtus). Rattus and Mus are invasive species, whereas the others are native.\n\nAnalyze the dat using correspondence analysis\n\ninterprent any results (loadings!)",
    "crumbs": [
      "Practice problems",
      "Multivariate methods"
    ]
  },
  {
    "objectID": "content/getting_started/getting_started.html",
    "href": "content/getting_started/getting_started.html",
    "title": "Before the first class",
    "section": "",
    "text": "Over the course of the semester/reading this book, our (ambitious) goals are to\nTo prepare for our first few lessons you should follow the basic steps below. Much of this is repeated and expanded in the tools overview.",
    "crumbs": [
      "Getting started",
      "Before the first class"
    ]
  },
  {
    "objectID": "content/getting_started/getting_started.html#concept-stuff",
    "href": "content/getting_started/getting_started.html#concept-stuff",
    "title": "Before the first class",
    "section": "Concept stuff",
    "text": "Concept stuff\n\nCheck out the class website\nWatch this video",
    "crumbs": [
      "Getting started",
      "Before the first class"
    ]
  },
  {
    "objectID": "content/getting_started/getting_started.html#tech-stuff",
    "href": "content/getting_started/getting_started.html#tech-stuff",
    "title": "Before the first class",
    "section": "Tech stuff",
    "text": "Tech stuff\nWe will use R in class to “do” statistics. R is a free, open-source program that is widely used in academia and industry (learning it is a CV or resume skill). It is command-line based, which may be different if you are used to point-and-click programs (graphical user interfaces), but that allows it to be easily saved and shared. We will also store R and related files in multiple places using a process called version control; specifically, we will use github to accomplish this.\n\nGet access to R!. You can make an account at posit Cloud (formerly Rstudio Cloud) (https://posit.cloud/). You can also install R (https://cran.r-project.org/) and Rstudio (https://www.rstudio.com/) on your machine, but I strongly recommend starting with Posit cloud. Rstudio cloud is free for up to 25 hours/month, you don’t have to maintain it, and it gives gives a standard install (same on all machines, so your intro/ our training may be smoother). You can also do both. If you need help, videos are at :\n\nMaking a posit Cloud account (formerly Rstudio Cloud, to be updated but similar process)- this is the recommended approach!\nDownloading R\nDownloading Rstudio\n\nJoin the github classroom we’ll be using for our sessions\n\nlook for email from Blackboard! \nWhen you visit the page it will ask you to connect or create a github repository. You can use any name (be anonymous or not) that you want. This is a free process.\n\n\n\nOptional (get a head start if you want)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio cloud(to be updated for Positcloud, but still basically the same).\nAfter you join the github classroom, you’ll make a clone of the first assignment repository. You can do this on Positcloud or an installed version of Rstudio. I recommend starting with posit Cloud and focus on that process here. First, open Posticloud in one tab/window on your browser (and log in). Next, open github on another tab/window.\nThen, find your copy of the repository on github. You can follow the github classroom link again, or log into github and then visit https://github.com/settings/repositories. Find the repository connected to the assignment. You can go to go to https://github.com/settings/repositories to look for it (you’ll need to sign in to github). For github classroom assignments, the repository will be called assignment_name_YOURGITHUBUSERNAME. Click on it to open the repository page.\n\n\n\nFind your repository @ https://github.com/settings/repositories. Then select it (use the top link!)\n\n\nThis will take you to your repository page. This is a also a chance to note you may want to sync the fork - this catches your copy up to any changes I have made in the assignments or associated files.\n\n\n\nYou can sync up any changes to the original assignment repository by clicking the sync fork button. Note all repositories will not have this option.\n\n\n\n\nWhat’s the difference between clone and fork? Click on the grey triangle\n\nA clone of repository is directly linked up to the original repository. Changes made in one will be pushed or pulled to the others. A fork is different in that it can’t directly communicate. Instead, changes can be synced up using pull requests. github also makes it easy to sync them using the button shown above. Github classroom forks the assignments for each of you, then you makes clones of the forks to work on posit Cloud or your machines.\n\nFrom the repository page, you need to get the url to copy (or clone) the repository. To do this, click on the green Code button from the github page for your repository. Copy the web url (or click the copy icon, two overlapping squares).\n\n\n\nClick on Code to get repository url\n\n\nNow go to the PositCloud tab. Select New Project, New Project from Github repo. You’ll need to enter the url for your github repository (what you copied). Press enter and the project will deploy.\n\n\n\nClick on New Project to clone a repository.\n\n\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!\n\nIf you are using RStudio on your desktop (or via a server…anywhere that\nlooks like an RStudio screen)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio desktop\nTo start working on an assignment, open RStudio.\n\n\n\nSelect File &gt; New Project in Rstudio to start a project\n\n\nSelect file, new project, Version control. On the next screen select git. If this isn’t available, you may need to install git (free) on your system. You can download it at https://git-scm.com/download/.\nNext you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository.\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the Rstudio Repository URL space. You can select/edit what you want the repository to be called and where its stored (its just a folder on your computer). For example, I have a Repositories folder in my main hard drive where I save all of these. Then select Create project. Whatever you choose, the project will be saved in new folder in that location using the name you chose. Note you may need to enter your github username and password to create the repository.\nYou also may get an error/warning about personal access token! this happens at different points on different machines (thus why Rstudio cloud is nice). If you see this now, don’t worry. We’ll cover it (a known issue) in class.\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!",
    "crumbs": [
      "Getting started",
      "Before the first class"
    ]
  },
  {
    "objectID": "content/end_matter/additional_resources.html",
    "href": "content/end_matter/additional_resources.html",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!",
    "crumbs": [
      "End matter",
      "Additional resources"
    ]
  },
  {
    "objectID": "content/end_matter/additional_resources.html#class-related-materials",
    "href": "content/end_matter/additional_resources.html#class-related-materials",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!",
    "crumbs": [
      "End matter",
      "Additional resources"
    ]
  },
  {
    "objectID": "content/end_matter/additional_resources.html#other-resources",
    "href": "content/end_matter/additional_resources.html#other-resources",
    "title": "Additional resources",
    "section": "Other resources",
    "text": "Other resources\nAs noted in the introduction, there are many, many resources that may assist you in your quest to learn statistics and R. Relevant ones are noted throughout the book and listed here.\n\nGeneral R\nPhillips (n.d.)\n\n\nGit help\nHester (n.d.)",
    "crumbs": [
      "End matter",
      "Additional resources"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html",
    "title": "One sample tests for continuous data",
    "section": "",
    "text": "In this chapter will build on our introduction to significance testing by considering tests for continuous data collected on one trait from a single population. This will also allow/require us to more fully define normal distributions, which we have already started to discuss.",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#example",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#example",
    "title": "One sample tests for continuous data",
    "section": "Example",
    "text": "Example\nLet’s return to our iris data and focus on sepal lengths of I. viriginica.\n\nset.seed(42)\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWhat if we wanted to test if the height was equal to a certain value like 7 cm?\nWe can’t, and it’s not.\nHeight is a random variable. It differs among individuals (see above), so it isn’t equal to any specific value. This may seem obvious, but it’s an important step in understanding hypothesis testing. Many students also struggle with this, but most are with the fact we learned about hypothesis testing focusing on proportions (remember the last chapter?). When we focused on binomial data, it was obvious a single draw could not be 2 things - it was a success or failure, and we focused on the relative occurrence of those.\nSimilarly, for continuous numeric data (remember: data that can on any value in a given range), we need to focus on describing the distribution of the data. If we do that, we might want (and be able to test) if, for example, the mean height of I. virginica is equal to 7 cm. In fact, we typically focus on the mean of the distribution (one of measures of central tendency)\nTo do this, we need to do what we did with binomial data: develop a null hypotheses, use it to construct a null distribution, and compare our data to it see how unusual it is (and get a p-value).\n\n\nWhat is our null hypothesis for this example?\n\nFor this example, we are focused on a two-tailed test (we are asking if the mean is equal to a certain value), so we have\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\n\nNow that we have a null hypothesis, we need to test it. We can do this by simulation. Let’s make a distribution where the \\(\\mu_{sepal \\ length} =7 \\  cm\\), then draw samples from it and see how rare it is to get what we actually observed in the data…which was\n\nmean(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\n\n[1] 6.588\n\n\nSeems easy enough, but what distribution do we draw from? For our binomial data we knew exactly what to parameterize - that’s because the entire distribution that fits the null hypothesis is described by the parameter p that is set by the null hypothesis (go back to the last chapter and note we can find the spread using this one variable as well!).\nIf you remember the central limit theorem, you might realize the distribution of the data does not matter in some ways. No matter what it looks like, the means of the data will tend towards normality. However, we still need to describe the data itself it to simulate our draws. We’ll discuss an alternative where you sample from the data itself at the end of this chapter.\nIt turns out the shape of the data itself appears fairly normal. So far we’ve said normal distributions\n\nare roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate\n\n95% of the sample is within \\~2 standard deviations of the mean (and for our mean of means, 95% of the data is within 2 standard errors)\nLook at a density function fit to the data:\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nIt does appear to be fairly symmetric and peaked in the middle. It turns out normal distributions (finally defined below!) are very common in nature.\nJust like the binomial data, a normal distribution can be described using a formula. The formula has 2 parameters that define the shape of the distribution. \\(\\mu\\) defines the center of the distribution, and \\(\\sigma^2\\) describes its spread. The formula for the probabilty density function is\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\ne^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\n\\]\nThis looks complicated, but remember: this is just an equation for describing the likelihood of outcomes in a probability space! The first part \\(\\sqrt{2\\pi\\sigma^2}\\) arises from trying to work with a curve. To understand the rest, lets take the ln of both sides\n\\[\n\\begin{split}\n\\ln(f(x)) = \\ln(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{1}{2\\sigma^2}*(x-\\mu)^2 \\\\\n\\ln(f(x)) = -\\ln(\\sqrt{2\\pi\\sigma^2}) - \\frac{1}{2\\sigma^2}*(x-\\mu)^2\n\\end{split}\n\\]\nThis may not look like it helps much, but we now have the formula for a straight line, \\(y=mx+b\\), where\n\\[\n\\begin{split}\ny= \\ln(f(x)) \\\\\nb = - \\frac{1}{2\\sigma^2}\\\\\nm = -\\ln(\\sqrt{2\\pi\\sigma^2})\\\\\nx =  (x-\\mu)^2\n\\end{split}\n\\]\nIn other words, our independent variable is the squared distance from the mean (so all positive)! Note both the y-intercept (the amplitude) and slope (shape) depends on how spread out the data is (\\(\\sigma^2\\)). Note in general when ln(y) decreases linearly with x, y decreases at a constant proportional rate with x. So we can say a normal random variate is any random variable in which the probability of an observation declines in proportion to its squared deviation from the mean (µ).\nLet’s fit a normal distribution to our data:\n\ncolors &lt;- c(\"PDF from data\" = \"black\", \"normal curve\" = \"red\")\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density(aes(color=\"PDF from data\"))+\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\",\n       color=\"Source\" ) +\nstat_function(fun = dnorm, args = list(mean = mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"]), sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"])), aes(color=\"normal curve\"))+\n      scale_color_manual(values = colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote it fits fairly well, so we’ll use it for our sampling experiment. To do so, we’ll take 50 draws (since we had a sample size of 50) from a normal distribution, find means for each draw, then consider their distribution.\n\nnumber_of_draws &lt;- 50\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_mean\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_mean[i] = mean(rnorm(50, 7, sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"])))\n}\n\nLet’s check out the first few outcomes\n\nhead(sampling_experiment)\n\n  observed_mean\n1      6.977317\n2      7.064034\n3      6.903823\n4      6.984919\n5      7.005049\n6      6.981765\n\n\nand plot them\n\nggplot(sampling_experiment,\n              aes(x=observed_mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed means from 1000 random draws\",\n       x= \"Mean\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow let’s see how that compares to what we actually saw.\n\nsampling_experiment$compare =   ifelse(abs(sampling_experiment$observed_mean-7) &gt;= abs(mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"])-7), 'as or more extreme', 'not as or more extreme')\n\nsampling_experiment$compare &lt;- factor(sampling_experiment$compare)\nlevels(sampling_experiment$compare) &lt;- c(levels(sampling_experiment$compare), \"as or more extreme\")\n\nggplot(sampling_experiment,\n              aes(x=observed_mean, fill=compare)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed means from 1000 random draws\",\n       x= \"Mean\",\n       y= \"Frequency\", \n       fill = \"Sampled mean is ...\") +\n    scale_fill_discrete(drop = FALSE)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nSo in our example simulation, no observed means were as far from the value from the null hypothesis as our sample mean was. This would leave to a p-value of 0 - unusual in some regards, but possible here.",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#another-way-to-compare",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#another-way-to-compare",
    "title": "One sample tests for continuous data",
    "section": "Another way to compare",
    "text": "Another way to compare\nJust like we saw for binomial data, we can always carry out a sampling experiment to find a p-value. However, that’s mainly because we have computers. Even with computers, it would be cumbersome to set up a new sampling experiment for every dataset (which we would need to do for any change in sample size, mean, or standard deviation).\nInstead it would be nice to find a way to replicate the distribution we see above for similar experiments using an equation (just like we did for the binomial data!). One step in doing this relates to how we examine our predictions given our hypotheses. It turns out, we can map our hypotheses to models that explain the variation we see in the data. Our hypotheses (remember\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\nfocus on the mean. They are also stating a prediction for every outcome! Under the null hypothesis, if we were asked to guess the length of a sepal from I. virginica, we would guess 7 cm. Under the alternative hypothesis, we would guess it’s something different than 7. Using our sample, we might instead guess it’s equal to 7 + \\(\\delta\\), where \\(\\delta\\) is estimated from our sample and 7+ \\(\\delta\\) is the mean of our sample.\nFor each hypothesis, we could calculate a measure of related mode fit called the sum squared error from our model, or SSE, where\n\\[\nSSE=sum \\ squared \\ error = \\sum_{i=1}^{n}(Y_i-\\hat{Y_i})^2\n\\]\nHere, \\(Y_i\\) are the data points, and \\(\\hat{Y_i}\\) is our predicted value.\nThis is basically saying we compare the predicted to observed value for each data point for each model (the square exists so things don’t cancel out!). Our null hypothesis corresponds to a simpler view of the world (a reduced or null model), where \\(\\hat{Y_i}\\) is equal to a given value (in our case, 7 cm), whereas under the alternative hypothesis (which corresponds to an alternative or full model), \\(\\hat{Y_i}\\) is equal to a different value (such as 7 + \\(\\delta\\)). The value for \\(\\delta\\) is estimated from our sample and makes the full model larger than the reduced in regard to the number of parameters included in the model.\nWe can then compare the SSE of the 2 models by finding their difference. This is our signal from the data. If we take multiple samples from a known population that is defined by the null hypothesis, we can carry out a very similar sampling to what we did originally.\n\nfor(i in 1:number_of_simulations){\na &lt;- rnorm(50, 7, sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))\nsampling_experiment$observed_mean[i] &lt;- mean(a)\n\nsampling_experiment$SSE_null[i] &lt;-  sum((a-7)^2)\n\nsampling_experiment$SSE_full[i] &lt;- sum((a-mean(a))^2)\n}\n\nsampling_experiment$SSE_difference &lt;- sampling_experiment$SSE_null - sampling_experiment$SSE_full\n\nggplot(sampling_experiment,\n              aes(x=SSE_difference)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed difference in model fit from 1000 draws\",\n       x= \"Mean\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\ndifference_SSE_observed &lt;- sum((iris[iris$Species == \"virginica\",\"Sepal.Length\"]-7)^2)-sum((iris[iris$Species == \"virginica\",\"Sepal.Length\"]-mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))^2)\n\nggplot(sampling_experiment,\n              aes(x=SSE_difference)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed difference in model fit from 1000 draws\",\n       x= \"Mean\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=difference_SSE_observed))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote we never saw as large a difference in the signal our sampling experiment as we did in the data!\n\nnrow(sampling_experiment[sampling_experiment$SSE_difference &gt;=  difference_SSE_observed,])\n\n[1] 0\n\n\nNote this distribution is skewed for a few reasons. Given the square term, it must positive. We also unlikely (given sampling error) that signal will be exactly zero. In fact,since we estimate \\(\\delta\\) from the data itself, the alternative model is almost always a better fit (remember our bias in variance estimates?).\nThis approach accounts for the noise that we see in our data (variation we expect to see in signal values even if the null hypothesis is true) through sampling. However, if we could estimate the noise, we could also divide our signal by it. Accounting for signal and noise let’s us take very different questions in terms of data and use a standardized approach to analyze them. This is because a signal to noise ratio typically follows some distribution.",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#z-test-a-distribution-based-approach",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#z-test-a-distribution-based-approach",
    "title": "One sample tests for continuous data",
    "section": "Z-test: a distribution based approach",
    "text": "Z-test: a distribution based approach\nIn our case, the signal to noise ratio is approximated by the normal distribution! This is an approximate solution to the signal to noise ratio because our means approach a normal distribution as sample size increases - so for non-infinity sample sizes, they may not be perfectly normal!\nWe can show that our signal is simply the mean from our data minus the mean under the null hypothesis, and including \\(\\sigma\\) in the denominator accounts for noise. We can make this more generalizable if we z-transform the data using the formula\n\\[\nz=\\frac{Y - \\mu}{\\sigma}\n\\]\nAfter this transformation, the data is centered at 0 (think about it - if you subtract the mean from all data points…) and has a standard deviation of 1 (because you divided by the standard deviation!). This also makes the mean of transformed data equal to \\(\\delta\\) and the mean under the null hypothesis equal to zero. This also means ~68% of the data points lie between -1 and 1, while ~95% lie between -2 and 2 (since the standard deviation is 1!).\n\n\n\n\n\n\n\n\nFigure 1: ~65% of the data lies with 1 standard deviation of the mean, ~95% lies within 2 standard deviations, and ~99% lies within 3 standard deviations of the mean\n\n\n\n\n\nWe call this specific form of the normal distribution (N(0,1), showing the mean and standard deviation parameters) the Z distribution. Extending on this with some algebra, we can get a Z-score from any data using the equation\n\\[\nz=\\frac{\\bar{x} - \\mu}{\\sigma}\n\\]\nThis transforms a given data point into a z-score on the z, or standard normal, distribution. We can then use the Z distribution to consider how unusual our z-scores are (i.e., get a p-value!). We call the approach that uses this distribution the z-test, and it can be carried out using the z.test function in the BDSA package.\n\nlibrary(BSDA)\nz.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7, \n             sigma.x= sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))\n\n\n    One-sample z-Test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nz = -4.5815, p-value = 4.617e-06\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.411746 6.764254\nsample estimates:\nmean of x \n    6.588 \n\n\nUsing this approach we get a p-value of .000005 - not 0, but very close!\n\nA little history\nAlthough software now provides us exact (approximate) p-values, historically this was far more difficult. For this reason, people took advantage of a transformation so they could use a standardized table like this one.\n\n\n\nExample of z-table. Jsmura, Creative Commons Attribution-Share Alike 4.0 International licence\n\n\nThese tables showed how Z-scores related to p-values. Note these often showed the area to the left of the value, so two-tailed tests required one to multiple the given p-value by 2 (or, if focused on the upper tail, multiply (1-given p-value) by 2 since the distribution is symmetric. Similarly, some tables only had values &lt;0; for those you could find the score whose absolute value corresponed to the observed z-score and multiply the noted p-value by 2 for two-tailed tests .\nFor our example, we got a z score of -4.8515. The table doesn’t even go that low!",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#does-the-distribution-of-the-data-matter",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#does-the-distribution-of-the-data-matter",
    "title": "One sample tests for continuous data",
    "section": "Does the distribution of the data matter?",
    "text": "Does the distribution of the data matter?\nRemember we are focusing on the distribution of the means (both our sampling experiment and SSE calculations include the means of the sample and data under the null hyothesis!). Given that and the central limit theorem, does the distribution of the data matter? Yes, but only in regards to the relationship between sample size and normality of the sample means. If the underlying data is normal, then the sampled means are distributed normally for almost any sample size, although sample size impacts the spread of the sample means.\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 2: Means drawn from a normal distribution are normal regardless of sample size\n\n\n\n\n\nFor other distributions, larger sample sizes are required to approximate normality. For example, consider a highly-peaked (double-exponential) distribution\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nor as skewed \\(\\chi^2\\) distribution (here with a df =4, to be explained later!):\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nEven for these very non-normal distributions, the means approach a normal distribution at fairly low sample sizes. This is even true for binomial data, especially when p is not very close to 0 or 1. Consider\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThis is why it used to be more common to use a normal approximation to the binomial distribution - even though the binomial distribution is easy to compute,the z is even easier! For example, Sandidge (Sandidge 2003) noted that brown recluse spiders chose dead prey items (as opposed to live - 2 categories!) when offered choices. This data could be assessed using a binomial test\n\n binom.test(119,(59+41+41), p=.5)\n\n\n    Exact binomial test\n\ndata:  119 and (59 + 41 + 41)\nnumber of successes = 119, number of trials = 141, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.7733542 0.8995595\nsample estimates:\nprobability of success \n             0.8439716 \n\n\nor a z-test approach by finding a z-sore\n\n p=.5\n n=41+41+59\n z_score &lt;- (119-p*n)/sqrt(n*p*(1-p))\n pnorm(z_score, lower.tail = F) *2\n\n[1] 3.11282e-16\n\n\nor a \\(\\chi^2\\) test, which is similar to a z test but focuses on a sum of independent squared Z variates. The \\(\\chi^2\\) distribution is defined by a degrees of freedom, or df, parameter, which in this case isequal to the number of categories -1 (or 2-1=1 in this case). We will return to df multiple times! Note the p-values obtained from the Z and \\(\\chi^2\\) tests are the same!\n\nchisq.test(c(119,n-119))\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(119, n - 119)\nX-squared = 66.73, df = 1, p-value = 3.113e-16\n\n\nThis may seem esoteric, but understanding these issues may help you interpret older papers while also choosing to employ more modern statistical methods.\n\nQQ norm plots - commonly used, but not needed, at this point!\nIn addition to considering the sample size and underlying distribution, quantile-quantile (Q-Q) plots are sometimes used to assess normality. These plots plot quantiles in one data set against quantiles from another to determine if they come from similar distribution. Remember, quantiles just order data; percentiles are example where you have 100 cut points. Q-Q norm plots consider if a given dataset are similar to a normal distribution. If so, then the dots should match the straight line produced by the qqline function.\n\nqqnorm(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\nqqline(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\n\n\n\n\n\n\n\n\nWhile we introduce Q-Q plots here, and they are often used to assess normality, remember our tests (so far) are relying on the means of the data being normally-distributed and not the data itself!",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-know-the-variance",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-know-the-variance",
    "title": "One sample tests for continuous data",
    "section": "What if we don’t know the variance?",
    "text": "What if we don’t know the variance?\nAssuming everything above makes sense, we are left with one issue: the variance of the underlying population is rarely known!\nIn the above examples, we actually used our estimate of variance from the sample to run our simulation experiment and z-test! While this works ok for large sample sizes (yay for central limit theorem!) and is what statisticians relied upon historically, it doesn’t work for well for smaller sample sizes (unless we somehow know the population variance). Our estimates for the population variance are less precise and potentially biased at small sample sizes.\nTo address this issue, statisticians developed the t-distribution. Unlike the normal distribution, its shape depends on the sample size. This parameter is coded as degrees of freedom, commonly denoted as df, and is equal to n - 1 (we’ll come back to df later!). The major breakthrough, however, was that df was the only sample-specific parameter. The same distribution works regardless of the estimated population variance, as a t statistic/score is created that functions like a z score.\n\\[\nt=\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\]\nIt can be shown (though not here!) that the t-distribution is actually a specific form of the F distribution (which we’ll see in ANOVAs). An F-distribution is the ration of two \\(\\chi^2\\) distributions, which (as noted above) are sums of squared Z distributions. The t distribution is the special case where you can take the square of an F distribution where the numerator (top) \\(\\chi^2\\) distribution has 1 degree of freedom and the denomintor (bottom) has n-1 degrees of freedom. In general, variance follows a \\(\\chi^2\\) distribution with n-1 degrees of freedom.\nBecause it directly uses the estimate of the population variance, smaller sample sizes show more spread (and thus make null hypotheses more difficult to reject!). For example, note how small sample sizes (remember, df=3 means n=4!) are notably different from the normal distribution, while larger sample sizes become very hard to distinguish!\n\n\n\n\n\n\n\n\n\nNote this means the t-distribution is actually a class of distributions.\nIn older text books, you would have a t-table that showed t scores corresponding to commonly used values of \\(\\alpha\\) for multiple degrees of freedom. These published t scores are sometimes called critical values. Users would have compared their calculated t-score (or its absolute value in the case of negative values) to the appropriate critical values (often \\(\\alpha/2\\) for 2-sided tests) to determine if a finding was significant. We can actually produce a t table in R.\n\ndf &lt;- 1:100\ncut_offs &lt;- c(\".1\", \".05\", \".025\", \".01\")\nt_table &lt;- setNames(data.frame(matrix(ncol = length(cut_offs)+1, nrow = length(df))), c(\"df\",cut_offs))\nt_table$df &lt;- df\nfor (i in 1:length(df)){\n  for (j in 2:ncol(t_table))\n  t_table[i,j] &lt;- round(abs(qt(as.numeric(colnames(t_table)[j]), df[i])),3)\n}\nlibrary(rmarkdown)\npaged_table(t_table)\n\n\n\n\n\n\n\n\nFigure 3: Critical values\n\n\n\n\nTo calculate the test statistic in R, we can instead (thankfully!) use the t.test function.\n\nt.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7)\n\n\n    One Sample t-test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nt = -4.5815, df = 49, p-value = 3.195e-05\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.407285 6.768715\nsample estimates:\nmean of x \n    6.588 \n\n\nNote the t-test also provides confidence intervals. Note these consider the spread of the data given the t-distribution so they are always wider than those predicted using a normal distribution, though the difference is small at large sample sizes.\nThis explains why I have noted ~95% of the data lies within 2 standard errors of the mean! For truly normal data, it’s actually within 1.96 standard errors. For data where we estimate the population variance, it depend on the sample size, but even at n=21 (and thus df = 20!) the number is 2.09. Note\n\nt_critical &lt;- setNames(data.frame(matrix(ncol = 2, nrow = length(sample_size))), c(\"n\", \"95% of the data is within this many standard deviations of the mean\"))\nfor (i in 1:length(sample_size)){\nt_critical$n[i] &lt;- sample_size[i]\nt_critical[i,2] &lt;-qt(.025,as.numeric(sample_size[i]))\n}",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-trust-the-normal-approximation",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-trust-the-normal-approximation",
    "title": "One sample tests for continuous data",
    "section": "What if we don’t trust the normal approximation?",
    "text": "What if we don’t trust the normal approximation?\nDespite the central limit theorem (or because of it), we may not think our sample size is sufficient given the distribution the data to assume that \\(\\hat{Y}\\) really follows a normal distribution. In that case we a few options.\n\nWilcoxon test (aka, signed binary-transform, Fisher’s sign test)\nIf the distribution of the data is symmetric, a Wilcoxon test may be appropriate. Note it is rare to have data that are symmetrically distributed but that for which you don’t think th means will be normally distributed). We introduce the test here as it will come back up (and be more useful) in later chapters.\nThis test employs a strategy we will see again and again: it ranks the data, in this case based on the distance from the mean under the null hypothesis. A sign is also assigned to each rank, with those originating from data points that were lower than the proposed mean becoming negative. In theory, the sum of the signed ranks should be ~0 if HO is true. We can carry out this test in R using the wilcox.test function.\n\nwilcox.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nV = 241.5, p-value = 0.0001312\nalternative hypothesis: true location is not equal to 7\n\n\n\n\nSign test (aka the median test)\nIf the data are not symmetrically distributed, the sign test actually just counts those below the proposed value (which is the median here instead of the mean, since we are concerned about normality). In theory, approximately half the values should be under the proposed mean if HO is true. The proportion below is compared to .5 using a binomial test.\n\nSIGN.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], md = 7)\n\n\n    One-sample Sign-Test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\ns = 12, p-value = 0.0003059\nalternative hypothesis: true median is not equal to 7\n95 percent confidence interval:\n 6.3 6.7\nsample estimates:\nmedian of x \n        6.5 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt U.E.pt\nLower Achieved CI     0.9351    6.3    6.7\nInterpolated CI       0.9500    6.3    6.7\nUpper Achieved CI     0.9672    6.3    6.7\n\n\n\n\nBootstrapping\nThe final option we will review is a little different. For all our other hypothesis tests we’ve been resampling from a distribution that fits the parameters from the null hypothesis. However, its turns out we can resample from the actual data we collected to approximate the distribution of the sample (or the signal in most cases). You can then use that distribution to develop confidence intervals or hypothesis testing. The only requirement here is we have a large enough sample size to actually appropriately sample from (and that we have the means to do it!). This approach was developed in the 1990s given the increase in computing power and availability.\nWe can demonstrate this with an imaginary population (and also demonstrate the central limit theorem). Let’s make a population whose trait value of focus falls between 60 and 80 in a uniform manner.\n\npopulation_unif &lt;- data.frame(id = 1:10000, \n                              value = runif(10000, 60, 80))\nggplot(population_unif, aes(x=value)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow’s let’s take samples of 50 from it a lot of times (1000 here) and plot the means of these samples.\n\nsampling_experiment&lt;- data.frame(\"observed_mean\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_mean[i] &lt;- mean(sample(population_unif$value,50, replace = F))\n}\nggplot(sampling_experiment, aes(x=observed_mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Means from imaginary samples of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow let’s instead think of what might happen - we get a single sample of 50.\n\nactual_sample &lt;- data.frame(sample = sample(population_unif$value,50, replace = F))\nggplot(actual_sample, aes(x=sample)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Actual sample of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow (here’s the odd part): Let’s sample from that sample with replacement to get “new” samples, then get those means, again, 1000 times.\n\nbootstrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\nexample_bootstrap &lt;-sample(actual_sample$sample, length(actual_sample$sample), replace = T)\nbootstrap_outcomes$mean[i] &lt;- mean(example_bootstrap)\nbootstrap_outcomes$sd[i] &lt;- sd(example_bootstrap)\n}\n\nWhen we plot them we see it looks very much like the distribution of means we obtained by re-sampling!\n\nggplot(bootstrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Bootstrapped means of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nOverall, this means we can use our sample to recreate our underlying distribution and explore its properties!\nLet’s demonstrate this approach with our iris data. First, we can make “new” datasets from our original data by sampling (with replacement) samples of the same size from our original dataset.\n\nbootstrap_data&lt;- iris[iris$Species == \"virginica\",\"Sepal.Length\"]\nbootstrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\niris_bootstrap &lt;-sample(bootstrap_data, length(bootstrap_data), replace = T)\nbootstrap_outcomes$mean[i] &lt;- mean(iris_bootstrap)\nbootstrap_outcomes$sd[i] &lt;- sd(iris_bootstrap)\n}\nggplot(bootstrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means of sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Mean sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe again (thanks to the central limit theorem) see the means follow a normal distribution.\nWe can also carry this out using the boot function (in the boot package), though the functions may look a little odd.\n\nlibrary(boot)\nresults &lt;- boot(data=bootstrap_data, statistic = function(x, inds) mean(x[inds]),\n   R=number_of_simulations)\nggplot(data.frame(results$t), aes(x=results.t)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means of sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Mean sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nand then find the 95% confidence interval. Like binomial data, there are a few ways to do this. One is to use the percentile, or quantile, method. This is intuitive. We rank the bootstrapped values from smallest to largest and then find points that cut off the bottom and top 2.5%.\n\nquantile( results$t, probs=c(.025, .975) ) \n\n  2.5%  97.5% \n6.4219 6.7781 \n\n\nThough simple, these findings may also be biased. More advanced intervals are provided the boot.ci function.\n\nboot.ci(results)\n\nWarning in boot.ci(results): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 6.410,  6.761 )   ( 6.394,  6.758 )  \n\nLevel     Percentile            BCa          \n95%   ( 6.418,  6.782 )   ( 6.416,  6.778 )  \nCalculations and Intervals on Original Scale\n\n\nThe boot.t.test function in the MKinfer package offers another way to calculate bootstrap statistics for single-sample continuous data. It returns the percentile confidence intervals and also offers a p value.\n\nlibrary(MKinfer)\nboot.t.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7)\n\n\n    Bootstrap One Sample t-test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nbootstrap p-value &lt; 2.2e-16 \nbootstrap mean of x (SE) = 6.589584 (0.08854959) \n95 percent bootstrap percentile confidence interval:\n 6.418 6.764\n\nResults without bootstrap:\nt = -4.5815, df = 49, p-value = 3.195e-05\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.407285 6.768715\nsample estimates:\nmean of x \n    6.588",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#next-steps",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#next-steps",
    "title": "One sample tests for continuous data",
    "section": "Next steps",
    "text": "Next steps\nNow that we’ve covered dealing with categorical and continuous data, we will move to comparing populations to each other.",
    "crumbs": [
      "Chapters",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html",
    "href": "content/chapters/Relationships_among_numerical_variables.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "In the last chapter we extended linear models to consider impacts of multiple factors. Continuing that tradition, we will now explore how numerical (and specifically continuous) predictor variables can be used to explain variation in numerical outcome variables.",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#back-to-the-iris-data",
    "href": "content/chapters/Relationships_among_numerical_variables.html#back-to-the-iris-data",
    "title": "Relationships among numerical variables",
    "section": "Back to the iris data",
    "text": "Back to the iris data\nWe will motivate this with an example from our favorite iris data. So far we have considered how species impacts measured outcomes. However, we might also want to consider the relationship between traits. For example, we might want to know if sepal and petal length are related. We could plot the data:\n\nlibrary(ggplot2)\nsepal_petal_relationship &lt;- ggplot(iris, aes(y=Sepal.Length, x=Petal.Length)) +\n  geom_point() +\n  labs(title=\"Sepal length increases with petal length\",\n       y= \"Sepal length (cm)\",\n       x= \"Petal Length (cm)\")\nsepal_petal_relationship\n\n\n\n\n\n\n\n\nOur related hypothesis might be a relationship exists among the variables; alternatively, one does not. To put this our null hypothesis framework, we might write:\n\\[\n\\begin{split}\nH_O: \\textrm{there is not a relationship between sepal and petal length}\\\\\nH_A: \\textrm{there is a relationship between sepal and petal length}\\\\\n\\end{split}\n\\]\nIn other words, we need to gather enough evidence to reject the hypothesis of no relationship. Note we will formalize these hypotheses more in a moment, but how do we test them?\n\nWorking with continuous predictors\nFor some background, consider differences between continuous and categorical predictor variables. Unlike examples of when we transformed continuous outcomes into binomial data, continuous predictors offers information on order and spacing. Compared to un-ordered categorical variables (what we’ve focused on), the numbers mean something! This allows us (with caution) to estimate outcomes from un-sampled regions.\nConsider: We know the mean sepal lengths for three species of irises:\n\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\n\n\n\n\nBut if we find a new species, we actually don’t know what to expect!\nHowever, if we have this graph\n\nsepal_petal_relationship\n\n\n\n\n\n\n\n\nWe might have a guess of the petal length of a flower that has a sepal length of 2.5 cm even though we didn’t measure anything of that size. In fact, you might be able to visualize the relationship:\n\nsepal_petal_relationship+geom_smooth(method = \"lm\",se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWhile we can draw this “line of best fit” by sight, linear models actually give us a way to formally define it (analyze our hypothesis). The line of best fit minimizes the residuals (which means it also offers a prediction any value of sepal length!). This approach, however, also means we are considering linear relationships between our predictor variables (but note our predictor variables themselves could be a transformation of an actual measurement, such as a square root or value cubed!). This is one assumption of linear regression. We can consider non-linear relationships using other techniques (which we will cover later).\nIf we wanted to carry out a sampling experiment to determine a p-value for our hypotheses, we could sample from a population that represents our sepal lengths and one that represents our petal lengths. If the two populations are not connected, then arbitrary pairs could be made - this would indicate no relationship among the variables. For each dataset, we could note the potential relationship (now occuring by chance!) between our variables, and then compare that null distribution to what we actually observed. To make this approach more generalizable, we could standardize our data points - using these to calculate our error terms for full and reduced models would lead us to F distributions.\nOverall, this means we can use a linear model approach to investigate relationships among numerical variables. We can build the model\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\n\nand see the impacts on our linear model.\nThe relationship between our two variables is noted in the model matrix, which now includes our actual values,\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(iris_regression)))\n\n\n  \n\n\n\nand a coefficient that shows their relationship. The first parameter is the x-intercept, and the second (the relationship) is the slope of the best fit line!\n\nmatrix(as.numeric(iris_regression$coefficients), ncol=1)\n\n          [,1]\n[1,] 4.3066034\n[2,] 0.4089223\n\n\nOnce the model is made, we can plot it to check assumptions\n\nplot(iris_regression)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor numerical relationships we typically see more of a cloud of data, but we are still assuming the residuals are normally distributed (with the same variance for all fitted values, i.e. identically distributed) and indepent. Iassumptions are met consider outcomes.\n\nlibrary(car)\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\nHere the ANOVA table tells us there is a significant impact of sepal length on petal length, and the summary (and graph) demonstrate that relationship is positive. Note we do not need any post-hoc analysis (why not?).",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#regression-or-correlation",
    "href": "content/chapters/Relationships_among_numerical_variables.html#regression-or-correlation",
    "title": "Relationships among numerical variables",
    "section": "Regression or correlation",
    "text": "Regression or correlation\nThis approach, with small changes in theory, can be used for two scenarios. We typically consider (but actually rarely use) linear regression. Linear regression technically assumes that an approach was used to determine how one variable impacts another (so we chose which one to vary and how). For this scenario, our sampling experiment technically uses the set values of the predictor variable,and our hypotheses focus on the coefficient value\n\\[\n\\begin{split}\nH_O: \\beta_\\textrm{(coefficient between sepal and petal length)} = 0\\\\\nH_A: \\beta_\\textrm{(coefficient between sepal and petal length)} \\neq 0\\\\\n\\end{split}\n\\]\nNote our coefficient will also change based on measurement units, but this should not impact the resulting p-value.\nThe other approach, correlation, is more simply measuring association between the variables. It’s not specifying which, if either, is the driver - both variables could be responding to an un-measured variable. For example, since we simply observed flower traits, we could easily reverse everything above (plot shown here).\n\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point() +\n  labs(title=\"Petal length increases with sepal length\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\n\n\n\n\nNote that doing so would change the coefficients in our linear model,but not the direction of the relationship. For this reason, correlation often focuses on a unitless correlation parameter, r, instead of a coefficient from our \\(\\beta\\) matrix.\n\\[\n\\begin{split}\nH_O: r_\\textrm{(association between sepal and petal length)} = 0\\\\\nH_A: r_\\textrm{(association between sepal and petal length)} \\neq 0\\\\\n\\end{split}\n\\]\nr can vary from -1 (values are perfectly negatively related) to 1 (values are perfectly positively related), where 0 indicates no associatoin. This should sound familiar (hold this thought). For a related sampling experiment, populations for both traits are simulated and then paired (what we described above!).\nThe correlation coefficient can be calculated in R using the cor.test function; note the formula interface is different to reflect association.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nNote that the output also gives us a confidence interval and estimate for r in addition to a p-value. If we square the provided r value, we get the R2 output we have previously described in our linear model summary.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)$estimate^2\n\n      cor \n0.7599546 \n\nsummary(iris_regression)$r.squared\n\n[1] 0.7599546\n\n\n\nOther options\nIf our assumptions are not met, we have a few options. You may have noticed the cor.test function provided a Pearson’s product-moment correlation. This is one approach that uses the raw data. Another approach, the Spearman rank correlation, uses (surprise) ranked data. This relaxes the assumption of normality and only assumes monotonic relationships (one variable increases or decreases with the other). We can use it by updating the arguments in the cor.test function.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris, method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\nBootstrapping and permutation options also exist. Some of these use the same functions we’ve encountered before. For example, we can do permutation tests using the coin package.\n\nlibrary(coin)\nindependence_test(Sepal.Length ~ Petal.Length, iris)\n\n\n    Asymptotic General Independence Test\n\ndata:  Sepal.Length by Petal.Length\nZ = 10.641, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nBootstrapping may be done using the boot or other packages. For example, the boot function in the car package gives an easy wrapper for boot.\n\nlibrary(car)\nbootstrap_iris &lt;- Boot(iris_regression)\nsummary(bootstrap_iris)\n\n\nNumber of bootstrap replications R = 999 \n             original    bootBias   bootSE bootMed\n(Intercept)   4.30660 -0.00169310 0.072903 4.30130\nPetal.Length  0.40892  0.00050629 0.019520 0.41004\n\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate     2.5 %    97.5 %\n(Intercept)  4.3066034 4.1775836 4.4599032\nPetal.Length 0.4089223 0.3685134 0.4468301",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#a-little-more-on-assumptions",
    "href": "content/chapters/Relationships_among_numerical_variables.html#a-little-more-on-assumptions",
    "title": "Relationships among numerical variables",
    "section": "A little more on assumptions",
    "text": "A little more on assumptions\nAlthough our linear models all have the same assumptions, numerical predictors add a few new wrinkles. For numerical predictors, outliers may be more of an issue. Outliers may be used a general term to focus on a data point that is different from the rest of the dataset, but only certain types of outliers matter.\nFor example, let’s pretend we realized our iris dataset was missing 3 rows and add them back in.\n\niris_new &lt;- iris\niris_new$Source &lt;- \"original\"\niris_new$label &lt;- NULL\n#make outlier\niris_outlier &lt;- data.frame(Petal.Length = c(2.5,12, 12.1),\n                           Sepal.Length = c(5.4,8.9, 3), \n                           Source = \"new\",\n                           label = c(\"A\",\"B\", \"C\"))\niris_merged &lt;- merge(iris_new, iris_outlier, all = T)\niris_merged &lt;- iris_merged[order(iris_merged$Source, decreasing = T),]\nrownames(iris_merged) &lt;- 1:nrow(iris_merged) \n\niris_merged$row_number &lt;- 1:nrow(iris_merged)\n\nggplot(iris_merged, aes(x=Petal.Length, y=Sepal.Length, color=Source)) +\n  geom_point() +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Sepal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       y= \"Sepal length (cm)\",\n       x= \"Petal Length (cm)\")\n\n\n\n\n\n\n\n\nOur 3 “new” points (rows 151-153) are all unique ins some way. 152 is from a relatively unsampled region of the graph that is within the range of existing data. 151 and 153 are also from un-sampled regions, but these are outside of the original range. More importantly, note if we fit the data without these points\n\nggplot(iris_merged, aes(y=Sepal.Length, x=Petal.Length, color=Source)) +\n  geom_point() +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Sepal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       subtitle = \"Best fit based on original data only!\",\n       y= \"Sepal length (cm)\",\n       x= \"Petal Length (cm)\") +\n  geom_smooth(data=iris_new[iris_new$Source == \"original\",], method = \"lm\", fullrange=T, se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nWe see that only row 151 appears to be different than what we would expect given the rest of the data. Now, note if we fit a model all these points and check assumptions\n\niris_regression_new &lt;- lm(Sepal.Length ~ Petal.Length, iris_merged)\nplot(iris_regression_new)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nseveral plots label row 151. In general, R provides the row number of the most “unusual” rows in each graph. This may mean a fairly normal row that just so happens to be the “most” extreme in a dataset is labelled. However, here we see row 151 falling outside the dotted lines that are labelled Cook’s distance in the 4th graph. Cook’s distance is one way of quantifying leverage, or how much a single point shifts the best fit line. The measure quantifies change in the regression coefficients if each data point is removed individually. Here we see row 151 is a high leverage point, while 153 is not even though the sepal length itself may be an outlier.\nAlthough row 153 is not identified as a high leverage point, it is impacting the line (as are all other points). Our best fit line will always go though the point \\((\\bar{x}, \\bar{y})\\), so outliers in the “x” variable will impact the line. This also explains why the confidence region (which we won’t calculate here), gets “smaller” in the middle of the data range.\n\nggplot(iris_merged, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(aes(color=Source)) +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Sepal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       subtitle = \"Grey area is confidence region, with mean point shown in purple!\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\") +\n  geom_smooth( method = \"lm\", fullrange=T, se=T)+\n  geom_point(aes(x=mean(iris_merged$Sepal.Length), y=mean(iris_merged$Petal.Length)), color=\"purple\")\n\nWarning: Use of `iris_merged$Sepal.Length` is discouraged.\nℹ Use `Sepal.Length` instead.\n\n\nWarning: Use of `iris_merged$Petal.Length` is discouraged.\nℹ Use `Petal.Length` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThis all the further you get from the mean, the wider your confidence interval will be for an estimate. Even more importantly, estimating points outside your data range is likely a bad idea.",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#plotting-outcomes",
    "href": "content/chapters/Relationships_among_numerical_variables.html#plotting-outcomes",
    "title": "Relationships among numerical variables",
    "section": "Plotting outcomes",
    "text": "Plotting outcomes\nAs shown above, numerical data is often plotted via paired points. You can also add regression lines with or without confidence regions.",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#next-steps",
    "href": "content/chapters/Relationships_among_numerical_variables.html#next-steps",
    "title": "Relationships among numerical variables",
    "section": "Next steps",
    "text": "Next steps\nIn the next chapters we will carry our linear model approach to consider the relationship between continuous outcomes and continuous predictor variables.",
    "crumbs": [
      "Chapters",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html",
    "href": "content/chapters/More_ANOVAs.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "In the last chapter we introduced the idea of comparing means among populations (one-way ANOVAs, our first linear models). However, the units that we measure may belong to multiple groups. We will extend our analysis of variance to consider multiple group membership and interactions in this chapter. As a starting point, consider that group membership may be an inherent property of the unit we measure or we may assign it.",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#example-back-to-the-birds",
    "href": "content/chapters/More_ANOVAs.html#example-back-to-the-birds",
    "title": "More ANOVAs",
    "section": "Example: Back to the birds",
    "text": "Example: Back to the birds\nOne of the last chapters practice problems focused bird feathers. While studying feather color in Northern flickers (Colaptes auratus), Wiebe and Bortolotti (2002) noted that ~25% of birds had one or more “odd” tail feathers. They decided to compare the color of these odd and “typical” feathers.\n\n\n\nNorthern Flicker. Mike’s Birds, CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&gt;, via Wikimedia Commons\n\n\nExample and data provided by McDonald (2014).\n\nlibrary(rmarkdown)\npaged_table(feather)",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#how-do-we-analyze-this-data",
    "href": "content/chapters/More_ANOVAs.html#how-do-we-analyze-this-data",
    "title": "More ANOVAs",
    "section": "How do we analyze this data?",
    "text": "How do we analyze this data?\nWe may first note that we have a continuous measurement (feather color, measured using color hues from a digital camera and another statistical technique that we will not go into here) and a categorical variable (feather type, with levels “typical” and “odd”). This hopefully reminds you of an ANOVA/t-test!\nWe could plot the data\n\nlibrary(ggplot2)\nggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type))+\n  geom_jitter()+\n  labs(y= \"Color index\",\n       x= \"Feather type\",\n       title=\"Comparing odd and typical feathers in Northern flickers\")+\n  guides(color=F)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\n\n\n\nDevelop a set of hypotheses:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{odd feather color}} = \\mu_{\\textrm{typical feather color}}\\\\\nH_A: \\mu_{\\textrm{odd feather color}} \\neq \\mu_{\\textrm{typical feather color}}\\\\\n\\end{split}\n\\]\nand test them using a t-test:\n\nt.test(Color_index ~ Feather_type, data=feather)\n\n\n    Welch Two Sample t-test\n\ndata:  Color_index by Feather_type\nt = -3.56, df = 29.971, p-value = 0.00126\nalternative hypothesis: true difference in means between group Odd and group Typical is not equal to 0\n95 percent confidence interval:\n -0.21579254 -0.05845746\nsample estimates:\n    mean in group Odd mean in group Typical \n            -0.176125             -0.039000 \n\n\nor, using more generalizable functions, a linear model:\n\nlibrary(car)\nAnova(lm(Color_index ~ Feather_type, data=feather), type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  0.49632  1  41.816 3.814e-07 ***\nFeather_type 0.15043  1  12.674  0.001259 ** \nResiduals    0.35607 30                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe find a significant p value, but we did not check assumptions. For linear models (remember, $i.i.d. N(,)$, we could use our visual checks\n\nplot(lm(Color_index ~ Feather_type, data=feather))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich appears ok, but there is a problem.\nOur data are not independent!",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#lack-of-independence",
    "href": "content/chapters/More_ANOVAs.html#lack-of-independence",
    "title": "More ANOVAs",
    "section": "Lack of Independence",
    "text": "Lack of Independence\nOdd and typical feathers were measured on a single bird (note the Bird column) in the dataset. We might assume feathers on a given bird are more closely related in color than feathers on different birds. This could be due to diet or other factors making all feathers on a given bird brighter or darker than those on another. Regardless of reason (and “good” p value), we know the measurements are linked in some way. Note we could “connect” individual observations.\n\nggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type, group=Bird))+\n  geom_line(position = position_dodge(0.4), color=\"black\") +\n  geom_point(position = position_dodge(0.4)) +  \n  labs(y= \"Color index\",\n       x= \"Feather type\",\n       title=\"Comparing odd and typical feathers in Northern flickers\")+\n  guides(color=F)\n\n\n\n\n\n\n\n\nThis may also occur if we measure outcomes with-in a single unit (e.g., a study of fertilizer impacts using multiple fields) or over time (e.g., before/after studies). Regardless of the reason, when our experimental design has led to measurements being connected/not independent, we need to consider these connections in order to properly note (and sometimes even observe) impacts of focal variables.",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#blocking-two-way-anovasand-paired-t-tests",
    "href": "content/chapters/More_ANOVAs.html#blocking-two-way-anovasand-paired-t-tests",
    "title": "More ANOVAs",
    "section": "Blocking, two-way ANOVAs,and paired t-tests",
    "text": "Blocking, two-way ANOVAs,and paired t-tests\nIn this case, the connections may be considered artifacts of the data. We didn’t assign birds. We also made a choice to compare odd and typical feathers from the same bird - why? In general, accounting for extra variation in the data will give you a better answer about how a given variable influences outcomes. This may be called blocking. Although the motivation might therefore be to get a “better” p value, it should be driven by experimental design (and thus we started with an example where we didn’t “need” to account for it to achieve significance).\nIn order to consider how color differs by bird and feather type, we need to add both variables to our linear model. For each variable we add, we also add a null (and corresponding alternative) hypothesis. So we retain our focus on feather type:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{odd feather color}} = \\mu_{\\textrm{typical feather color}}\\\\\nH_A: \\mu_{\\textrm{odd feather color}} \\neq \\mu_{\\textrm{typical feather color}}\\\\\n\\end{split}\n\\]\nbut also add a set of hypotheses focused on birds:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{color of bird A}} = \\mu_{\\textrm{color of bird B}}....\\textrm{for all birds}\\\\\nH_A: \\mu_{\\textrm{color of bird A}} \\neq \\mu_{\\textrm{color of bird B}}....\\textrm{for all birds}\\\\\n\\end{split}\n\\]\nWe can analyze this using our linear model approach. This is possible because, as we noted earlier, we can subdivide variance among multiple levels. Under the hood, the linear model approach build a model matrix that considers the impact of feather type and bird on outcomes. Since both variables are categorical, this is often called a two-way ANOVA. First, let’s make the object\n\ntwo_way_anova_example &lt;- lm(Color_index ~ Feather_type + Bird, data=feather)\n\n\n\nYou can see the new model matrix and coefficients if you want\n\nNote the model matrix now includes columns for feather type and bird (lots of dummy variables, and now intercept is Bird A’s odd feather!). The \\(\\beta\\) matrix of coefficients has corresponding estimates.\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(two_way_anova_example)))\n\n\n  \n\n\nmatrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n            [,1]\n [1,] -0.3580625\n [2,]  0.1371250\n [3,]  0.0905000\n [4,]  0.0450000\n [5,]  0.1250000\n [6,]  0.2535000\n [7,]  0.2575000\n [8,]  0.1500000\n [9,]  0.2525000\n[10,]  0.2885000\n[11,]  0.2150000\n[12,]  0.2530000\n[13,]  0.1445000\n[14,]  0.1365000\n[15,]  0.2190000\n[16,]  0.2530000\n[17,]  0.2275000\n\n\nSo for our first observation, which is\n\nfeather[1,]\n\n  Bird Feather_type Color_index\n1    A      Typical      -0.255\n\n\nOur estimate is the intercept (since it’s bird A) and the typical feather:\n\nmodel.matrix(two_way_anova_example)[1,] %*% matrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n           [,1]\n[1,] -0.2209375\n\n\nand thus our residual is\n\ntwo_way_anova_example$residuals[1]\n\n         1 \n-0.0340625 \n\n\nwhich is the same as\n\nfeather[1,]$Color_index-model.matrix(two_way_anova_example)[1,] %*% matrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n           [,1]\n[1,] -0.0340625\n\n\n\nThen check the assumptions\n\nplot(two_way_anova_example)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote, visually speaking, the residuals do appear to be closer to normal now. Since assumptions look ok, we can analyze the outcome\n\nsummary(two_way_anova_example)\n\n\nCall:\nlm(formula = Color_index ~ Feather_type + Bird, data = feather)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.12444 -0.05209  0.00000  0.05209  0.12444 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -0.35806    0.06955  -5.148 0.000119 ***\nFeather_typeTypical  0.13712    0.03374   4.065 0.001017 ** \nBirdB                0.09050    0.09542   0.948 0.357936    \nBirdC                0.04500    0.09542   0.472 0.643998    \nBirdD                0.12500    0.09542   1.310 0.209903    \nBirdE                0.25350    0.09542   2.657 0.017950 *  \nBirdF                0.25750    0.09542   2.699 0.016505 *  \nBirdG                0.15000    0.09542   1.572 0.136802    \nBirdH                0.25250    0.09542   2.646 0.018330 *  \nBirdI                0.28850    0.09542   3.023 0.008554 ** \nBirdJ                0.21500    0.09542   2.253 0.039643 *  \nBirdK                0.25300    0.09542   2.651 0.018139 *  \nBirdL                0.14450    0.09542   1.514 0.150719    \nBirdM                0.13650    0.09542   1.431 0.173069    \nBirdN                0.21900    0.09542   2.295 0.036567 *  \nBirdO                0.25300    0.09542   2.651 0.018139 *  \nBirdP                0.22750    0.09542   2.384 0.030759 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09542 on 15 degrees of freedom\nMultiple R-squared:  0.7304,    Adjusted R-squared:  0.4427 \nF-statistic: 2.539 on 16 and 15 DF,  p-value: 0.03923\n\nAnova(two_way_anova_example, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df F value   Pr(&gt;F)    \n(Intercept)  0.24133  1 26.5059 0.000119 ***\nFeather_type 0.15043  1 16.5214 0.001017 ** \nBird         0.21950 15  1.6072 0.184180    \nResiduals    0.13657 15                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote we see a significant difference in color among birds and feather type. Although we may be tempted to (and could) use post-hoc tests to consider which birds are different than which others, this is typically not done for blocked variables. We did not assign these pairings and it is not the focus of our efforts.\nSince we only had 2 types of feathers, we also don’t need post-hoc tests. A significant p value means they differ from each other, and the estimates provided by the summary command indicate the typical feathers have a higher color index.\n\nt-test connections\nWhen we have only two measurements per group (e.g., odd and typical feathers from each bird), we can use a t-test approach to achieve similar goals. This approach is known as a paired t-test. Instead of focusing on the difference in means (like a 2-sample t-test), the test focuses on the mean difference between paired measurements (which would be 0 under the null hypothesis!). In this way, it is effectively a one-sample test that is pairing the data to reduce variation (blocking). We can do carry out the test:\n\nt.test(Color_index ~ Feather_type, data=feather, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  Color_index by Feather_type\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean difference \n      -0.137125 \n\n\nand get the same results as above (note we don’t even have to consider corrections like the Welch approach since this a one-sample test). Common examples of paired t-tests include before-after and twin studies.\nIn an earlier chapters we considered options for one- and two-sample tests when t-tests assumptions were not met. For two-sample tests, one of these approaches, the sign or binary test, is only valid for paired data. The differences in paired observations are compared to a set value (typically 0). Under the null hypothesis, half should be below the proposed median and half should be above. Differences matching the proposed value are ignored, thus reducing the sample size and making it harder to reject the null hypothesis; this is actually an odd way of accounting for them. The proportion of values below the proposed median is then evaluated using a binomial test. For two sample, the SIGN.test function in the BSDA package requires 2 columns of data and assumes the order of the column represents paired data.\n\nlibrary(BSDA)\nSIGN.test(feather[feather$Feather_type == \"Odd\", \"Color_index\"], \n          feather[feather$Feather_type == \"Typical\", \"Color_index\"],\n          md = 0)\n\n\n    Dependent-samples Sign-Test\n\ndata:  feather[feather$Feather_type == \"Odd\", \"Color_index\"] and feather[feather$Feather_type == \"Typical\", \"Color_index\"]\nS = 3, p-value = 0.02127\nalternative hypothesis: true median difference is not equal to 0\n95 percent confidence interval:\n -0.24048275 -0.02331055\nsample estimates:\nmedian of x-y \n       -0.114 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level  L.E.pt  U.E.pt\nLower Achieved CI     0.9232 -0.2400 -0.0320\nInterpolated CI       0.9500 -0.2405 -0.0233\nUpper Achieved CI     0.9787 -0.2410 -0.0140\n\n\n\n\nMore than 2 measurements? Back to the linear model\nWe can also block for variation when we take more than 2 measurements per unit. For example, imagine if these birds also had a special, long tail feather.\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather_type = \"Special\", \n                      Color_index= feather[feather$Feather_type == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather_extra &lt;- merge(feather, special, all = T)\nfeather_extra$Feather_type &lt;- factor(feather_extra$Feather_type)\n\nWe could still block for variation using the linear model/ANOVA, but not the t-test, approach. As another review, we create the model\n\nmore_blocks &lt;-lm(Color_index ~ Feather_type + Bird, data=feather_extra)\n\nCheck assumptions\n\nplot(more_blocks)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck outcome (this time focusing on Anova output)\n\nAnova(more_blocks, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  0.36392  1  59.9538 1.224e-08 ***\nFeather_type 1.67906  2 138.3093 7.208e-16 ***\nBird         0.34649 15   3.8055 0.0008969 ***\nResiduals    0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe still see feather type has a significant impact on color, but since we have more than 2 groups we need to follow up this finding with a post-hoc test.\n\nlibrary(multcomp)\ncompare &lt;- glht(more_blocks, linfct = mcp(Feather_type = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather_type + Bird, data = feather_extra)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nSpecial - Odd == 0      0.44712    0.02755  16.232   &lt;1e-04 ***\nTypical - Odd == 0      0.13712    0.02755   4.978   &lt;1e-04 ***\nTypical - Special == 0 -0.31000    0.02755 -11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#other-ways-to-be-in-multiple-groups",
    "href": "content/chapters/More_ANOVAs.html#other-ways-to-be-in-multiple-groups",
    "title": "More ANOVAs",
    "section": "Other ways to be in multiple groups",
    "text": "Other ways to be in multiple groups\nIn the bird example, one of our categories (bird) was un-intential. We chose to measure odd and typical feathers, and accounting for variation among birds was an appropriate step given lack of independence in measurements. However, we can also assign units to multiple groups (instead of making multiple measurements within one unit).\nConsider if we ran an experiment focused on the impact of factors A and B on some trait. We can fully cross the factors in an experiment. Doing so can let us consider the main effects of multiple variables and potential interactions among them in what is often called a factorial ANOVA. For starters, let each factor have only 2 levels, and let the levels be the absence or presence of the factor.\n\n\n\n\nFactor A\n\n\n\nFactor B\nAbsent\nPresent\n\n\nAbsent\nControl\nImpact of A only\n\n\nPresent\nImpact of B only\nCombined impact of A+B\n\n\n\n\n\nExperimental design notes\n\nFor a factorial ANOVA, we need to assign each unit randomly to a level of factor A. Then each level of factor B is randomly assigned to subjects at each level of factor A. This is different than randomly assigning treatments of A and B, as that could lead to outcomes where some level of factor B is not represented in some level of factor A.\nWe also need multiple units (3+) assigned to each combination.\n\nWhen both are absent we have a classic control outcome. When one is present and the other absent we see main effects impacts of only one factor. Note we previously analyzed experiments that considered only one factor using ANOVAs or t-tests (linear models), but now we have multiple factors. We should not analyze the main effects of each using 2 one-way ANOVAs. Doing so cuts our data in half, meaning our estimates of variances are less precise and we increase our chance of making a type 1 error. More importantly, we wouldn’t be able to properly consider the combined impacts of A + B. What could these be?\n\nexample_interaction &lt;- data.frame(Treatment = c(rep(\"Control\",5),\n                                                rep(\"Impact of A only\",5),\n                                                rep(\"Impact of B only\",5),\n                                                rep(\"A+B Additive\",5), \n                                                rep(\"A+B Synergistic\", 5),\n                                                rep(\"A+B Antagonistic\", 5)), \n                                  Cause= rep(c(\"Control\",\"Factor A\",\"Factor B\", \"Synergistic\", \"Antagonistic\"), 6),\n                                  Impact = c(5,0,0,0,0,\n                                             5,2,0,0,0,\n                                             5,0,3,0,0,\n                                             5,2,3,0,0,\n                                             0,0,0,20,0,\n                                             0,0,0,0,6))\nexample_interaction$Treatment &lt;- factor(example_interaction$Treatment, levels=c(\"Control\",\"Impact of A only\",\"Impact of B only\", \"A+B Additive\", \"A+B Synergistic\", \"A+B Antagonistic\"))\nexample_interaction$Cause &lt;- factor(example_interaction$Cause, levels=c(\"Control\",\"Factor A\",\"Factor B\", \"Synergistic\", \"Antagonistic\"))\nggplot(example_interaction, aes(x=Treatment, y= Impact, fill= Cause))+\n  geom_col(position = position_stack(reverse = TRUE))+\n  theme(axis.text.x = element_text(angle = -45))\n\n\n\n\n\n\n\n\nAs shown in the graph (Inspired by (Fong, Bittick, and Fong 2017)), A and B could have additive effects (where they simply stack), synergistic effects (the combined impact is more than the sum of the two), or antagonistic effects (the combined impacts is less than the sum of the two). Synergistic and antagonistic impacts are both examples of interactions. Interactions occur when the impact of one variable depends on the level of another.\n\nExample: Impacts of grazing and fertilization\nWe can extend this example to consider more than 2 levels for one or more factors. For example, Valdez et al. (2023) wanted to consider the impact of top-down (snail grazing) and bottom- up (nutrient availability) on marsh plant (Spartina alterniflora) growth. To do this, they assigned plots to one of 3 grazer treatments and one of 2 nitrogen treatments.\n\n\n\nFig 1 from Valdez et al. 2003. Map and conceptual illustration of experimental design.\n\n\nThis design is different from the bird example. No two measurements for a given trait were taken on the same plot. In this case, we likely care about the main effects, or impacts, of both variables. However, we may also need to consider interactions among the variables. Interactions occur when the impact of one variable depends on the level of another. For example, snail removal might have major impacts on nitrogen-enriched plots while having no impact on ambient plots. Due to this, we now have even more hypotheses:\n\\[\n\\begin{split}\nH_O: \\mu_\\textrm{plant growth, no fertilizer} = \\mu_\\textrm{plant growth, fertilizer}\\\\\nH_O: \\mu_\\textrm{plant growth, snails removed} = \\mu_\\textrm{plant growth, control snails}= \\mu_\\textrm{plant growth, snails added}\\\\\nH_O: \\textrm{impact of snail grazing does not depend on nitrogen level}\\\\\n\\end{split}\n\\]\nFortunately, these are easy to consider in our linear model framework. While not shown here, the model matrix adds columns to note our new interaction terms, and the coefficient matrix estimates them. From an R standpoint, we can include the interaction between two variables using the “:” notation. We’ll focus on below-ground biomass (standardized to m2) for this example (the paper measured 9 response variables!)\n\nvaldez_2023 &lt;- read.csv(\"data/Spartina_alterniflora_traits.csv\", stringsAsFactors = T)\nbgb_model &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023)\n\nFor shorthand, note that if we put main effect * main effect in a model, it automatically adds the interaction term. You can see the model summary is the same.\n\nbgb_model_shorthand &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level * Nitrogen.level, valdez_2023)\nsummary(bgb_model)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level + \n    Snail.Level:Nitrogen.level, data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\nsummary(bgb_model_shorthand)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\n\nYou may note a weird NA here (we’ll come back to it), but remember we should really check model assumptions before looking at output.\n\nplot(bgb_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese look ok. There may be a slight increase in variance with fitted values, but we can work with this. Let’s build an ANOVA table.\n\nAnova(bgb_model, type=\"III\")\n\nError in Anova.III.lm(mod, error, singular.ok = singular.ok, ...): there are aliased coefficients in the model\n\n\nBut we got an error! What happened? Let’s look at the data\n\npaged_table(valdez_2023)\n\n\n  \n\n\n\nA summary may help more. Note we can summarize across multiple factors.\n\nlibrary(Rmisc)\npaged_table(summarySE(valdez_2023, measurevar = \"below.biomass.g.meter.sq..m2..\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\")))\n\n\n  \n\n\n\nNote the uncaged treatment only has without for the nitrogen impact. It was a control! While we often need these in experiments, they can create analysis problems. This is because we can’t consider how nutrient level depends on snail treatment for the control level! In other words, interactions can not be calculated for some levels.\nThis is also why we saw the NA and warnings in our model summary\n\nsummary(bgb_model)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level + \n    Snail.Level:Nitrogen.level, data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\n\nYou could note we have the same issue for our initial bird analysis:\n\ntwo_way_anova_example_int &lt;- lm(Color_index ~ Feather_type * Bird, data=feather)\nAnova(two_way_anova_example_int, type=\"III\")\n\nError in Anova.lm(two_way_anova_example_int, type = \"III\"): residual df = 0\n\n\nOn a positive note, this means R will typically not consider interactions when it shouldn’t, but you need to know why in order to fix it.\n\n\nDealing with controls and missing interactions\nTo fix this (and deal with controls), we need to consider the data. Valdez et al. (2023) used t-tests (why?) to consider differences between cage and cage control plots (note %in% and the fact they did not focus on above-ground biomass (maybe because uncaged plots had little..). %in% allows you to subset data by matching items to list. Remember you can always get help on functions using something like (we need the quotations for operators!)\n\n?'%in%'\n\n\nt.test(below.biomass.g.meter.sq..m2..~Snail.Level, valdez_2023[valdez_2023$Snail.Level %in% c(\"uncaged\",\"control snails\") & valdez_2023$Nitrogen.level == \"without\",])\n\n\n    Welch Two Sample t-test\n\ndata:  below.biomass.g.meter.sq..m2.. by Snail.Level\nt = -0.82961, df = 3.9666, p-value = 0.4538\nalternative hypothesis: true difference in means between group control snails and group uncaged is not equal to 0\n95 percent confidence interval:\n -196.4785  106.3052\nsample estimates:\nmean in group control snails        mean in group uncaged \n                    430.2967                     475.3833 \n\n\nIf interactions are missing for other reasons (e.g., a set of units failed/died/data was lost), we can either ignore interactions or combine factor levels into a single new treatment variable and analyze using one-way ANOVAs.\n\n\nConsidering interactions\nTo consider interactions, we can remove the controls\n\nbgb_model_cont_removed &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\n\nWe can consider the assumptions\n\nplot(bgb_model_cont_removed)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand now note …\n\nAnova(bgb_model_cont_removed, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: below.biomass.g.meter.sq..m2..\n                           Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)                881823  1 176.4820 1.545e-08 ***\nSnail.Level                 24012  2   2.4028   0.13254    \nNitrogen.level              18771  1   3.7567   0.07648 .  \nSnail.Level:Nitrogen.level   2893  2   0.2895   0.75371    \nResiduals                   59960 12                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n…that the ANOVA table works.\n\n\nIntepreting interactions\n\nWhen not significant\nIf interactions are not significant, they can be handled in 2 ways.\n\nWe can leave the interaction in the model and interpret main effects immediately\nWe can remove the interaction from the model, re-run it, and interpret main effects of the factors.\n\nbgb_model_cont_removed_int_removed &lt;- update(bgb_model_cont_removed, .~.-Snail.Level:Nitrogen.level)\nplot(bgb_model_cont_removed_int_removed)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(bgb_model_cont_removed_int_removed, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: below.biomass.g.meter.sq..m2..\n                Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)    1239848  1 276.1645 1.303e-10 ***\nSnail.Level      39024  2   4.3461   0.03402 *  \nNitrogen.level   26919  1   5.9959   0.02812 *  \nResiduals        62853 14                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nRegardless, we can interpret main effects (though with possibly different outcomes). The benefit of approach 2 is we “increase” the degrees of freedom associated with the residuals, which ends up reducing the the MST. This is because in 2-way ANOVAs we allocate degrees of freedom to calculating main effects and interactions. This approach was likely used in the original manuscript.\nSimply using the the provided output (approach 1) and not perform another series of tests, however, reduces the chances for a Type 1 error. We will return to this discussion when we get to model selection.\nIf we see significant effects of a factor that has more than 2 levels (like we do when using the approach that drops insignificant interactions), we can consider the general impact of grazing levels using post-hoc tests:\n\nsummary(glht(bgb_model_cont_removed_int_removed, linfct = mcp(Snail.Level = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)  \nremoval - control snails == 0           55.27      38.68   1.429   0.3534  \nsnail addition - control snails == 0   -58.76      38.68  -1.519   0.3123  \nsnail addition - removal == 0         -114.04      38.68  -2.948   0.0267 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nWhen significant\nIf the interaction term is significant, it means the main effects can not be interpreted. This is because the impact of a given variable depends on the level of another. When this happens, the data is typically divided into subset and analyzed using one-way ANOVAs.\nFor example, when Valdez et al. (2023) analyzed standing dead mass, they found a significant interaction term:\n\nsdm_model &lt;-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\nplot(sdm_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n                            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)                1050.19  1 328.463 4.392e-10 ***\nSnail.Level                 300.82  2  47.042 2.095e-06 ***\nNitrogen.level              348.39  1 108.963 2.248e-07 ***\nSnail.Level:Nitrogen.level  200.90  2  31.417 1.700e-05 ***\nResiduals                    38.37 12                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFollowing this, you could investigate impacts in plots with nitrogen, where you find snail manipulation had a significant impact (and considered post-hoc which ones!)\n\nsdm_model_fertilized &lt;-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\" & valdez_2023$Nitrogen.level == \"Fertilized\",])\nplot(sdm_model_fertilized)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_fertilized, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 1050.19  1 206.027 7.158e-06 ***\nSnail.Level  300.82  2  29.507  0.000786 ***\nResiduals     30.58  6                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(glht(sdm_model_fertilized, linfct = mcp(Snail.Level= \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Standing.Dead..dry..m2. ~ Snail.Level, data = valdez_2023[valdez_2023$Snail.Level != \n    \"uncaged\" & valdez_2023$Nitrogen.level == \"Fertilized\", ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nremoval - control snails == 0         -14.150      1.843  -7.676   &lt;0.001 ***\nsnail addition - control snails == 0   -7.567      1.843  -4.105   0.0150 *  \nsnail addition - removal == 0           6.583      1.843   3.571   0.0272 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nand plots without added nutrients, where you find snail addition did not\n\nsdm_model_not_fertilized &lt;-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\" & valdez_2023$Nitrogen.level == \"without\",])\nplot(sdm_model_not_fertilized)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_not_fertilized, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept) 36.123  1 27.8457 0.001871 **\nSnail.Level 12.416  2  4.7856 0.057211 . \nResiduals    7.783  6                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOther approaches for dealing with significant interactions include directly interpreting interaction terms (which we can do given our understanding of linear model coefficients), but this is rarely used. They are somewhat messy\n\ncoef(sdm_model)\n\n                                    (Intercept) \n                                      18.710000 \n                             Snail.Levelremoval \n                                     -14.150000 \n                      Snail.Levelsnail addition \n                                      -7.566667 \n                          Nitrogen.levelwithout \n                                     -15.240000 \n       Snail.Levelremoval:Nitrogen.levelwithout \n                                      16.153333 \nSnail.Levelsnail addition:Nitrogen.levelwithout \n                                      10.356667 \n\n\nAnother approach when interactions are significant is to compare all group means (somewhat like a Tukey design for combined treatment levels). The emmeans package offers this approach.\n\nlibrary(emmeans)\nemmeans(sdm_model, pairwise ~ Snail.Level*Nitrogen.level)\n\n$emmeans\n Snail.Level    Nitrogen.level emmean   SE df lower.CL upper.CL\n control snails Fertilized      18.71 1.03 12    16.46    20.96\n removal        Fertilized       4.56 1.03 12     2.31     6.81\n snail addition Fertilized      11.14 1.03 12     8.89    13.39\n control snails without          3.47 1.03 12     1.22     5.72\n removal        without          5.47 1.03 12     3.22     7.72\n snail addition without          6.26 1.03 12     4.01     8.51\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                              estimate   SE df t.ratio\n control snails Fertilized - removal Fertilized          14.150 1.46 12   9.692\n control snails Fertilized - snail addition Fertilized    7.567 1.46 12   5.183\n control snails Fertilized - control snails without      15.240 1.46 12  10.439\n control snails Fertilized - removal without             13.237 1.46 12   9.066\n control snails Fertilized - snail addition without      12.450 1.46 12   8.528\n removal Fertilized - snail addition Fertilized          -6.583 1.46 12  -4.509\n removal Fertilized - control snails without              1.090 1.46 12   0.747\n removal Fertilized - removal without                    -0.913 1.46 12  -0.626\n removal Fertilized - snail addition without             -1.700 1.46 12  -1.164\n snail addition Fertilized - control snails without       7.673 1.46 12   5.256\n snail addition Fertilized - removal without              5.670 1.46 12   3.884\n snail addition Fertilized - snail addition without       4.883 1.46 12   3.345\n control snails without - removal without                -2.003 1.46 12  -1.372\n control snails without - snail addition without         -2.790 1.46 12  -1.911\n removal without - snail addition without                -0.787 1.46 12  -0.539\n p.value\n  &lt;.0001\n  0.0024\n  &lt;.0001\n  &lt;.0001\n  &lt;.0001\n  0.0072\n  0.9716\n  0.9868\n  0.8450\n  0.0021\n  0.0206\n  0.0512\n  0.7419\n  0.4406\n  0.9932\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\nThis was likely the approach used in the Valdez et al. 2023 paper.\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Snail.Level*Nitrogen.level)$contrasts))\n\n\n  \n\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Snail.Level)$contrasts))\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n\n  \n\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Nitrogen.level)$contrasts))\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n\n  \n\n\n\nNote the warning; if interactions are significant comparing main effects may be inappropriate (which is why other approaches include subsetting the data).",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#other-options",
    "href": "content/chapters/More_ANOVAs.html#other-options",
    "title": "More ANOVAs",
    "section": "Other options",
    "text": "Other options\nBootstrapping and permutation tests options may also be used for two-way ANOVAs when assumptions are not met, though there is implementation is more complicated than single-sample designs due to the need to randomize/permute interaction impacts.",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#plotting-outcomes",
    "href": "content/chapters/More_ANOVAs.html#plotting-outcomes",
    "title": "More ANOVAs",
    "section": "Plotting outcomes",
    "text": "Plotting outcomes\nResults from two-way ANOVAs are often plotted similarly to one-way ANOVAs, but with colors or other aesthetics representing the additional group.\n\nsdm_summary &lt;- summarySE(valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], measurevar = \"Standing.Dead..dry..m2.\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\"))\nsdm_summary\n\n     Snail.Level Nitrogen.level N Standing.Dead..dry..m2.        sd        se\n1 control snails     Fertilized 3               18.710000 3.6626220 2.1146158\n2 control snails        without 3                3.470000 1.0013491 0.5781292\n3        removal     Fertilized 3                4.560000 0.4250882 0.2454248\n4        removal        without 3                5.473333 1.4150029 0.8169523\n5 snail addition     Fertilized 3               11.143333 1.3025104 0.7520047\n6 snail addition        without 3                6.260000 0.9417006 0.5436911\n        ci\n1 9.098457\n2 2.487489\n3 1.055978\n4 3.515062\n5 3.235615\n6 2.339314\n\n\n\nsdm_summary$Snail.Level &lt;- relevel(sdm_summary$Snail.Level, \"removal\")\n\nsdm_summary$Nitrogen.level &lt;- revalue(sdm_summary$Nitrogen.level, c(\"Fertilized\" = \"Yes\",\n                                                                    \"without\"= \"No\"))\n\nggplot(sdm_summary, aes(x=Snail.Level, \n                           y=Standing.Dead..dry..m2.,\n                           fill=Nitrogen.level)) +\n  geom_col(color=\"black\", position=position_dodge()) +\n  geom_errorbar(aes(ymin=Standing.Dead..dry..m2., ymax=Standing.Dead..dry..m2.+ci), position = position_dodge()) +\n  labs(title=\"Grazing impacts depend on nitrogen levels\",\n       x= \"Grazing level\",\n       y= expression(paste(\"Standing dry mass (\" , g^{-1}, m^{-2}, \")\")),\n       fill = \"Fertilized?\")",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#next-steps",
    "href": "content/chapters/More_ANOVAs.html#next-steps",
    "title": "More ANOVAs",
    "section": "Next steps",
    "text": "Next steps\nIn the next chapters we will carry our linear model approach to consider the relationship between continuous outcomes and continuous predictor variables.",
    "crumbs": [
      "Chapters",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/chapters/Introduction.html",
    "href": "content/chapters/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "“Why is statistics a required course for someone who wants to be a dentist/doctor/ nurse?”\nThis is a common question (or at least thought) for many students. I hope to convince you this semester you at least need to understand statistics as part of the scientific method (and you should realize the scientific process informs all those jobs - in fact it can inform any job or task where you are searching for an answer or better method).\nFor example, doctors prescribe medicine to patients, but how do they know these medicines work? Some doctors carry out research, but many rely on published guidelines, which themselves rely on research. So a new drug or treatment is proposed- but who decides if it should be used? Researchers carry out trials to determine the efficacy of the treatment. In doing this they have to consider how to design an experiment (what do they collect? from whom?) and analyze the resulting data so they can trust the results.\n\n\n\n\n\n\nFigure 1: XKCD: Control Group. https://xkcd.com/2576/, CC BY-NC 2.5 &lt;https://creativecommons.org/licenses/by-nc/2.5/&gt;.\n\n\n\nOther students in our class may be interested in a career focused on resource management or environmental issues (e.g., wildlife rehabilitation, carbon mitigation expert, researcher). Regardless of your goal, any question should be informed by this approach. For example,\n\nDoes an environmental factor cause cancer?\nDo potential toxins really harm the enviroment?\nIs organic food really healthier?\nDoes exposing organisms reared in captivity to predator cues lead to more successful releases?\n\nZhu et al. (2023)\n\n\nAt its heart, statistics is about turning data into information that we can use to make decisions or better understand the world around us. Data can come from experiments we are running. This offers a clear connection to field and lab science, and its what we will focus on for most of this class. Data and theories can also be used to develop models that produce output ; this isn’t real-world data, but it offers very useful insight on what we think will happen if something occurs (and something we can test with other field data!). For example, restoration projects may focus on small-scale plots that undergo different restoration protocols. Data produced from monitoring these plots may be used to develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions.\nAbove I used words like know (how do they know these medicines work? )and predict (develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions). While we may use words like these to discuss our findings and results, its important to note the are not totally correct. Statistics (and related models) generally give us estimates about how the real world works. Put another way, if we knew everything about the world, we wouldn’t need to use statistics because we wouldn’t need estimates.\nThe reasons we don’t usually know everything include\n\nthe world is complicated (some questions can’t be directly tested)\nit’s not possible to measure everything\n\nBecause of this, statistics is also focused on trying to describe populations of interest or find signals (impacts of treatments, medicines, or restoration practices, for example) amidst the noise (variation in outcomes that are always common!). When considering relationships among variables, noise may occur because there are lots of things impacting the outcome of interest. For example, restoration protocol may impact the trajectory of an oyster reef, but so too may local factors like temperature an and salinity. Noise can also occur because of sampling error - since we don’t measure everything, our estimate of relationship or population traits may be imperfect.\nIn the next session we’ll start to discuss how we can use data to make estimates about a population (and answer questions like what is a population and what are we trying to estimate). However, a final aside to finish this section - we often think about statistics happening after an experiment, survey, or other thing we get data from is finished. However, part of statistics is experimental design! Statistics should inform how you setup an experiment. In fact, the best idea (which seldom happens!) is that you simulate the type of data you expect to get from your experiment and then analyze that before you actually run the experiment. This ensures you are measuring what you need to measure and setting things up correctly! As the famous (to statisticians) quote states,\n\nTo consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of. -Ronald Fisher\n\n\n\n\n\nReferences\n\nZhu, Jennifer, J. Stephen Gosnell, Laila Akallal, and Micah Goltsman. 2023. “Fear Changes Traits and Increases Survival: A Meta-Analysis Evaluating the Efficacy of Antipredator Training in Captive-Rearing Programs.” Restoration Ecology 31 (3): e13674. https://doi.org/10.1111/rec.13674.",
    "crumbs": [
      "Chapters",
      "Introduction"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html",
    "href": "content/chapters/Compare_proportions_among_populations.html",
    "title": "Comparing proportions among groups",
    "section": "",
    "text": "Now that we’ve covered hypothesis testing for both discrete and continous data, we’ll extend these ideas to compare differences among groups. In addition considering these differences, the same test we’ll let us consider if proportions follow a given ratio.",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#example-back-to-the-birds",
    "href": "content/chapters/Compare_proportions_among_populations.html#example-back-to-the-birds",
    "title": "Comparing proportions among groups",
    "section": "Example: Back to the birds",
    "text": "Example: Back to the birds\nLet’s return to our bird example Klem (1989). We previously found that purple finches did not strike windows at proportions that might be predicted by population demographics using a binomial test. However, what if instead we wanted to compare the collision rate of old vs young birds among several species?\n\n\n\nCephas, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\n\n\nLet’s start simple and just compare purple finches and dark-eyed juncos.\n[Becky Matsubara from El Sobrante, California, CC BY 2.0 &lt;https://creativecommons.org/licenses/by/2.0&gt;, via Wikimedia Commons&gt;, via Wikimedia Commons] (/images/Dark-eyed_Junco_(Oregon)_(39651044095).jpg){fig-alt=“Dark-eyed Junco (Junco hyemalis), Sobrante Ridge Regional Reserve, Richmond, California.”}\nKlem’s sample of finches totaled 18, with 9 being older (after hatching year). For juncos, 4 of 11 sampled birds were older. We could put this data in a table.\n\n\n\n\nObserved\n\n\n\n\n\n\n\nFinch\nJunco\nRow Totals\n\n\nOlder\n9\n4\n13\n\n\nYounger\n9\n7\n16\n\n\nColumn Totals\n18\n11\nN = 29\n\n\n\nFirst, we could plot our data\n\nbirds_original &lt;- data.frame(Age = c(\"Old\",\"Young\",\"Old\", \"Young\"),\n                      Species = c(\"Junco\", \"Junco\", \"Finch\", \"Finch\"),\n                      Number = c(4, 7, 9, 9))\nlibrary(ggplot2)\nggplot(birds_original, aes(x= Species, y = Number)) +\n  geom_col(aes(fill = Age)) + \n  labs(x=\"Species\", \n       y=\"Frequency\", \n       main =\"Age at collision for juncos and finches\")\n\n\n\n\n\n\n\n\nGiven the different sampling sizes, a mosaic plot might help in visually comparing ratios.\n\nggplot(birds_original, aes(x= Species, y = Number)) +\n  geom_col(aes(fill = Age), position = \"fill\")+\n    labs(x=\"Species\", \n       y=\"Proportion\", \n       main =\"Age at collision for juncos and finches\")\n\n\n\n\n\n\n\n\nBefore we test this, we need to decide on an hypothesis. Although both species were predicted to occur at 3:1 ratios in the wild, that’s not what we are considering here. Instead, we want to know if the likelihood of old vs young birds being in our samples differed for the species. Put another way, we are asking if the proportion of young vs old is contingent on species. These tests are often called contingency analysis, and the table we started with may be referred to as a to as a contingency table.\nIf the proportion of old vs young birds differ among species, it could be because the age structure of the focal populations are different or because the birds differ in their relationship to glass at different ages. However, we are still testing a distribution-based parameter.\n\\[\n\\begin{split}\nH_O: p_{finches} = p_{juncos} \\\\  \nH_A: p_{finches} \\neq p_{juncos} \\\\\n\\textrm{ where p is likelihood of sampled bird being older}\\\\\n\\end{split}\n\\]\nPut another way,we want to test if p is independent of species.\n\\[\n\\begin{split}\nH_O: \\textrm{Probability of older bird hitting window is independent of species} \\\\  \nH_A: \\textrm{Probability of older bird hitting window is dependent of species} \\\\  \n\\end{split}\n\\]\nThis formulation is important, because it helps form our predictions under the null hypothesis. What would we expect if p did not differ among species? If age and species were independent, we could expect\n\\[\n\\textrm{Pr[ Old AND Given speciesuse] = Pr[given species] * Pr[Old]}\n\\]\nSince we have 13/29 birds are old, we should expect\n\n\n\n\nObserved\n\n\n\n\n\n\n\nFinch\nJunco\nRow Totals\n\n\nOlder\n18 * 13/29\n11 * 13/29\n13\n\n\nYounger\n18 * 16/29\n11 * 16/29\n16\n\n\nColumn Totals\n18\n11\nN = 29\n\n\n\nIn order to carry out a sampling experiment to consider noise from this expected outcome, we have to determine the p parameter to use for our population. This is because under the null hypothesis, there is only one population- any observed difference is just due to chance!\nHowever, we have an issue - we don’t know p. In our binomial experiment it was set by our null hypothesis. Now we are comparing p among species, but that doesn’t set a population distribution.\nTo fix this, we go back to our normal approximations. We have shown for large sample sizes the binomial distribution follows the central limit theorem, with \\(Np\\) and \\(p\\) both showing a normal distribution.\n\nsample_size=c(\"1\",\"5\",\"10\", \"20\", \"40\", \"80\")\nnumber_of_simulations &lt;- 1000\nsampling_experiment &lt;- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)\n\nfor(k in 1:length(sample_size)){\nfor(i in 1:number_of_simulations){\nsampling_experiment[i,k] = rbinom(n=1, size=as.numeric(sample_size[k]), prob=.7)\n}\n}\nlibrary(reshape2)\nsampling_experiment_long &lt;- melt(sampling_experiment, variable.name = \"Sample_size\", value.name = \"mean\")\n\nNo id variables; using all as measure variables\n\nsampling_experiment_long$Sample_size &lt;- factor(sampling_experiment_long$Sample_size, levels =c(\"1\",\"5\",\"10\", \"20\", \"40\", \"80\"))\nlevels(sampling_experiment_long$Sample_size) &lt;- paste(\"Sample size of \", levels(sampling_experiment_long$Sample_size))\n\nggplot(sampling_experiment_long,aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=paste(\"Observed number of successes from \", number_of_simulations, \" random draws\"),\n       subtitle = \"Binomial distribution, p=.7\",  \n       x= \"Mean\",\n       y= \"Frequency\")+\n    facet_wrap(~Sample_size, nrow = 2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nSo, we can replace the binomial distribution in our sampling experiment with a normal population. To use this approach, we estimate a value for p, \\(\\hat{p}\\), from the data, and let\n\\[\n\\begin{split}\n\\mu = Np \\\\\n\\sigma_\\mu =\\sqrt{Np(1-p)}\n\\end{split}\n\\]\nWe then draw only 1 draws this distribution. Why only 1? Because we need to keep the sample sizes the same, so the row and column totals are set! Remember this for a moment. After we draw 1 number, we fill in the rest.\n\nnum_of_simulations &lt;- 10000\nsimulations &lt;- r2dtable(num_of_simulations,c(13,16),c(18,11))\nchi_sq_stats &lt;- data.frame(chisq = rep(NA, num_of_simulations))\nfor(i in 1:num_of_simulations){\nchi_sq_stats$chisq[i] &lt;- chisq.test(matrix(unlist(simulations[i]),nrow=2, byrow=T))$statistic\n}\n\ncolors &lt;- c(\"distribution\" = \"green\", \"simulated data\" = \"orange\")\nggplot(chi_sq_stats, aes(x=chisq)) +\n  geom_histogram(aes(y=..count../sum(..count..), color = \"simulated data\", fill=\"simulated data\")) +\n  labs(y=paste(\"Probability under \", num_of_simulations, \" simulations\", \nsep =\"\"), x=expression(chi^2), color=\"Source\")+guides(fill=F)+\n  scale_color_manual(values = colors)+\n  scale_fill_manual(values=colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nOnce we carry out the sampling experiment, we can Z-transform our cell data(because they are normal now!). The results for a single cell would follow a N(0,1) distribution (the Z). If we wanted, we could square these outcomes (which would then follow a \\(\\chi^2\\) distribution, by definition), and, since we have 4 cells, add them. The resulting variate would follow a \\(\\chi^2\\) distribution with 1 degree of freedom (since we drew 1 numbers for the free “cell” in our table). Finally, because of all the p’s above, we could actually rewrite all of this as\n\\[\nV=\\sum_{i=1}^{n}{\\frac{{(Observed-Expected)}^2}{Expected}} \\textrm{where n is number of cells}\n\\]",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#contingency-analysis-using-the-chi2-test",
    "href": "content/chapters/Compare_proportions_among_populations.html#contingency-analysis-using-the-chi2-test",
    "title": "Comparing proportions among groups",
    "section": "Contingency analysis using the \\(\\chi^2\\) test",
    "text": "Contingency analysis using the \\(\\chi^2\\) test\nThe resulting test is called a \\(\\chi^2\\) test. Note this takes count-based data and uses a continuous distribution to describe it, so it’s an approximate test.\n\nggplot(chi_sq_stats, aes(x=chisq)) +\n  geom_histogram(aes(y=..count../sum(..count..), color = \"simulated data\", fill=\"simulated data\")) +\n  stat_function(fun = dchisq, args = list(df = 1),aes(color =\"distribution\")) +\n  labs(y=paste(\"Probability under \", num_of_simulations, \" simulations\", \nsep =\"\"), x=expression(chi^2), color=\"Source\")+guides(fill=F)+\n  scale_color_manual(values = colors)+\n  scale_fill_manual(values=colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can carry out this test in R using the chisq.test function.\nThis function requires a matrix of aggregated values (counts for each cell). Currently we have a data frame (birds). To make this work, we have a few options.\nWe can input the data directly as a matrix, specifying the string, the number of rows and columns, and how we entered the data in regards to rows (remember ?chisq.test)\n\nchisq.test(matrix(c(9,4,9,7), 2, 2, byrow=T))\n\nWarning in chisq.test(matrix(c(9, 4, 9, 7), 2, 2, byrow = T)): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(9, 4, 9, 7), 2, 2, byrow = T)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nIf the data is in wide data frame (meaning more than one measured outcome per row, so measuring the young and old as columns in the data frame) or we make it look like that, we can use the data directly from the data frame. Consider the difference in format. This is long data (one measure per row):\n\nbirds_original\n\n    Age Species Number\n1   Old   Junco      4\n2 Young   Junco      7\n3   Old   Finch      9\n4 Young   Finch      9\n\n\nand this wide\n\nlibrary(reshape2) \nbirds_wide &lt;- dcast(birds_original, Age~Species) \n\nUsing Number as value column: use value.var to override.\n\nbirds_wide\n\n    Age Finch Junco\n1   Old     9     4\n2 Young     9     7\n\n\nWe can make the matrix with wide data\n\nchisq.test(matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2))\n\nWarning in chisq.test(matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nFor our 2x2 table, notice the order of input does not matter (because it wouldn’t impact the expected values. Consider\n\nchisq.test(matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2))\n\nWarning in chisq.test(matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nUsing cbind is also an option.\n\nchisq.test(cbind(birds_wide$Finch, birds_wide$Junco))\n\nWarning in chisq.test(cbind(birds_wide$Finch, birds_wide$Junco)): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  cbind(birds_wide$Finch, birds_wide$Junco)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nAs long as we specify the table, we are ok. Note each of these tests notes 1 df. The degrees of freedom associated with this test are based on the number of free cells (or, alternatively, the number of cells minus the parameters you had to fill in!). This typically can be calculated as (# of columns -1)*(# of rows -1). They each also note a p-value greater than .05. This would suggest we should fail to reject the null hypothesis.\nEach result also tells you this is an approximation (as we already noted!). Since the test is approximate, by default R applies Yate’s continuity correction to data focused on 2x2 tables. Some argue this correction is too strict, and you can turn it off in R (correct=F argument). You can also choose to simulate the outcome instead (simulate.p.value = T), but note this will still be an approximate answer since we can’t do every single sample.\nThe output also indicate the results may be incorrect? Why? In order for our normal approximation to work, we need large samples and a \\(\\hat{p}\\) that is not near 0 or 1. Together, these mean our expected values for most cells (actually, &gt;80%) can not be less than 5., and no cell can have an expected value of less than 1. If these assumption are not met(or are close), R will warn us. We can check expected values using\n\nchisq.test(matrix(c(9,4,9,7), 2, 2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(9, 4, 9, 7), 2, 2, byrow = T)): Chi-squared\napproximation may be incorrect\n\n\n         [,1]     [,2]\n[1,] 8.068966 4.931034\n[2,] 9.931034 6.068966\n\n\nIn this case, 25% of the cells (1/4) has an expected value of less than 5.",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#other-options",
    "href": "content/chapters/Compare_proportions_among_populations.html#other-options",
    "title": "Comparing proportions among groups",
    "section": "Other options",
    "text": "Other options\n\nFisher’s test\nIf this is the case for a 2x2 table, we can use a Fisher’s test instead\n\nfisher.test(matrix(c(9,4,9,7), 2, 2, byrow=T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(9, 4, 9, 7), 2, 2, byrow = T)\np-value = 0.7021\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.2997173 11.0799590\nsample estimates:\nodds ratio \n  1.716435 \n\n\nAs opposed to resampling from a null distribution, Fisher’s test considers all (or lots) of ways the data could be re-arranged (or permuted) and then computes a p-value using that approach. This means Fisher’s test works for any sample size. It is an exact test if all possible combinations are considered (but they rarely are).\nNotice the output reports the odds ratio. This ratio is found by dividing odds in one group by odds in another (thus a ratio). Odds are the probability of one outcome over another. For our data, this could be considered (old/young(finches)) divided by (old/young(juncos)), (9/9)/(4/7)=63/36. This is close to what we saw in the output; slight differences occur since the fisher.test function returns a conditional estimate of the odds ratio.\nNote odds differ from relative risks, which compare the probability of an event occurring (or not) among 2 groups. The results are similar for rare events (think about why!) but not for common events. For more, see Altman, Deeks, and Sackett (1998) Davies, Crombie, and Tavakoli (1998) or this [video and paper]{https://www.bmj.com/content/348/bmj.f7450}(target=“_blank”) Grant (2014).\n\n\nG test\nAnother option, the G test, uses a slightly different approach as well. Instead of resampling, the test uses likelihood to compare outcomes. Likelihood asks how likely we were to observed a given set of data given parameter values.\nFor an easy example of likelihood, let’s go back to a one-sample example and focus on just our new finch data. We have 9 old and 9 young birds, so we have a signal of .5 for p. We can use likelihood to calculate how likely our data was under multiple values of p (ranging from 0 - 1, the only options here) and compare the likelihood of those outcomes White (n.d.).\n\n\n\n\n\n\n\n\n\nSimilar to calculating sum square errors from models, what is most likely is what we saw, but we know there is always noise in the data. Thankfully, it turns out the ratio of likelihood values follow a \\(\\chi^2\\) distribution and can thus provide a p-value to compare possible models. We will return to likelihood-based approaches later, in fact, as they can be used for any dataset we can generate a model for and can be used to compare multiple models.\nFor our current contingency analysis, we can develop a model where a species parameter impacts the likelihood and one where it does not (not fully shown here, but shown by Patrone (2022)).\nThe GTest function from the DescTools package to employ this test.\n\nlibrary(DescTools)\nGTest(x = matrix(c(9,7,9,4), 2, 2, byrow = T))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  matrix(c(9, 7, 9, 4), 2, 2, byrow = T)\nG = 0.51774, X-squared df = 1, p-value = 0.4718",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#what-about-more-than-2-groups",
    "href": "content/chapters/Compare_proportions_among_populations.html#what-about-more-than-2-groups",
    "title": "Comparing proportions among groups",
    "section": "What about more than 2 groups?",
    "text": "What about more than 2 groups?\nThese ideas can be extended to compare more than 2 groups with a few important caveats.\n\nThe Fisher test is even less exact since all permutations of the data can seldom be explored\nMore importantly, if we reject the null hypothesis we need to do follow-up tests.\n\nLet’s explore this idea with the Klem data. In addition to considering impacts of age, Klem also recorded the sex (coded as male/female) for each bird. He had data on 4 species.\n\n\n\n\nObserved\n\n\n\n\n\n\n\n\nFinch\nJunco\nRobin\nCardinal\n\n\n\n6\n5\n7\n7\n\n\n\n12\n7\n11\n3\n\n\n\nWe can use the same approaches to test this.\n\nchisq.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow =\nT)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\nX-squared = 3.7909, df = 3, p-value = 0.2849\n\n\nNote our sample size is still a potential issue, but only 1/8 cells has a predicted value less than 1.\n\nchisq.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow =\nT)): Chi-squared approximation may be incorrect\n\n\n          [,1]     [,2]      [,3]     [,4]\n[1,]  7.758621 5.172414  7.758621 4.310345\n[2,] 10.241379 6.827586 10.241379 5.689655\n\n\nwhich means the approximation is fine. We could use the other tests if we preferred.\n\nfisher.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\np-value = 0.2941\nalternative hypothesis: two.sided\n\nGTest(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\nG = 3.8087, X-squared df = 3, p-value = 0.2829\n\n\nRegardless, we see all p&gt;.05. What does this mean?\n\nPost-hoc comparisons: Controlling for the FWER\nWhen we compared one group to a set value or two groups to each other, this was easy: it meant our focal parameter was the same between the groups or between expected and observed values. For more than 2 groups, it means the parameters is also means the parameter of interest does not differ among the groups. In other words, our null hypothesis is\n\\[\nH_O: p_{finch} = p_{junco} = p_{cardinal} = p_{robin}\n\\]\nwhere p is the proportion of the population that are males. Here, this means all species have similar male/female ratios (at least given our samples). This is an example of a very useful insignificant result. This study would have been interesting regardless of outcome.\nHowever, let’s imagine we had data on another species (catbirds in the table below).\n\n\n\n\nObserved\n\n\n\n\n\n\n\n\n\nFinch\nJunco\nRobin\nCardinal\nCatbird\n\n\nMale\n6\n5\n7\n7\n30\n\n\nFemale\n12\n7\n11\n3\n7\n\n\n\nWhen we run the test (notice I immediately checked expected values, or assumptions, which is a good habit to get into)\n\nchisq.test(matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T))\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, :\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, byrow = T)\nX-squared = 17.179, df = 4, p-value = 0.001784\n\nchisq.test(matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, :\nChi-squared approximation may be incorrect\n\n\n          [,1]     [,2]      [,3]     [,4]     [,5]\n[1,] 10.421053 6.947368 10.421053 5.789474 21.42105\n[2,]  7.578947 5.052632  7.578947 4.210526 15.57895\n\n\nWe now have a significant p-value (.002). What does this mean now?\nA significant p-value from a multi-population test means the parameter is not the same for all groups. However, it does not necessarily mean the parameter is different for every group. Remember, our null hypothesis is (now)\n\\[\nH_O: p_{finch} = p_{junco} = p_{cardinal} = p_{robin} = p_{catbird}\n\\]\nWe would reject this if we have evidence any of these qualities are not true. For example, focusing on catbird comparisons for now, we may find\n\\[\n\\begin{split}\np_{catbird} \\neq p_{junco} \\\\\np_{catbird} \\neq p_{cardinal} \\\\\np_{catbird} \\neq p_{robin} \\\\\np_{catbird} \\neq p_{finch} \\\\\n\\end{split}\n\\]\nor we may find\n\\[\n\\begin{split}\np_{catbird} \\neq p_{junco} \\\\\np_{catbird} \\neq p_{cardinal} \\\\\np_{catbird} = p_{robin} \\\\\np_{catbird} = p_{finch} \\\\\n\\end{split}\n\\]\nEither of these outcomes would reject the null hypothesis that proportions were the same for all species, but they mean different things.\nIn general, after we show using an overall, or omnibus, test that there is a difference among populations, we need to determine which ones actually differ from the others. We do this using post-hoc comparisons to compare specific groups.\nWe can technically choose which comparisons to focus on. For example, you can do compare all possible pairs or just certain combinations. Why would this matter?\nThe answer has to do with family-wise error rate (FWER). Remember, for every test we run we have an \\(\\alpha\\)% chance of a type 1 error. If we run many tests, the likelihood of making a type 1 error increases (the rate of increase depends on how independent the tests are, but we need to control for it.\n\n\n\nXKCD 882: Significant\n\n\nFor this reason, we modify our “used” \\(\\alpha\\) for our post-hoc tests. There are many approaches to doing this, but they all depend on how many tests we run - so the more post-hoc comparisons we include, the harder it may be to find a significant difference among focal pairs.\nTo illustrate this, we will first use a very simple method that is no longer recommended but is useful as a starting point. One options is to control the FWER by dividing \\(\\alpha\\) by the number of post-hoc tests we intend to run. For the above example, if we do all pairs comparisons we would be running 10 comparison (4+3+2+1…). So instead of using .05 as a cutoff, we would use .005.\nFirst, it helps to make a table with row and column names (which are slightly different than headers and very different than a column of names in R).\n\nbird_ratio_table &lt;- matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T)\ncolnames(bird_ratio_table) &lt;- c(\"Finch\", \"Junco\", \"Cardinal\", \"Robin\", \"Catbird\")\nrownames(bird_ratio_table) &lt;- c(\"Male\", \"Female\")\n\nThen we can run the test with the pairwiseNominalIndependence function from the rcompanion package. Note the function needs a table or matrix and to know which method to use to compare rows or columns. Looking at the table\n\nbird_ratio_table\n\n       Finch Junco Cardinal Robin Catbird\nMale       6     5        7     7      30\nFemale    12     7       11     3       7\n\n\nLet’ s us see we want to compare columns.\n\nlibrary(rcompanion)\nbonf_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"bonf\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nlibrary(rmarkdown)\npaged_table(bonf_correct)\n\n\n  \n\n\n\nThe test then shows all-pair comparisons with regular (what we should compare to .005 now, but we don’t usually know that!) and adjusted p-values (which have compensated for multiple tests so we can use our normal .05 cutoff- use this one!) for each test we have covered (you should use a post-hoc that matches what you did for the overall, or omnibus, comparison).\nYou can order and display these differently if it helps. For example, if we used the \\(\\chi^2\\) test.\n\npaged_table(bonf_correct[order(bonf_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")])\n\n\n  \n\n\n\nWe see that catbirds different from finches and cardinals in the proportion of males and females, while all other species do not differ. Note the un-adjusted p-value for this comparison pair is the same we would have found from just comparing the two groups\n\nchisq.test(matrix(c(6,30,12,7), nrow=2, byrow=T))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(6, 30, 12, 7), nrow = 2, byrow = T)\nX-squared = 10.189, df = 1, p-value = 0.001413\n\nbonf_correct[bonf_correct$Comparison==\"Finch : Catbird\", \"p.Chisq\"]\n\n[1] 0.00141\n\n\nSince we have 10 comparisons, the adusted value is an order of magnitude larger:\n\npaged_table(bonf_correct[bonf_correct$Comparison==\"Finch : Catbird\", c(\"p.Chisq\", \"p.adj.Chisq\")])\n\n\n  \n\n\n\nIf the un-adjusted p-value was greater than .1, the adjusted value becomes 1. However, this comparison is very conservative. Many other options exist, and we will explore two here.\nThe sequential Bonferroni, or Holm’s, method, allocates your \\(\\alpha\\) to accept as many tests as significant as possible while still controlling for the FWER. To do this, it orders the post-hoc tests by p-value, smallest to largest. It then rejects the null hypothesis attached to the smallest p-value and subtracts that p-value from \\(\\alpha\\). It continues to do this until \\(\\alpha\\) is too small to reject the next smallest p-value. I think of it as buying p-values with \\(\\alpha\\).\nAlternatively, you can consider summing up the smallest p-values associated with the pairs of tests until the cumulative sum is as close as you can get to \\(\\alpha\\).\nWe can use this approach by simply changing the method. Let’s also order our results again for viewing.\n\nholm_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nholm_correct[order(holm_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")]\n\n           Comparison p.adj.Chisq\n4     Finch : Catbird      0.0141\n9  Cardinal : Catbird      0.0428\n7     Junco : Catbird      0.1910\n3       Finch : Robin      0.9940\n1       Finch : Junco      1.0000\n2    Finch : Cardinal      1.0000\n5    Junco : Cardinal      1.0000\n6       Junco : Robin      1.0000\n8    Cardinal : Robin      1.0000\n10    Robin : Catbird      1.0000\n\n\nAlthough we still reject the same null hypotheses, notice the adjusted p-value for the junco:catbird comparison is slightly lower. This is due to the “holm” approach.\nA final approach we will demonstrate is called the False Discovery Rate, or FDR, approach. It’s similar to the Holm’s approach in that it starts by ordering the post-hoc tests by p-value, smallest to largest. However, it then rejects the null hypothesis attached to the largest p-value that is &lt; \\(\\alpha\\) and subsequently rejects all null hypotheses attached to smaller p-values. It is thus less conservative but basically attempts to maximize the number of hypotheses you reject given a set \\(\\alpha\\).\n\nfdr_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"fdr\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nfdr_correct[order(fdr_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")]\n\n           Comparison p.adj.Chisq\n4     Finch : Catbird      0.0141\n9  Cardinal : Catbird      0.0238\n7     Junco : Catbird      0.0797\n3       Finch : Robin      0.3550\n8    Cardinal : Robin      0.4740\n6       Junco : Robin      0.6150\n1       Finch : Junco      1.0000\n2    Finch : Cardinal      1.0000\n5    Junco : Cardinal      1.0000\n10    Robin : Catbird      1.0000\n\n\nAgain, we reject the same null hypotheses, but again you also observe a slight change in p-values. This indicates the important point here is controlling for the FWER. In later chapters we will expand this idea further by focusing on specific subsets of tests or comparisons, although these approaches are less commonly used.",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#goodness-of-fit-tests",
    "href": "content/chapters/Compare_proportions_among_populations.html#goodness-of-fit-tests",
    "title": "Comparing proportions among groups",
    "section": "Goodness of fit tests",
    "text": "Goodness of fit tests\nAbove we focused on comparing proportions among multiple groups using the \\(\\chi^2\\) test. This same approach (comparing expected vs observed values) can also be used to see if a single sample follows a specific distribution. In general, these tests are used to test hypotheses in the form of:\n\\[\n\\begin{split}\nH_O: \\textrm{data come from a particular discrete probability distribution} \\\\\nH_A: \\textrm{data do not come from a particular discrete probability distribution} \\\\\n\\end{split}\n\\]\nFor example, we used a binomial test in earlier chapters to see if our observed number of old (9) and young (9) finches matched a probability of .75.\n\nbinom.test(x=9, n=18, p=.75)\n\n\n    Exact binomial test\n\ndata:  9 and 18\nnumber of successes = 9, number of trials = 18, p-value = 0.02499\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.2601906 0.7398094\nsample estimates:\nprobability of success \n                   0.5 \n\n\nNote we instead consider what we observed vs what we expected using a \\(\\chi^2\\) test.\n\nchisq.test(c(9,9), p=c(.75,.25))\n\nWarning in chisq.test(c(9, 9), p = c(0.75, 0.25)): Chi-squared approximation\nmay be incorrect\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(9, 9)\nX-squared = 6, df = 1, p-value = 0.01431\n\n\nBoth p values are &lt; .05, so we reject the null hypothesis, \\(H_O: p=.75\\) . However, the p values are different? Do you remember why?\nThe \\(\\chi^2\\) test is an approximation! Thus, we prefer the binomial test to the \\(\\chi^2\\) test when we only have 2 categories (binomial data) but for more groups we can use the \\(\\chi^2\\) test. Since we are still using a \\(\\chi^2\\) test, these goodness-of-fit tests have the same assumptions as contingency analysis. If this isn’t true, we can combine categories as needed (note the binomial distribution is the extreme form of combining categories!), or we can use a G-test.\nThe main issue with goodness-of-fit tests is understanding how many degrees of freedom should be used for the null distribution. It usually depends on how many parameters you are estimating. Note, if parameters are determined outside of R, the software may not give appropriate answers.\nFor example, Klem wanted to know if bird strikes differed among months. The null hypothesis was no difference among months, which he tested by assuming a single probability described the likelihood of strikes regardless of month. An alternative (attached to a full model) would have assumed different probabilities for different months.\nIn this case, we estimated one parameter (p), or the number of collisions in one month is determined by the others due to our sample size, so we have 12-1=11 degrees of freedom. If we instead compared our data to a binomial distribution, we might need to estimate p and have one value set by the others. Another common use of goodness-of-fit tests is to determine if the number of offspring (or seeds) match ratios predicted by Punnet square crosses.\nAnother common distribution that data are tested against is the Poisson distribution. It describes the probability that a certain number of events occur in a block of time (or space), when those events happen independently of each other and occur with equal probability at every point in time or space. The Poisson distribution thus matches a null hypothesis that incidents are randomly distributed in space or time. The Poisson distribution is an extension of binomial that occurs when p is very low and n is large. When this occurs, note N-S ~ N (and a few other things happen), which lead to the entire distribution being described by a single parameter \\(\\mu \\approx Np\\), which is the mean and variance.\nThese traits also allow you to determine if data are random, clumped, or uniform. If the mean of a dataset is approximately the same as the variance, the points may be randomly distributed. If the variance is much greater than the mean, the data may be clumped. Alternatively, if the variance is much less than the mean, the data may be uniformly distributed.",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#next-steps",
    "href": "content/chapters/Compare_proportions_among_populations.html#next-steps",
    "title": "Comparing proportions among groups",
    "section": "Next steps",
    "text": "Next steps\nOur following chapters will extend ideas about testing differences among populations, including post-hoc tests, to continuous data.",
    "crumbs": [
      "Chapters",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "",
    "text": "So far we’ve used linear models to consider how categorical predictors and continuous numerical predictors can predict continuous outcomes. We’ve already considered having multiple categorical predictors (remember factorial ANOVAs). Now we’ll extend those ideas to models where we have numerous categorical and/or continuous numerical predictors in the same model. In doing so we’ll introduce (and connect) ANCOVAs, multiple regression, and model selection.",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html#back-to-the-iris-data",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html#back-to-the-iris-data",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Back to the iris data",
    "text": "Back to the iris data\nWe will motivate this (again!) with an example from our favorite iris data. So far we have considered how species impacts sepal lengths (abbreviated analysis:\n\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nlibrary(ggplot2)\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\n\n\n\n\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\nplot(iris_anova)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(iris_anova, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nWe’ve also considered how petal length influences sepal length (abbreviated analysis:\n\nggplot(iris, aes(y=Sepal.Length, x=Petal.Length)) +\n  geom_point() +\n  labs(title=\"Sepal length increases with petal length\",\n       y= \"Sepal length (cm)\",\n       x= \"Petal Length (cm)\") +\n  geom_smooth(method = \"lm\",se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\nplot(iris_regression)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\nHowever, what if we wanted to consider the combined (and potentially interacting) effects of petal length and species on sepal length? This is like our 2-way ANOVA but with one predictor being continuous. This is often called an ANCOVA, but it’s just another linear model! Overall, we are decomposing the variance of each data point among various factors. Our use of type III residuals let’s us ask how much any given factor explains given that other factors are in the model (we’ll explore this more below). Put another way, we might want to know if a factor adds explanatory power to the model (and is not redundant or subsumed by another factor).\nContinuing to use focal iris dataset, we can use the same format we used for factorial or 2-way ANOVAs to add the factors.\n\niris_ancova &lt;- lm(Sepal.Length~Species*Petal.Length, iris)\n\nThis model includes an interaction and matche the following null hypotheses (note 2 are copied from previous sections!):\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length, \\ setosa} = \\mu_{sepal \\ length, \\ virginica} = \\mu_{sepal \\ length, \\ versicolor}\\\\\nH_O: \\beta_\\textrm{(coefficient between sepal and petal length)} = 0\\\\\\\\\nH_O: \\textrm{relationship between petal length and sepal length does not differ\namong species}\\\\\n\\end{split}\n\\]\nOnce we develop the model, we can visually check the assumptions, which remain\n\\[\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n\\]\n\nplot(iris_ancova)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIf assumptions appear to be met (as they do here), we can consider impacts of factors. Given the presence of categorical predictors, an Anova table may be informative\n\nAnova(iris_ancova, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n                      Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept)          12.1053   1 106.9378 &lt; 2.2e-16 ***\nSpecies               2.8991   2  12.8054 7.611e-06 ***\nPetal.Length          0.4346   1   3.8392    0.0520 .  \nSpecies:Petal.Length  0.3810   2   1.6828    0.1895    \nResiduals            16.3007 144                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince the interaction is not significant (F2,144 = 1.68, p = 0.19), we have the same 2 options we noted in factorial ANOVAs.\n\nInterpret results with the interaction\nWe can read results from the full model. These show no interaction between species and petal length (F2,144 = 1.68, p = 0.1895) and no impact of petal length (F1,144=3.83, p = 0.052) but a significant impact of species (F2,144 = 12.81, p &lt; 0.01). We can follow this up with a post-hoc test\n\ncompare_ancova_tukey &lt;- glht(iris_ancova, linfct = mcp(Species = \"Tukey\"))\n\nWarning in mcp2matrix(model, linfct = linfct): covariate interactions found --\ndefault contrast might be inappropriate\n\nsummary(compare_ancova_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species * Petal.Length, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0     -1.8056     0.5984  -3.017  0.00843 ** \nvirginica - setosa == 0      -3.1535     0.6341  -4.973  &lt; 0.001 ***\nvirginica - versicolor == 0  -1.3479     0.6544  -2.060  0.10178    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nwhich suggests I. versicolor and I. virginica are similar to each other but different from other species.\nHowever, note the glht output notes interactions are still present in model, so this approach may be inappropriate. For ANOVA’s we noted could instead compare means for each combination.\n\nlibrary(emmeans)\nemmeans(iris_ancova, pairwise ~ Species*Petal.Length)\n\n$emmeans\n Species    Petal.Length emmean    SE  df lower.CL upper.CL\n setosa             3.76   6.25 0.637 144     4.99     7.51\n versicolor         3.76   5.52 0.070 144     5.38     5.66\n virginica          3.76   4.80 0.163 144     4.48     5.12\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                                   estimate    SE  df\n setosa Petal.Length3.758 - versicolor Petal.Length3.758       0.731 0.641 144\n setosa Petal.Length3.758 - virginica Petal.Length3.758        1.449 0.658 144\n versicolor Petal.Length3.758 - virginica Petal.Length3.758    0.719 0.178 144\n t.ratio p.value\n   1.140  0.4911\n   2.203  0.0740\n   4.044  0.0003\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nThis approach, however, is less useful for numerical predictors. By default the emmeans package uses the average for the covariate (note,\n\nmean(iris$Petal.Length)\n\n[1] 3.758\n\n\nis why we see 3.578 spread throughout the output). While we can specify other breaks, this highlights the difference in combining cateorical variable impacts and combining effects of categorical and continuous variables.\n\n\nRemove the interaction\nSince the interaction isn’t significant, we can also remove it.\n\niris_ancova_updated &lt;- lm(Sepal.Length~Species+Petal.Length, iris)\nplot(iris_ancova_updated)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(iris_ancova_updated, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n              Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept)  137.726   1 1205.394 &lt; 2.2e-16 ***\nSpecies        7.843   2   34.323 6.053e-13 ***\nPetal.Length  22.275   1  194.950 &lt; 2.2e-16 ***\nResiduals     16.682 146                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis shows us that both petal length and species impact sepal length.\nWhy did these factors “suddenly” become significant. The issue lies in that they are not fully independent. Note\n\npetal_anova &lt;- lm(Petal.Length ~ Species, iris)\nplot(petal_anova)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(petal_anova, type =\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Petal.Length\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 106.87   1   577.1 &lt; 2.2e-16 ***\nSpecies     437.10   2  1180.2 &lt; 2.2e-16 ***\nResiduals    27.22 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(petal_anova)\n\n\nCall:\nlm(formula = Petal.Length ~ Species, data = iris)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.260 -0.258  0.038  0.240  1.348 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        1.46200    0.06086   24.02   &lt;2e-16 ***\nSpeciesversicolor  2.79800    0.08607   32.51   &lt;2e-16 ***\nSpeciesvirginica   4.09000    0.08607   47.52   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4303 on 147 degrees of freedom\nMultiple R-squared:  0.9414,    Adjusted R-squared:  0.9406 \nF-statistic:  1180 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nThis shows that species explains a lot (0.9413717 %, in fact) of the variation in petal length. Thus interactions among species and petal length are hard to define, as each species petal lengths are mostly different than the others.\nThis relates to an issue we will soon see. When you consider the impacts of multiple factors on a variable, you are assuming they are not related. That is rarely true (except for when we set up factorial ANOVAs), so we have to decide how related is ok. As factors become more related, the linear model approach does not work.On one level, its hard to split variance correctly among two similar columns. Mathematically, it also makes the design matrix harder to invert.\n\n\nHow does this relate to types of residuals?\n\nThis also relates to the “types” of residuals. Type 1 notes the order of factors in the model. The function anova uses this type. Note the values are different (but still significant) depending on the order.\n\nanova(iris_ancova)\n\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n                      Df Sum Sq Mean Sq  F value Pr(&gt;F)    \nSpecies                2 63.212 31.6061 279.2076 &lt;2e-16 ***\nPetal.Length           1 22.275 22.2745 196.7730 &lt;2e-16 ***\nSpecies:Petal.Length   2  0.381  0.1905   1.6828 0.1895    \nResiduals            144 16.301  0.1132                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nand\n\niris_ancova_reversed &lt;- lm(Sepal.Length~Petal.Length*Species, iris)\nanova(iris_ancova_reversed)\n\nAnalysis of Variance Table\n\nResponse: Sepal.Length\n                      Df Sum Sq Mean Sq  F value    Pr(&gt;F)    \nPetal.Length           1 77.643  77.643 685.8998 &lt; 2.2e-16 ***\nSpecies                2  7.843   3.922  34.6441 5.206e-13 ***\nPetal.Length:Species   2  0.381   0.190   1.6828    0.1895    \nResiduals            144 16.301   0.113                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis is because Type 1 residuals remove all the variation that can be explained by the first factor (even if it could be given to a related factor), then do the same for the second and so forth. So related factors will have different p-values depending on order (unbalanced designs also impact this.)\nType II residuals don’t focus on order, but they ignore interactions. In doing so they ignore any variation that could be attributed to multiple factors.\n\nAnova(iris_ancova, type=\"II\")\n\nAnova Table (Type II tests)\n\nResponse: Sepal.Length\n                      Sum Sq  Df  F value    Pr(&gt;F)    \nSpecies               7.8434   2  34.6441 5.206e-13 ***\nPetal.Length         22.2745   1 196.7730 &lt; 2.2e-16 ***\nSpecies:Petal.Length  0.3810   2   1.6828    0.1895    \nResiduals            16.3007 144                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nType III residuals include interactions, but ask how much a given factor contributes to the explanatory power of a model given main effects of other factors and interactions, including those with the focal factor, are already present. This use of marginal means may seem odd (e.g., asking if a factor should be included when you are already including interactions with said factor) and also means the sum of squares that we get from decomposing the variance adds up to more than the total sum of squares. However, from a conceptual standpoint they work and are thus commonly used.\n\n\n\nWhat would interactions look like?\nSo, what would interactions actually look like, and how would you interpret them? To illustrate this, let’s pretend we visit another valley and sample 3 new iris species (I. baruch, I. hunter, and I. york). We want to see how species and petal length impact sepal length in these species. Let’s make some data to suggest potential outcomes.\n\nNo impact of petal length or species\nFirst, we might find no relationship between the variables. That might looi something like this:\n\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_no_impacts, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nAnova(lm( Sepal_no_impacts~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_impacts\n                      Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)          15.5910  1 50.7890 7.838e-10 ***\nPetal_Length          0.2812  1  0.9162    0.3418    \nSpecies               0.4198  2  0.6838    0.5081    \nPetal_Length:Species  0.4781  2  0.7788    0.4630    \nResiduals            21.1813 69                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nno impact of interaction, so we could drop it\n\nAnova(lm( Sepal_no_impacts~ Petal_Length + Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_impacts\n             Sum Sq Df  F value Pr(&gt;F)    \n(Intercept)  61.439  1 201.3986 &lt;2e-16 ***\nPetal_Length  0.007  1   0.0229 0.8801    \nSpecies       0.043  2   0.0700 0.9325    \nResiduals    21.659 71                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nbut we still find no main effects.\n\n\nImpact of petal length but not species\nAlternatively, we might find a situation where there is a relationship between petal length and sepal length, but no impact of species\n\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_no_impact_species, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nAnova(lm( Sepal_no_impact_species~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_impact_species\n                     Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)           0.233  1  0.2086    0.6493    \nPetal_Length         35.555  1 31.8760 3.375e-07 ***\nSpecies               1.233  2  0.5528    0.5778    \nPetal_Length:Species  1.769  2  0.7931    0.4565    \nResiduals            76.964 69                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nno impact of interaction, so we could drop it\n\nAnova(lm( Sepal_no_impact_species~ Petal_Length + Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_impact_species\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   0.311  1  0.2803    0.5981    \nPetal_Length 89.619  1 80.8172 2.451e-13 ***\nSpecies       2.196  2  0.9901    0.3766    \nResiduals    78.733 71                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nand note only petal length impacts sepal length. We could use summary to see the impact\n\nsummary(lm( Sepal_no_impact_species~ Petal_Length + Species, iris_example_species))\n\n\nCall:\nlm(formula = Sepal_no_impact_species ~ Petal_Length + Species, \n    data = iris_example_species)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.1913 -0.5082 -0.0111  0.6568  2.4913 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     0.3519     0.6646   0.529    0.598    \nPetal_Length    1.9663     0.2187   8.990 2.45e-13 ***\nSpecieshunter  -0.3474     0.2979  -1.166    0.247    \nSpeciesyork    -0.3805     0.3015  -1.262    0.211    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.053 on 71 degrees of freedom\nMultiple R-squared:  0.5375,    Adjusted R-squared:  0.518 \nF-statistic: 27.51 on 3 and 71 DF,  p-value: 6.509e-12\n\n\n\n\nImpact of species but not petal length\nWe could also see an impact of species on sepal length, but no relationship between petal length and sepal length.\n\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_no_relationship_petal, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nAnova(lm( Sepal_no_relationship_petal~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_relationship_petal\n                     Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)           0.928  1  0.7644 0.384996   \nPetal_Length          0.373  1  0.3070 0.581305   \nSpecies              12.282  2  5.0583 0.008914 **\nPetal_Length:Species  4.690  2  1.9314 0.152699   \nResiduals            83.771 69                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nno impact of interaction, so we could drop it\n\nAnova(lm( Sepal_no_relationship_petal~ Petal_Length + Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_relationship_petal\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)    8.924  1  7.1629  0.009236 ** \nPetal_Length   0.052  1  0.0421  0.837988    \nSpecies      230.679  2 92.5730 &lt; 2.2e-16 ***\nResiduals     88.461 71                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nand we find only species impacts sepal length. In that case, we need a post-hoc follow up.\n\nsummary(glht(lm( Sepal_no_relationship_petal~ Petal_Length + Species, iris_example_species), \n             linfct =mcp(Species = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal_no_relationship_petal ~ Petal_Length + Species, \n    data = iris_example_species)\n\nLinear Hypotheses:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \nhunter - baruch == 0   2.2703     0.3157   7.190  &lt; 1e-08 ***\nyork - baruch == 0     4.3452     0.3196  13.597  &lt; 1e-08 ***\nyork - hunter == 0     2.0750     0.3190   6.505 1.77e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nImpact of species and petal length, but no interaction\nWe also might see a difference among the species on sepal length and a relationship between petal length and sepal length, but find the relationship is the same for all species\n\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_no_interaction, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nAnova(lm( Sepal_no_interaction~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_interaction\n                     Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)           2.019  1  2.0815 0.1536187    \nPetal_Length         33.579  1 34.6162 1.305e-07 ***\nSpecies              17.167  2  8.8488 0.0003794 ***\nPetal_Length:Species  1.916  2  0.9876 0.3776779    \nResiduals            66.933 69                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nno impact of interaction, so we could drop it\n\nAnova(lm( Sepal_no_interaction~ Petal_Length + Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_no_interaction\n              Sum Sq Df  F value Pr(&gt;F)    \n(Intercept)    6.700  1   6.9096 0.0105 *  \nPetal_Length 111.746  1 115.2368 &lt;2e-16 ***\nSpecies      225.299  2 116.1681 &lt;2e-16 ***\nResiduals     68.849 71                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nGiven this, we could focus post-hoc tests on which species are different than which others (since the relationship between sepal and petal length is the same)\nand we find only species impacts sepal length. In that case, we need a post-hoc follow up.\n\nsummary(glht(lm( Sepal_no_interaction~ Petal_Length + Species, iris_example_species), \n             linfct =mcp(Species = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal_no_interaction ~ Petal_Length + Species, data = iris_example_species)\n\nLinear Hypotheses:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \nhunter - baruch == 0  -0.3612     0.2785  -1.297    0.402    \nyork - baruch == 0     3.5372     0.2819  12.546   &lt;1e-04 ***\nyork - hunter == 0     3.8983     0.2814  13.852   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nHere we would note that only I. york is different than the other species.\n\n\nImpact of species and petal length that differs among species\nFinally, we could not there is an relationship between petal and sepal length that differs among the species.\n\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_interaction, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nAnova(lm( Sepal_interaction~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n                      Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)            7.076  1   8.0267  0.006038 ** \nPetal_Length          38.452  1  43.6177  6.88e-09 ***\nSpecies                3.353  2   1.9015  0.157092    \nPetal_Length:Species 227.334  2 128.9368 &lt; 2.2e-16 ***\nResiduals             60.828 69                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ninteractions do exist. This means we can’t interpret the “general” relationship, so we need to look for each species using regression.\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"baruch\", ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7194 -0.5504 -0.1860  0.4736  1.7067 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.9734     0.9767   3.044  0.00576 ** \nPetal_Length  -2.3663     0.3335  -7.097 3.14e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8738 on 23 degrees of freedom\nMultiple R-squared:  0.6865,    Adjusted R-squared:  0.6728 \nF-statistic: 50.36 on 1 and 23 DF,  p-value: 3.144e-07\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   7.076  1  9.2676  0.005758 ** \nPetal_Length 38.452  1 50.3604 3.144e-07 ***\nResiduals    17.561 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"hunter\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"hunter\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89221 -0.58055  0.00876  0.47006  2.49756 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    1.2564     1.1463   1.096    0.284\nPetal_Length   0.4962     0.3895   1.274    0.215\n\nResidual standard error: 0.9902 on 23 degrees of freedom\nMultiple R-squared:  0.06589,   Adjusted R-squared:  0.02528 \nF-statistic: 1.622 on 1 and 23 DF,  p-value: 0.2155\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"hunter\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value Pr(&gt;F)\n(Intercept)   1.1779  1  1.2014 0.2844\nPetal_Length  1.5907  1  1.6224 0.2155\nResiduals    22.5503 23               \n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"york\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"york\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.45150 -0.69660  0.02717  0.83006  1.64698 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    4.0617     0.9550   4.253    3e-04 ***\nPetal_Length   4.9642     0.3024  16.417  3.4e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9491 on 23 degrees of freedom\nMultiple R-squared:  0.9214,    Adjusted R-squared:  0.918 \nF-statistic: 269.5 on 1 and 23 DF,  p-value: 3.401e-14\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"york\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   16.292  1  18.087 0.0002998 ***\nPetal_Length 242.770  1 269.527 3.401e-14 ***\nResiduals     20.717 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere we see that there is a significant negative relationship (F~1,23 = 50.36, p&lt;0.001) between sepal and petal length for I. baruch, a significant positive relationship (F~1,23 = 269.53, p&lt;0.001) between sepal and petal length for I. york,and no relationship (F~1,23 = 1.63, p&lt;-0.21) between sepal and petal length for I. hunter.",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html#extensions-to-multiple-regression",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html#extensions-to-multiple-regression",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Extensions to multiple regression",
    "text": "Extensions to multiple regression\nJust as we can extend the 2-way ANOVA ideas to ANCOVA, it turns out we can extend these ideas further to include even more variables (and their interactions, if we want) using our linear model framework. At each stage we are continuing to partition variance among factors and ask (using our type III residuals) how “much” better a given factor makes a model.\nFor example, we can return to our FEV data from the previous chapters practice problems. Remember, we investigated the impact of age,\n\n#fev data####\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T,\n                  stringsAsFactors = T)\nhead(fev)\n\n    ID Age   FEV Height    Sex Smoker\n1  301   9 1.708   57.0 Female    Non\n2  451   8 1.724   67.5 Female    Non\n3  501   7 1.720   54.5 Female    Non\n4  642   9 1.558   53.0   Male    Non\n5  901   9 1.895   57.0   Male    Non\n6 1701   8 2.336   61.0 Female    Non\n\nfev_age &lt;- lm(FEV ~ Age, fev)\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)   9.89   1  30.707 4.359e-08 ***\nAge         280.92   1 872.184 &lt; 2.2e-16 ***\nResiduals   210.00 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.57539 -0.34567 -0.04989  0.32124  2.12786 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.431648   0.077895   5.541 4.36e-08 ***\nAge         0.222041   0.007518  29.533  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5675 on 652 degrees of freedom\nMultiple R-squared:  0.5722,    Adjusted R-squared:  0.5716 \nF-statistic: 872.2 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n#age plot####\nggplot(fev, aes(x=Age, y=FEV)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  labs(y=\"FEV (liters)\",\n       x= \"Age (years)\",\n       title =\"FEV increases with age\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nheight,\n\nfev_height &lt;- lm(FEV ~ Height, fev)\nplot(fev_height)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_height, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 166.25   1  896.33 &lt; 2.2e-16 ***\nHeight      369.99   1 1994.73 &lt; 2.2e-16 ***\nResiduals   120.93 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_height)\n\n\nCall:\nlm(formula = FEV ~ Height, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.75167 -0.26619 -0.00401  0.24474  2.11936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -5.432679   0.181460  -29.94   &lt;2e-16 ***\nHeight       0.131976   0.002955   44.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4307 on 652 degrees of freedom\nMultiple R-squared:  0.7537,    Adjusted R-squared:  0.7533 \nF-statistic:  1995 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n#height plot####\nggplot(fev, aes(x=Height, y=FEV)) +\n  geom_point() +\n  geom_smooth(method = \"lm\") +\n    labs(y=\"FEV (liters)\",\n       x= \"Height (inches)\",\n       title =\"FEV increases with height\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nand gender\n\nfev_gender &lt;- lm(FEV ~ Sex, fev)\nplot(fev_gender) #anova is fine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_gender, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n             Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 1910.62   1 2652.756 &lt; 2.2e-16 ***\nSex           21.32   1   29.607 7.496e-08 ***\nResiduals    469.60 652                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_gender)\n\n\nCall:\nlm(formula = FEV ~ Sex, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01645 -0.69420 -0.06367  0.58233  2.98055 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.45117    0.04759  51.505  &lt; 2e-16 ***\nSexMale      0.36128    0.06640   5.441  7.5e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8487 on 652 degrees of freedom\nMultiple R-squared:  0.04344,   Adjusted R-squared:  0.04197 \nF-statistic: 29.61 on 1 and 652 DF,  p-value: 7.496e-08\n\n#gender plot ####\n\n#bar chart with error bars ####\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(fev, measurevar=\"FEV\", groupvars =\n                               c(\"Sex\"))\n\nggplot(function_output, aes(x=Sex, y=FEV)) +\n  geom_col() +\n  ylab(\"FEV\") +\n  geom_errorbar(aes(ymin=FEV-ci, ymax=FEV+ci), size=1.5) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\non outcomes and found all were significant predictors. However, these variables are correlated. For example, there is a relationship between height and gender\n\nheight_gender &lt;- lm(Height ~ Sex, fev)\nplot(height_gender) #anova is fine\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(height_gender, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Height\n             Sum Sq  Df   F value    Pr(&gt;F)    \n(Intercept) 1152902   1 36305.026 &lt; 2.2e-16 ***\nSex             537   1    16.917 4.405e-05 ***\nResiduals     20705 652                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(height_gender)\n\n\nCall:\nlm(formula = Height ~ Sex, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-15.0253  -3.7119   0.7881   4.2881  11.9747 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  60.2119     0.3160 190.539  &lt; 2e-16 ***\nSexMale       1.8133     0.4409   4.113  4.4e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5.635 on 652 degrees of freedom\nMultiple R-squared:  0.02529,   Adjusted R-squared:  0.0238 \nF-statistic: 16.92 on 1 and 652 DF,  p-value: 4.405e-05\n\n#gender plot ####\n\n#bar chart with error bars ####\nfunction_output &lt;- summarySE(fev, measurevar=\"Height\", groupvars =\n                               c(\"Sex\"))\n\nggplot(function_output, aes(x=Sex, y=Height)) +\n  geom_col() +\n  ylab(\"Height\") +\n  geom_errorbar(aes(ymin=Height-ci, ymax=Height+ci)) \n\n\n\n\n\n\n\n\nSo we may want to know if we can do better with a larger model.\nTo begin with, notice we are slightly changing the question. We are moving from hypothesis-based analysis to a decision to find the “best” model. However, we are still trying to use a linear model framework, so our predictor variables need to be independent (or at least somewhat independent). We can consider this by noting the relationship among all predictor variables. The pairs function is one way to do this; the added portion below shows r values (correlations) among variables and marks significant relationships using asterisks (any asterisk indicates a p value of &lt; .05):\n\nlibrary(psych)\npairs.panels(fev, stars=T)\n\n\n\n\n\n\n\n\nNote we significant relationships among FEV and several variagles (e.g., age), but also among several predictor variables (e.gl, height and age). This makes sense (people tend to grow for first 20ish years!), but the r2 between height and age is only 64%.\n\ncor.test(~ Age + Height, fev)\n\n\n    Pearson's product-moment correlation\n\ndata:  Age and Height\nt = 33.118, df = 652, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7615128 0.8188906\nsample estimates:\n      cor \n0.7919436 \n\n\nWhile there is no hard limit, if 2 variables share an r2 value of greater than 80%, only one should be included in the model. 60-70% is even better.\nFor now, let’s retain all factors and consider how we can carry out model selection.\n\nOption 1: Run full model and interpet outcomes\nOne option is to construct a large model,\n\nfev_full &lt;- lm(FEV ~ Age * Height * Sex * Smoker, fev)\n\ncheck it,\n\nplot(fev_full)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nand interpret outcomes if assumptions are met.\n\nAnova(fev_full, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n                      Sum Sq  Df F value  Pr(&gt;F)  \n(Intercept)            0.547   1  3.7336 0.05377 .\nAge                    0.557   1  3.8008 0.05167 .\nHeight                 0.426   1  2.9068 0.08869 .\nSex                    0.595   1  4.0635 0.04424 *\nSmoker                 0.661   1  4.5134 0.03402 *\nAge:Height             0.555   1  3.7859 0.05213 .\nAge:Sex                0.256   1  1.7478 0.18663  \nHeight:Sex             0.589   1  4.0174 0.04546 *\nAge:Smoker             0.536   1  3.6616 0.05613 .\nHeight:Smoker          0.620   1  4.2352 0.04000 *\nSex:Smoker             0.711   1  4.8534 0.02795 *\nAge:Height:Sex         0.250   1  1.7090 0.19159  \nAge:Height:Smoker      0.495   1  3.3772 0.06657 .\nAge:Sex:Smoker         0.423   1  2.8874 0.08976 .\nHeight:Sex:Smoker      0.708   1  4.8324 0.02829 *\nAge:Height:Sex:Smoker  0.428   1  2.9204 0.08795 .\nResiduals             93.465 638                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThis (and the following) approaches assume you chosen legitimate predictor variables (you have a reason/mechanism for explaining their impact).\n\n\nOption 2: Remove or add variables using p-values\nAnother option is to start with the full model and remove factors (or their interactions) until all are “significant”. You can do this by building models manually or using automated approaches like the drop1 function.\n\ndrop1(fev_full, test=\"F\")\n\nSingle term deletions\n\nModel:\nFEV ~ Age * Height * Sex * Smoker\n                      Df Sum of Sq    RSS     AIC F value  Pr(&gt;F)  \n&lt;none&gt;                             93.465 -1240.4                  \nAge:Height:Sex:Smoker  1   0.42783 93.893 -1239.4  2.9204 0.08795 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNotice it considers highest order interactions first. This indicates we should drop the 4-way interaction term, so we do that and continue\n\nfev_full_working &lt;- update(fev_full, .~.- Age:Height:Sex:Smoker)\ndrop1(fev_full_working, test = \"F\")\n\nSingle term deletions\n\nModel:\nFEV ~ Age + Height + Sex + Smoker + Age:Height + Age:Sex + Height:Sex + \n    Age:Smoker + Height:Smoker + Sex:Smoker + Age:Height:Sex + \n    Age:Height:Smoker + Age:Sex:Smoker + Height:Sex:Smoker\n                  Df Sum of Sq    RSS     AIC F value    Pr(&gt;F)    \n&lt;none&gt;                         93.893 -1239.4                      \nAge:Height:Sex     1   1.67744 95.570 -1229.8 11.4160 0.0007724 ***\nAge:Height:Smoker  1   0.08082 93.974 -1240.8  0.5500 0.4585756    \nAge:Sex:Smoker     1   0.00474 93.898 -1241.3  0.0322 0.8575529    \nHeight:Sex:Smoker  1   1.20821 95.101 -1233.0  8.2226 0.0042735 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNow we can drop another interaction term\n\nfev_full_working &lt;- update(fev_full_working, .~.- Age:Sex:Smoker)\ndrop1(fev_full_working, test = \"F\")\n\nSingle term deletions\n\nModel:\nFEV ~ Age + Height + Sex + Smoker + Age:Height + Age:Sex + Height:Sex + \n    Age:Smoker + Height:Smoker + Sex:Smoker + Age:Height:Sex + \n    Age:Height:Smoker + Height:Sex:Smoker\n                  Df Sum of Sq    RSS     AIC F value    Pr(&gt;F)    \n&lt;none&gt;                         93.898 -1241.3                      \nAge:Height:Sex     1    1.6786 95.576 -1231.8 11.4412 0.0007621 ***\nAge:Height:Smoker  1    0.0811 93.979 -1242.8  0.5528 0.4574650    \nHeight:Sex:Smoker  1    1.2755 95.173 -1234.5  8.6939 0.0033091 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nand another\n\nfev_full_working &lt;- update(fev_full_working, .~.- Age:Height:Smoker)\ndrop1(fev_full_working, test = \"F\")\n\nSingle term deletions\n\nModel:\nFEV ~ Age + Height + Sex + Smoker + Age:Height + Age:Sex + Height:Sex + \n    Age:Smoker + Height:Smoker + Sex:Smoker + Age:Height:Sex + \n    Height:Sex:Smoker\n                  Df Sum of Sq    RSS     AIC F value    Pr(&gt;F)    \n&lt;none&gt;                         93.979 -1242.8                      \nAge:Smoker         1    1.4059 95.385 -1235.1  9.5893 0.0020425 ** \nAge:Height:Sex     1    1.7363 95.715 -1232.8 11.8424 0.0006166 ***\nHeight:Sex:Smoker  1    1.1946 95.173 -1236.5  8.1478 0.0044507 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nand so on until all interactions or main effects are significant (like we see now). This approach requires nested models (you compare a model without a given factor to one that has it - type III residuals!).\nAlternatively, you can build a simple model\n\nfev_under &lt;- lm(FEV ~ 1, fev)\n\nand add factors to it until none are significant (not fully shown here).\n\nadd1(fev_under, ~ Age + Height + Sex, test = \"F\")\n\nSingle term additions\n\nModel:\nFEV ~ 1\n       Df Sum of Sq    RSS      AIC  F value    Pr(&gt;F)    \n&lt;none&gt;              490.92  -185.58                       \nAge     1    280.92 210.00  -738.94  872.184 &lt; 2.2e-16 ***\nHeight  1    369.99 120.93 -1099.86 1994.731 &lt; 2.2e-16 ***\nSex     1     21.32 469.60  -212.63   29.607 7.496e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nfev_under_a &lt;- update(fev_under, .~. + Age)\nadd1(fev_under_a, ~ . + Height + Sex, test = \"F\")\n\nSingle term additions\n\nModel:\nFEV ~ Age\n       Df Sum of Sq    RSS      AIC F value    Pr(&gt;F)    \n&lt;none&gt;              210.00  -738.94                      \nHeight  1    95.326 114.67 -1132.62 541.157 &lt; 2.2e-16 ***\nSex     1    17.066 192.94  -792.37  57.583 1.125e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nOption 3: Compare models (nested or not) using AIC\nYou may have noted the AIC values above. AIC is “an information criteria” that uses maximum likelihood to compare models.\n\n\nRemember that? from the chapter on comparing proportions\n\nFor an easy example of likelihood, let’s go back to a one-sample example of comparing a proportion to a sample and focus on finch data. We have 9 old and 9 young birds, so we have a signal of .5 for p. We can use likelihood to calculate how likely our data was under multiple values of p (ranging from 0 - 1, the only options here) and compare the likelihood of those outcomes White (n.d.).\n\n\n\n\n\n\n\n\n\nSimilar to calculating sum square errors from models, what is most likely is what we saw, but we know there is always noise in the data. Thankfully, it turns out the ratio of likelihood values follow a \\(\\chi^2\\) distribution and can thus provide a p-value to compare possible models. We will return to likelihood-based approaches later, in fact, as they can be used for any dataset we can generate a model for and can be used to compare multiple models.\n\nTo do so, it obtains a likelihood value for a model and takes a log of it. It then multiples that by -2 and adds a penalty parameter multiplied by the number of parameters in the model. Why? Because the algorithms used mean an extra parameter will always make a model better (or at least no worse).\nThe true AIC process uses a penalty parameter of 2; other approaches vary this. The Bayesian information criterion (BIC), for example, uses a penalty parameter of of log(n), where n is the number of observations. Given this formula, the “best” model has the lowest AIC value.\nAIC and other information criteria can be used to compare nested models (the value of adding or removing a single variable). This can be done in a few ways. The default for drop1 focuses on AIC\n\ndrop1(fev_full)\n\nSingle term deletions\n\nModel:\nFEV ~ Age * Height * Sex * Smoker\n                      Df Sum of Sq    RSS     AIC\n&lt;none&gt;                             93.465 -1240.4\nAge:Height:Sex:Smoker  1   0.42783 93.893 -1239.4\n\n\nbut we can also automate this process using the stepAIC function\n\nstepAIC(fev_full)\n\nStart:  AIC=-1240.37\nFEV ~ Age * Height * Sex * Smoker\n\n                        Df Sum of Sq    RSS     AIC\n&lt;none&gt;                               93.465 -1240.4\n- Age:Height:Sex:Smoker  1   0.42783 93.893 -1239.4\n\n\n\nCall:\nlm(formula = FEV ~ Age * Height * Sex * Smoker, data = fev)\n\nCoefficients:\n                 (Intercept)                           Age  \n                    25.71051                      -1.95406  \n                      Height                       SexMale  \n                    -0.34974                     -31.17265  \n                   SmokerNon                    Age:Height  \n                   -28.32508                       0.03009  \n                 Age:SexMale                Height:SexMale  \n                     1.60183                       0.47343  \n               Age:SmokerNon              Height:SmokerNon  \n                     1.92939                       0.42323  \n           SexMale:SmokerNon            Age:Height:SexMale  \n                    34.15472                      -0.02410  \n        Age:Height:SmokerNon         Age:SexMale:SmokerNon  \n                    -0.02860                      -2.07178  \n    Height:SexMale:SmokerNon  Age:Height:SexMale:SmokerNon  \n                    -0.52090                       0.03172  \n\n\nAIC and IC can also be used to compare non-nested models. For example, the dredge function in the MuMin package takes a large model and copmares all outcomes.\n\nlibrary(MuMIn)\noptions(na.action = \"na.fail\")\nauto &lt;- dredge(fev_full)\n\nFixed term is \"(Intercept)\"\n\nlibrary(rmarkdown)\npaged_table(auto)\n\n\n  \n\n\n\nThe output shows us which factors lead to the smallest AIC value (here using the small sample correction, the AICc value). One benefit of this approach is we may find multiple models have similar AIC values. Delta (difference) values of &lt;2 mean models are supported (Burnham and Anderson 2004).\n\nModels having \\(\\Delta_i\\) ≤ 2 have substantial support (evidence), those in which 4 ≤ \\(\\Delta_i\\) ≤ 7 have considerably less support, and models having \\(\\Delta_i\\) &gt; 10 have essentially no support.\n\nWe can actually average supported models using their weight to find an “final” model (code shown here, but note we only have one model meeting this criteria and thus receive an error.\n\nmodel.avg(auto, subset = delta &lt; 2)\n\n\nCall:\nmodel.avg(object = auto, subset = delta &lt; 2)\n\nComponent models: \n'1+2+3+4+5+6+7+8+9+10+11+13'    '1+2+3+4+5+6+7+8+9+10+11+12+13'\n\nCoefficients: \n       (Intercept)        Age       Height   SexMale SmokerNon  Age:Height\nfull      3.103673 -0.2360365 -0.001240504 -4.865981  -5.58118 0.003591144\nsubset    3.103673 -0.2360365 -0.001240504 -4.865981  -5.58118 0.003591144\n       Age:SexMale Age:SmokerNon Height:SexMale Height:SmokerNon\nfull    -0.4448419     0.1907352     0.07042723       0.07253359\nsubset  -0.4448419     0.1907352     0.07042723       0.07253359\n       SexMale:SmokerNon Age:Height:SexMale Height:SexMale:SmokerNon\nfull            7.681415        0.007223447               -0.1152972\nsubset          7.681415        0.007223447               -0.1152972\n       Age:Height:SmokerNon\nfull           -0.001775413\nsubset         -0.005591655\n\n\nWhile AIC and other IC may be an interesting approach, a few points should be made.\n\nAIC values are relative only to models fit with the same data in the same way.\n\nSo there is no “good” AIC value\nDifferent programs may use different additive components, so be careful in using functions or different pieces of software to calculate AIC for different models that you want to compare. In R, an easy example is the following functions (both in base R) give different output (as noted in their respective help files)\n\nAIC(fev_full)\n\n[1] 617.602\n\nextractAIC(fev_full)\n\n[1]    16.00 -1240.37\n\n\n\nAIC outcomes actually correspond to using an \\(\\alpha\\) level of .15 (Steyerberg et al. 2000), so AIC approaches typically favor larger models\nAIC relies on large-sample approximations\n\nAICc corrects for small samples and can always be used.\n\nModels that are being compared must focus on the same set of outcomes. One model can’t use fewer rows due to missing data, and different responses (we’ll cover transformations and glms in a few chapters) can’t be compared. Note, however, models may differ in the number of explanatory variables.\n\n\n\nOption 4: Compare r2 (or adjusted r2) values\nThis option is noted here as it was more common in the past, but now it should not be used. If it is used, however, one should compare adjusted r2 values since the r2 values my be connected to larger but less useful models.",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html#final-model-checks",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html#final-model-checks",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Final model checks",
    "text": "Final model checks\nRegardless of the the method that is used, the linear models still need to meet basic assumptions. For this reason, the final model (and probably all those developed in route to getting there, though this rarely happens) should be assessed for assumptions.\nA new approach we have not used previously focuses on variance inflation factors (vif) to ensure collinearity (more on this in next section) isn’t an issue. In general you want these values to be less than 5. When working with normal linear models, especially those have factors that have more than 2 levels, focusing on the generalized form of the vif for predictors is appropriate.\n\nvif(fev_full_working, type=\"predictor\")\n\nGVIFs computed for predictors\n\n\n       GVIF Df GVIF^(1/(2*Df))      Interacts With Other Predictors\nAge       1 12               1 Height, Sex, Smoker             --  \nHeight    1 12               1    Age, Sex, Smoker             --  \nSex       1 12               1 Age, Height, Smoker             --  \nSmoker    1 12               1    Age, Height, Sex             --",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html#important-differences",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html#important-differences",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Important differences",
    "text": "Important differences\nOne major difference between ANCOVA/ANOVA and multiple regression is that multiple regression, especially with larger models, is often more focused on outcomes/prediction than explanation. This differs from the focus on null hypothesis significance testing (NHST) that we have been focused on in previous chapters, but the mathematical approaches remain the same via the use of the linear model.",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Combining_numerical_and_categorical_predictors.html#next-steps",
    "href": "content/chapters/Combining_numerical_and_categorical_predictors.html#next-steps",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Next steps",
    "text": "Next steps\nThese methods can be extended to other models that are used when linear model assumptions are not met, which is the focus of the next chapter.",
    "crumbs": [
      "Chapters",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/chapters/Acquiring_data.html",
    "href": "content/chapters/Acquiring_data.html",
    "title": "Acquiring data",
    "section": "",
    "text": "Let’s start our statistics journey by thinking about the simplest scenario: We want to know something about a group. An example might be the average (also known as the mean, we will define later if needed!), the minimum value, or the maximum value for some trait. These questions all deal with the distribution of values for that trait in the group. These specific traits of the group distribution are called statistics:\n\nthe numerical facts or data themselves - Dictionary.com\n\nThis means we have a target trait we are focused on, and we have defined a group of interest. We can call this group of interest a population. Note that while the term population may have specific meanings in some fields (such as ecology), here population is just the group of interest. It could be a population of Goliath grouper in Florida, a population of flowers in Virginia, or people from a certain country or demographic group. We could want to know something about all of these groups!\nAs we’ve already noted, in a perfect world we know everything (or at least everything about our trait value) for every member of the focal population. However, we often don’t and can’t measure every member of a population. It may be too difficult or expensive to measure every member of the population. In fact, we may not even know how large the population is!\nIn the cases where we can’t measure every member of the population, we collect data on the focal trait(s) from a sample. A sample is the subset of the population of interest. Data can be collected from samples used in experimental studies, where researchers manipulate something to see how it impacts the focal trait. Researchers may expose organisms to different stimuli in controlled lab, field, or mesocosm studies to see what happens. For example, researchers interested in impacts of an invasive crayfish (Pacifastacus leniusculus) on Mazama newts (Taricha granulosa mazamae) collected newts and crayfish.; they then placed either just newts or newts and crayfish in in large tanks to observe interactions (Girdner et al. 2018).\n\n\n\n\n\n\nFigure 1: Experimental mesocosms used to evaluate Mazama newt and signal crayfish behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists observed the interaction between newts and crayfish in tanks designed to mimic natural habitat. NPS photo, public domain.\n\n\n\nData can also be collected from observational studies, where researchers “simply” measure outcomes and other traits without manipulating anything. For example, scientists interested in impacts of climate change on species ranges surveyed sites for species presence and abundance and compared it to historical data (Sagarin et al. 1999). Note doing this may actually be very difficult! Metcalfe, Yaicurima, and Papworth (2022) found that just observing capuchin monkeys (Sapajus macrocephalus) changed their behavior.\n\n\n\nLarge-headed capuchins studied by Metcalfe et al (2022) changed their behavior based on observer density and distance. Cody H., CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&gt;, via Wikimedia Commons.\n\n\nDifferent types of studies change what we can use the data for. We’ll come back to this later, but, in general, experimental studies are more commonly used to ascertain causation (something makes something happen), whereas observational studies are used to assess correlation (something happens when something else happens, also known as association). However, these can be hard to disentangle, especially since studies can only be observational since experiments would be unethical or impossible to carry out. As XKCD puts it\n\n\n\n\n\n\nFigure 2: XKCD: Correlation. Title text (text that pops up when you hover over the comic): Correlation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’. https://xkcd.com/552/, CC BY-NC 2.5 &lt;https://creativecommons.org/licenses/by-nc/2.5/&gt;.\n\n\n\n\nCorrelation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’ - XKCD #552\n\nOnce we have the sample, we can measure the trait of interest in it, and use that to estimate the statistic of interest for the actual population. This is the science of statistics, which can actually be defined as\n\nthe practice or science of collecting and analyzing numerical data in large quantities, especially for the purpose of inferring proportions in a whole from those in a representative sample. - Oxford English Dictionary\n\nIf the whole idea of statistics is to infer something about the population from our sample, we need to make sure the sample is representative of the population. That means it should not be biased. Bias occurs if the trait values we measure in our sample differ from the population in a consistent way. This can happen with samples of convenience, or when researchers select samples that are easy to measure but may not be representative of the population. Classic examples include estimating the amount of time students spend studying by surveying students at a campus library.\nBias may also be related to issues of independence. In a good sampling design, every member of the population has the same chance of being included in a sample. Samples of convenience violate this premise, and often the underlying issue is that the samples are not independent. A perfect solution is to randomly choose members of the population to be in the sample, but that is often not possible. Again, it requires knowing every member of the population! Independence also means each data point is not related to any others!\n\n\n\n\n\n\nFigure 3: XKCD: Slope Hypothesis Testing. Don’t worry, we’ll come back to significance - but what is the independence issue? https://xkcd.com/2533/, , CC BY-NC 2.5 &lt;https://creativecommons.org/licenses/by-nc/2.5/&gt;.\n\n\n\nIn some cases linkages among samples are impossible to avoid. We will cover ways to address that using blocking factors or random effects later.\nNotice in discussing bias this way we are not directly focusing on the quality of the measurements. Obviously we need good data to make good estimates, but these ideas are different from our current focus on picking a good sample. If we want to discuss the quality of our measurements, we could think about accuracy (how well we measure the underlying trait in regards to its true value, which we typically don’t know) and precision (how repeatable our measurement technique is).\n\n\n\nExample of accuracy and precision. From sketchplantations.com, https://sketchplanations.com/accuracy-and-precision, CC BY-NC 4.0 &lt;https://creativecommons.org/licenses/by-nc/4.0/&gt;\n\n\nEven if we have a proper way to measure a trait (accurate and precise) in a good sample (not biased), we will still be producing an estimate of the population statistic! This is due to sampling error. Sampling error refers to the fact that every sample will produce a slightly different estimate of the statistic. Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their length, and use it calculate the average fish length. If we took a different sample, do you think it would have exactly the same average?\nWe can demonstrate this in R - you won’t understand the code below yet, so just trust me for now, but this will let you start seeing code and thinking about how to use it.\nLet’s generate a population of fish. We’ll store their lengths in a vector called lengths.\n\nlengths &lt;- rnorm(n=1000, mean = 10, sd=1)\n\nThe average length of fish in this population is 10.02 cm (Note: if you view this on the webpage you will see a number, but in the actual qmd file you see R code here - this is an example of merging code and text!). We can then simulate a sample from this population. In fact, let’s simulate 2 and compare the means of each.\n\nsample_1 &lt;- sample(lengths,50)\nsample_2 &lt;-sample(lengths, 50)\n\nThe mean length for fish in sample 1 is 10.03 cm, while that in sample 2 is 10 cm . These are both close to the true value, but they are also both slightly different - this is sampling error!\nSampling error always exists, and a major part of statistics is to quantify it. One thing that reduces sampling error is to have large samples! Remember, if we measure every member of the population we don’t even need statistics, so the closer we get to that (implying larger samples) the better!",
    "crumbs": [
      "Chapters",
      "Acquiring data"
    ]
  },
  {
    "objectID": "content/chapters/Acquiring_data.html#how-do-we-get-data",
    "href": "content/chapters/Acquiring_data.html#how-do-we-get-data",
    "title": "Acquiring data",
    "section": "",
    "text": "Let’s start our statistics journey by thinking about the simplest scenario: We want to know something about a group. An example might be the average (also known as the mean, we will define later if needed!), the minimum value, or the maximum value for some trait. These questions all deal with the distribution of values for that trait in the group. These specific traits of the group distribution are called statistics:\n\nthe numerical facts or data themselves - Dictionary.com\n\nThis means we have a target trait we are focused on, and we have defined a group of interest. We can call this group of interest a population. Note that while the term population may have specific meanings in some fields (such as ecology), here population is just the group of interest. It could be a population of Goliath grouper in Florida, a population of flowers in Virginia, or people from a certain country or demographic group. We could want to know something about all of these groups!\nAs we’ve already noted, in a perfect world we know everything (or at least everything about our trait value) for every member of the focal population. However, we often don’t and can’t measure every member of a population. It may be too difficult or expensive to measure every member of the population. In fact, we may not even know how large the population is!\nIn the cases where we can’t measure every member of the population, we collect data on the focal trait(s) from a sample. A sample is the subset of the population of interest. Data can be collected from samples used in experimental studies, where researchers manipulate something to see how it impacts the focal trait. Researchers may expose organisms to different stimuli in controlled lab, field, or mesocosm studies to see what happens. For example, researchers interested in impacts of an invasive crayfish (Pacifastacus leniusculus) on Mazama newts (Taricha granulosa mazamae) collected newts and crayfish.; they then placed either just newts or newts and crayfish in in large tanks to observe interactions (Girdner et al. 2018).\n\n\n\n\n\n\nFigure 1: Experimental mesocosms used to evaluate Mazama newt and signal crayfish behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists observed the interaction between newts and crayfish in tanks designed to mimic natural habitat. NPS photo, public domain.\n\n\n\nData can also be collected from observational studies, where researchers “simply” measure outcomes and other traits without manipulating anything. For example, scientists interested in impacts of climate change on species ranges surveyed sites for species presence and abundance and compared it to historical data (Sagarin et al. 1999). Note doing this may actually be very difficult! Metcalfe, Yaicurima, and Papworth (2022) found that just observing capuchin monkeys (Sapajus macrocephalus) changed their behavior.\n\n\n\nLarge-headed capuchins studied by Metcalfe et al (2022) changed their behavior based on observer density and distance. Cody H., CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&gt;, via Wikimedia Commons.\n\n\nDifferent types of studies change what we can use the data for. We’ll come back to this later, but, in general, experimental studies are more commonly used to ascertain causation (something makes something happen), whereas observational studies are used to assess correlation (something happens when something else happens, also known as association). However, these can be hard to disentangle, especially since studies can only be observational since experiments would be unethical or impossible to carry out. As XKCD puts it\n\n\n\n\n\n\nFigure 2: XKCD: Correlation. Title text (text that pops up when you hover over the comic): Correlation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’. https://xkcd.com/552/, CC BY-NC 2.5 &lt;https://creativecommons.org/licenses/by-nc/2.5/&gt;.\n\n\n\n\nCorrelation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’ - XKCD #552\n\nOnce we have the sample, we can measure the trait of interest in it, and use that to estimate the statistic of interest for the actual population. This is the science of statistics, which can actually be defined as\n\nthe practice or science of collecting and analyzing numerical data in large quantities, especially for the purpose of inferring proportions in a whole from those in a representative sample. - Oxford English Dictionary\n\nIf the whole idea of statistics is to infer something about the population from our sample, we need to make sure the sample is representative of the population. That means it should not be biased. Bias occurs if the trait values we measure in our sample differ from the population in a consistent way. This can happen with samples of convenience, or when researchers select samples that are easy to measure but may not be representative of the population. Classic examples include estimating the amount of time students spend studying by surveying students at a campus library.\nBias may also be related to issues of independence. In a good sampling design, every member of the population has the same chance of being included in a sample. Samples of convenience violate this premise, and often the underlying issue is that the samples are not independent. A perfect solution is to randomly choose members of the population to be in the sample, but that is often not possible. Again, it requires knowing every member of the population! Independence also means each data point is not related to any others!\n\n\n\n\n\n\nFigure 3: XKCD: Slope Hypothesis Testing. Don’t worry, we’ll come back to significance - but what is the independence issue? https://xkcd.com/2533/, , CC BY-NC 2.5 &lt;https://creativecommons.org/licenses/by-nc/2.5/&gt;.\n\n\n\nIn some cases linkages among samples are impossible to avoid. We will cover ways to address that using blocking factors or random effects later.\nNotice in discussing bias this way we are not directly focusing on the quality of the measurements. Obviously we need good data to make good estimates, but these ideas are different from our current focus on picking a good sample. If we want to discuss the quality of our measurements, we could think about accuracy (how well we measure the underlying trait in regards to its true value, which we typically don’t know) and precision (how repeatable our measurement technique is).\n\n\n\nExample of accuracy and precision. From sketchplantations.com, https://sketchplanations.com/accuracy-and-precision, CC BY-NC 4.0 &lt;https://creativecommons.org/licenses/by-nc/4.0/&gt;\n\n\nEven if we have a proper way to measure a trait (accurate and precise) in a good sample (not biased), we will still be producing an estimate of the population statistic! This is due to sampling error. Sampling error refers to the fact that every sample will produce a slightly different estimate of the statistic. Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their length, and use it calculate the average fish length. If we took a different sample, do you think it would have exactly the same average?\nWe can demonstrate this in R - you won’t understand the code below yet, so just trust me for now, but this will let you start seeing code and thinking about how to use it.\nLet’s generate a population of fish. We’ll store their lengths in a vector called lengths.\n\nlengths &lt;- rnorm(n=1000, mean = 10, sd=1)\n\nThe average length of fish in this population is 10.02 cm (Note: if you view this on the webpage you will see a number, but in the actual qmd file you see R code here - this is an example of merging code and text!). We can then simulate a sample from this population. In fact, let’s simulate 2 and compare the means of each.\n\nsample_1 &lt;- sample(lengths,50)\nsample_2 &lt;-sample(lengths, 50)\n\nThe mean length for fish in sample 1 is 10.03 cm, while that in sample 2 is 10 cm . These are both close to the true value, but they are also both slightly different - this is sampling error!\nSampling error always exists, and a major part of statistics is to quantify it. One thing that reduces sampling error is to have large samples! Remember, if we measure every member of the population we don’t even need statistics, so the closer we get to that (implying larger samples) the better!",
    "crumbs": [
      "Chapters",
      "Acquiring data"
    ]
  },
  {
    "objectID": "content/chapters/Acquiring_data.html#next-steps",
    "href": "content/chapters/Acquiring_data.html#next-steps",
    "title": "Acquiring data",
    "section": "Next steps",
    "text": "Next steps\nNow that we have data, we’ll discuss summarizing it in the next section (and actually define mean and some of the other terms we’ve started to use!).",
    "crumbs": [
      "Chapters",
      "Acquiring data"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html",
    "href": "content/chapters/Binomial.html",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "",
    "text": "In this chapter will build on our previous exploration of estimation by considering the world of hypothesis testing. These are different but related ideas, and we’ll end the section showing why. Along the way we will introduce the p-value. We will do all this while considering binomial tests, which are some of the simplest data we will see.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#example-does-age-of-birds-impact-their-likelihood-of-colliding-with-glass",
    "href": "content/chapters/Binomial.html#example-does-age-of-birds-impact-their-likelihood-of-colliding-with-glass",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Example: Does age of birds impact their likelihood of colliding with glass?",
    "text": "Example: Does age of birds impact their likelihood of colliding with glass?\nLet’s start with an example. Klem Klem (1989) wanted to know if various factors (e.g., age, sex) of birds impacted the probability they would collide with glass windows. He collected data from several areas. In one of his samples, he found 18 purple finches collided with glass windows. 9 of these were in their hatching year (we’ll call them younger), and 9 were older. Is there any evidence that age impacts the probability of a purple finch colliding with the glass?\n\n\n\nCephas, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\n\n\nWhat have we done with data like this so far? You should know to calculate the proportion of each category impacting the probability of either category being represented in the sample. For example, since there were 9 older birds and 18 total, the proportion of older birds in the sample was:\n\n9/18\n\n[1] 0.5\n\n\nWe could also graph this, but it wouldn’t be very interesting:\n\nlibrary(ggplot2)\nfinch_data &lt;- data.frame(age = c(\"younger\", \"older\"), collisions = c(9,9))\nggplot(finch_data, aes (x=age, y = collisions))+\n  geom_col()+\n  labs(x=\"Age\", y= \"Collisions\", title = \"No apparent difference in sample based on age\")\n\n\n\n\n\n\n\n\nAnd although we haven’t discussed it, you should understand we could develop a confidence interval for this type of data (we’ll do so below). That would tell us the range of proportions we might typically expect. But does that really answer the question of whether age impacts likelihood of colliding with glass?",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#welcome-to-hypothesis-testing",
    "href": "content/chapters/Binomial.html#welcome-to-hypothesis-testing",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Welcome to hypothesis testing",
    "text": "Welcome to hypothesis testing\nTo answer that question, we have to move to hypothesis testing. This approach focuses on if a given value we found in the data (we’ll call it a signal) is really different (or significantly different) from what we would expect to see for a a given set of circumstances given the sampling error we now know to expect when we sample.\nThe given set of circumstances are described by a null hypothesis (this is why this approach is sometimes called NHST, or null hypothesis significance testing). We often abbreviate this as Ho. Let’s start by comparing this to estimation. Given our data, we could develop a 95% confidence interval (theoretically) that you should now understand will capture the true signal of the data about 95% of the time (here we are using proportion as opposed to mean, but it works). That’s a slightly different approach than asking if the true mean is equal to a given number, which is what hypothesis testing asks. Both deal with sampling error and explain why we can’t simply say an estimate being different than a given value proves there is a difference (make sure you understand why!).\nFor hypothesis testing in general, we again generate a known population that we draw from multiple times (should sound familiar), but this time the population parameters are set by a null hypothesis. Then we compare the spread of signals from those multiple draws (which exist due to sampling error!) to what we actually observed to determine how likely our draw was given the null hypothesis was true. If it’s unlikley to have occured by chance under the null hypothesis, we consider that evidence the null hypothesis is not correct and (eventually) reject it.\nYou can typically think of a null hypothesis as a hypothesis of no difference, affect, or relationship. Let’s walk through this with our bird example, where our null hypothesis would state age (measured as a category here!) has no impact on collisions. Given that, what would we expect to see in our sample?\nThis is a tricky question (that I chose on purpose!). Many approaches to this question start with a 50/50 expectation (like flipping a coin), but I’ve found that confuses students into thinking that is always the answer. Instead, think about what we would expect to see if age had no impact on collisions. We would not necessarily expect a 50/50 split in older and younger birds because that may not be what the population looks like. In fact, previous research has suggested the population is split closer to 3:1, with 3 younger birds for every older bird. This means if age has no impact on collisions, we should see about (due to sampling error!) 3 younger birds for every one older bird in our samples of birds that hit glass.\nWhat did we actually see? We saw 9 younger birds and 9 older birds. That is not a 3:1 split, but its also a small sample size. If we had a population with a 3:1 split and randomly selected 18 birds from it, how rare would it be to get 9 younger and 9 older birds? That’ (close) to what we are asking.\nIn this case, our null hypothesis is comparing our signal to a set value. This is common when we measure a single group and want to compare it to something. So our null hypothesis could be written as conceptually as age does not impact the probabilty a bird collides with glass. However, its often better (in order to connect it to tests!) to write it using numbers. In this case, we could write\n\\[\nH_O: p=.75\n\\]\nwhere p is the probability of a bird in our sample being young (for a single draw), or what we expect on average over larger samples (a proportion!). Remember, to find a proportion, you count the number of samples that fall in a given group and divided that by the total number sampled. Alternatively, you can assign a score of 0 for values that are not in the focal group and a score of 1 to samples that are - the average of these scores will give you the proportion.\nNote we could instead focus on old birds and get:\n\\[\nH_O: p=.25\n\\]\nWe also have alternative hypotheses (abbreviated HA)to accompany each of these. Our alternative is just the opposite of the null. Together, they encompass all the probability space. It is usually just as simple as switching signs. For example, if we focus on younger birds, we get\n\\[\n\\begin{split}\nH_O: p=.75 \\\\  \nH_A: p \\neq .75\n\\end{split}\n\\]\nThe above ideas stay the same for all NHST approaches! We always use the null hypothesis to generate a “known” population (sometimes called the null population, draw samples from it, and then compare it to what we actually observed. What changes based on data type is how we generate the sample and multiple draws.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#binomial-data",
    "href": "content/chapters/Binomial.html#binomial-data",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Binomial data",
    "text": "Binomial data\nThis example focuses on independent data points (one does not impact any others) that can be divided into 2 outcomes (young and old in our example). That is known as binomial data (so if data can be divided into two categories, we call it binomial data). A special case of binomial data exists when we only get one organism in our sample (e.g., one bird, one coin flip). We call this Bernoulli data.\nFor any type of data, we can simulate a distribution under the null hypothesis. For this example, we could put 4 pieces of paper in a hat, 3 labelled younger and 1 labelled older. We can then draw a sample of 18 (the number we actually observed) by drawing a piece of paper, writing down what it says, returning it to the hat, and repeating the process 9 more times to get single sample. For each sample, you could then calculate the observed proportion of younger birds. You could visualize the spread of those results using a histogram. It’s important to realize this is doable without a computer (think it through), but it would take a lot of time because you need a lot of samples (we’ll come back to this).\nFor now, let’s do it with the computer. Let’s also take a shortcut: Instead of younger and older, let’s label the pieces of paper 1 and 0. We will also call the 0’s failures and the 1’s successes. Then we can sum the draws and divide by 18 to get the proportion of successes (make sure you understand why!). For now, let’s do a 1000 random draws of 18.\n\nset.seed(42)\nchoices &lt;- c(rep(0,1),rep(1,3))\nnumber_of_draws &lt;- 18\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_proportion\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_proportion[i] = sum(sample(choices,number_of_draws, replace=T))/number_of_draws\n}\n\nLet’ s take a look at the first few draw\n\nhead(sampling_experiment$observed_proportion)\n\n[1] 0.6111111 0.7222222 0.8333333 0.8333333 0.6111111 0.7222222\n\n\nNote we see some variation. Also note it is impossible to get a proportion of .75. Why? We only sampled 18 individuals, so we can’t get any outcomes that aren’t some form of a whole number less than 18 divided by 18. This seems simple, but it’s a reminder that your signal being different than your hypothesized value is not sufficient to reject the null hypothesis!\nNow let’s plot the proportions from our sampling experiment:\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nJust looking at this, it seems getting a proportion of .5 is unlikely. It only occurred 14 times. However, we also need to note how often more extreme outcomes occurred. Why?\nMore extreme values (the same or further distance away from the hypothesized value as our observed signal were) are also useful in considering if the null hypothesis is valid. When we move to continuous distributions, it’s also impossible to get a certain value (as mentioned in the probability section).\nIn this example, our observed proportion was .5. That’s .25 away from the value under the null hypothesis (.75), so we should all simulations that were . 5 or less or 1 or more. That only happened 22 times. So, in taking 1000 random draws from our null population, we only saw what we actually observed (or something more extreme) 0.022% of the time.\n\nsampling_experiment$Proportion = ifelse(sampling_experiment$observed_proportion &lt;= .5, \n                                  '&lt;= .5', ifelse(sampling_experiment$observed_proportion &lt; 1, '&gt;.5 & &lt; 1', '&gt;= 1'))\n\n\n\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nOr to think about as or more extreme..\n\nsampling_experiment$Proportion2 = ifelse(abs(sampling_experiment$observed_proportion-.75) &gt;= abs(9/18-.75), 'as or more extreme', 'not as or more extreme')\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion2)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\", \n       fill = \"Proportion\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#welcome-to-the-p-value",
    "href": "content/chapters/Binomial.html#welcome-to-the-p-value",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Welcome to the p-value",
    "text": "Welcome to the p-value\nThis is a p-value. Don’t get confused! We will get p-values from multiple tests, but the binomial distribution also has a p parameter (the proportion). They are not the same.\nExplaining p-values is hard! You can see some statisticians try to explain the concept here.\nA smaller p-value therefore means it is less likely to obtain your observed signal, or something more extreme, by chance when the null hypothesis is true. Traditionally, a p-value of less than .05 is thought to be sufficient evidence to reject the null hypothesis. This comparison value is sometimes called the \\(\\alpha\\) (alpha), or significance, level. So if our p-value is &lt; .05, we often say we have significant evidence against HO. While we now often get specific p-values from software, historically people used tables to find ranges (less than .05, for example).",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#understand-what-this-implies",
    "href": "content/chapters/Binomial.html#understand-what-this-implies",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Understand what this implies!",
    "text": "Understand what this implies!\nNote our p-value is the probability we would get a signal like we observed by chance if the null hypothesis was true. This means for an \\(\\alpha\\) of .05,we would expect to see something this extreme by chance 1 time out of 20! In other words, we can have errors. Think about it this way:\n\n\n\n\n\n\n\n\n\nBiological reality\n\n\n\n\n\nDecision (based on analysis of sample data)\nHO True\nHO False\n\n\nReject HO\nType I error (P[ɑ])\nPower (1- \\(\\beta\\) )\n\n\nDo not reject HO\nCorrect (P[1- ɑ])\nType II Error ( Pr\n[\\(\\beta\\)])\n\n\n\n\\(\\alpha\\) sets the limit we are ok with for rejecting HO when it is true (a Type 1 error). Alternatively, a Type II error is when we do not reject HO even when it’s is false. Importantly, \\(\\alpha + \\beta \\neq 1\\)! Instead, \\(\\alpha + (1-\\alpha)\\) is the probability space for HO, and \\(\\beta + (1-\\beta)\\) (or \\(\\beta + power\\)) is the probability space for HA. How they overlap depends on the signal, as the the distribution of signals under HA is close to what we already estimated for confidence intervals! You can visualize the relationship using the image below. Note the code is hidden given it’s length!\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `show_guide` argument of `layer()` is deprecated as of ggplot2 2.0.0.\nℹ Please use the `show.legend` argument instead.\n\n\n\n\n\n\n\n\n\nThe key point is the experimenter sets HO and \\(\\alpha\\). Here we clearly see that in a typical test (like what we illustrated above) \\(\\alpha\\) is split among the top and bottom of the distribution of signals under HO to create rejection regions. Note if we decrease \\(\\alpha\\), which we can, we also decrease the power of the test! On a related note, we can return to an earlier image\n\n\n\nA 3D visualisaion of PPV, NPV, Sensitivity and Specificity. Luigi Albert Maria, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\n\n\nand note that power is equal to sensitivity!\nThese issues come up in power analysis, which is way of using prior estimates of the distribution of signals to determine appropriate sample sizes needed to detect significant results. Another form of power analysis occurs after a test is carried out, but this basically rehashing the p-value Levine and Ensom (2001) Heckman, Davis, and Crowson (2022).\nThis all points to a central idea of NHST. Larger sample sizes let you pick up smaller differences among groups! We will develop this below and consider relationships among significance and importance!",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#can-we-do-this-without-running-a-sampling-experiment-every-time",
    "href": "content/chapters/Binomial.html#can-we-do-this-without-running-a-sampling-experiment-every-time",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Can we do this without running a sampling experiment every time?",
    "text": "Can we do this without running a sampling experiment every time?\nAs shown above, we can always use simulations to obtain a p-value. However, without a computer (and even with) it’s cumbersome. We also have to redo it for every change (for example, what if our sample contained 19 instead of 18 birds?). Another option is to find an algorithm that can be used to calculate a distribution that is very close to what we saw with the simulation.\nIn the case of our binomial data, very close actually means exact. The binomial data is an example of data where we can fully describe the probability outcomes a sample may take. The binomial distribution allows calculations of how often you would expect s successes for a set number of trials (n-s) if a population had a proportion of p for the focal trait. This means we use the binomial distribution to calculate our probabilities.\nLet’s not derive this fully, but just think about it. We have a proportion of success p, so (1 - p) is equal to the probability of failure (since we only have 2 options). For variance, we noted we find the average squared distance from the focal parameter value (in this case, a proportion).\nFor a single draw (what we call Bernoulli data), if we assume a success is equal to 1 and a failure to zero, we could “simply” multiply the likelihood of each our outcomes by their average squared distance from the mean\n\\[ \\begin{split} \\sigma^2 = (0-p)^2(1-p)+(1-p)^2(p)\\\\ which \\ eventually \\ reduces \\  to \\\\ \\sigma^2 =p(1-p) \\end{split} \\]\nSince we are assuming each data point is independent ( remember the multiplication rule?), the probability distribution of getting S successes from N draws will be\n\\[ Pr[S] =p^S(1-p)^{N-S} \\]\nand the variance will be\n\\[\n\\sigma_\\mu^2 =Np(1-p)\n\\]\nsince when you add independent events, you multiply the variances.\nSince we don’t care about the order of successes and failures in the sample, we have to think about combinations (not developed here), or how many ways one can arrange s successes in n draws. Putting it together, we can write the binomial distribution as\n\\[\nP[n \\ successes] = {n\\choose s}p^s(1-p)^{n-s}\n\\]\nUsing this distribution we can ask for the probability of obtaining any given number of successes for a given sample size. We can then find how likely we were to see a signal as more extreme than what we actually observed in the data by chance if the null hypothesis is true (p-value!). The dbinom function in R uses this distribution.\n\nsum(dbinom(0:9,18,.75))+dbinom(18,18,.75)\n\n[1] 0.02498549\n\n\nThis distributional assumptions also powers the binomial test (also called the exact binomial test). In R, we can use the binom.test function to carry it, with the arguments\n\nx=number of successes\n\nnow you see why we called them successes!\n\nn = total number of trials\np= expected proportion under the null hypothesis\n\n\nbinom.test(x=9, n=18, p=.75)\n\n\n    Exact binomial test\n\ndata:  9 and 18\nnumber of successes = 9, number of trials = 18, p-value = 0.02499\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.2601906 0.7398094\nsample estimates:\nprobability of success \n                   0.5 \n\n\nNote for this test the default value for p is .5 (equal chance), so if you don’t enter it that’s what will be used.\nNotice all our p-values are fairly close. P-values obtained using the distributional assumptions match exactly., and that obtained by simulation is very close. It should also be noted that although the p-value obtained by simulation will vary slightly each time, while those obtained using the binomial distribution will stay the same.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#impact-of-sample-size",
    "href": "content/chapters/Binomial.html#impact-of-sample-size",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Impact of sample size",
    "text": "Impact of sample size\nNow that we can “easily” run a binomial test, let’s do it a few times to see the impact of sample sizes. For example, we could see the same proportion/signal (50%) of younger birds in our sample, but if we only collected 8 individuals we would not be able to reject HO. Note what happens to our simulation outcomes:\n\nnumber_of_draws &lt;- 8\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_proportion\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_proportion[i] = sum(sample(choices,number_of_draws, replace=T))/number_of_draws\n}\nsampling_experiment$Proportion = ifelse(sampling_experiment$observed_proportion &lt;= .5, \n                                  '&lt;= .5', ifelse(sampling_experiment$observed_proportion &lt; 1, '&gt;.5 & &lt; 1', '&gt;= 1'))\n\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nSo now, we find that outcomes that are as or more extreme than what we saw in the actual data occur 2 times. So, in taking 1000 random draws from our null population, we only saw what we actually observed (or something more extreme) 0.002% of the time. Similarly,\n\nbinom.test(4,8,p=.75)\n\n\n    Exact binomial test\n\ndata:  4 and 8\nnumber of successes = 4, number of trials = 8, p-value = 0.1138\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.1570128 0.8429872\nsample estimates:\nprobability of success \n                   0.5 \n\n\nleads to a p-value which is &gt;.05, so we fail to reject HO. Again, this relates to how sampling error interacts with sample size, much as we saw when constructing confidence intervals. This means we have to differentiate between statistical significance and importance.\nGiven a large enough sample size, we can detect very small differences from our parameter value under the null hypothesis. For example, what if data from another population of finches showed 780 younger birds out of a sample of 1000 birds that collided with windows. If we assume the population distribution in regards to age is the same, we are still testing\n\\[\n\\begin{split}\nH_O: p=.75 \\\\  \nH_A: p \\neq .75\n\\end{split}\n\\]\nIn our sample, we found a signal of 0.78, which is very close to .75. However, we find a p-value of\n\nbinom.test(780,1000, p = .75)\n\n\n    Exact binomial test\n\ndata:  780 and 1000\nnumber of successes = 780, number of trials = 1000, p-value = 0.02843\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.7530202 0.8053200\nsample estimates:\nprobability of success \n                  0.78 \n\n\nIs the slight increase in older birds really important to understanding the population? Maybe, or maybe not. The point is we have to understand the difference between estimates and significance and the more nebulous idea of importance.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#estimates-and-p-values-work-together",
    "href": "content/chapters/Binomial.html#estimates-and-p-values-work-together",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Estimates and p-values work together",
    "text": "Estimates and p-values work together\nThis is one way estimates and NHST work together. Estimate focuses on the sample (Given sampling error, where do we think true parameter lies?). Hypothesis testing focuses on the likelihood of the signal given the null distribution (how likely were we to observe data that we did, a la the p-value), but gives no information about the actual difference (which could be important for determining if something really matters!).",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#one-sided-tests",
    "href": "content/chapters/Binomial.html#one-sided-tests",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "One-sided tests",
    "text": "One-sided tests\nIn introducing the p-value (and estimation) we focused on two-sided (or two-tailed) tests. This means we considered deviations from our value under the null hypothesis (for p-values) or via sampling error (for confidence intervals) based on their magnitude, and not direction. However, we can instead decide we want to consider differences to one “side” of our value of interest. Following this idea, we have 3 options for our null and alternative hypotheses (note C is a constant value here!):\n\n\n\n\n\n\n\n\n\n\n\n*Two-sided (\n\nt ypical)**\nFocused on signals greater than predicted in null\nFocused on signals less than predicted in null\n\n\nHO\np = C\np &lt;= C\np &gt;= C\n\n\nHA\np \\(\\neq\\) C\np &gt; C\np &lt; C\n\n\n\nFor example, Claramunt et al Claramunt, Hong, and Bravo (2022) wished to consider if roads impaired bird movement. To do they considered if banded birds were more likely to be recapture in one of 3 areas across a road from their original location or one of 6 on the same side on which they were captured. They were only interested if roads reduced bird movement, so they were justified in using a sided test. These tests move all the rejection region to one side. You can run these by adding an alternative argument to binom.test\n\nbinom.test(116,641, p=.33, alternative = \"less\")\n\n\n    Exact binomial test\n\ndata:  116 and 641\nnumber of successes = 116, number of trials = 641, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is less than 0.33\n95 percent confidence interval:\n 0.0000000 0.2078378\nsample estimates:\nprobability of success \n             0.1809672 \n\n\nHere we reject HO, where\n\\[\n\\begin{split}\nH_O: p&gt;=.33 \\\\\nH_A: p &lt; .33\n\\end{split}\n\\]\nHowever, sided or tailed tests should be rarely used? Why? Because it can be too tempting to use a sided test after observing the data! A signal that is not significant at the \\(\\alpha\\) =.05 level using two-sided tests can be significant as a one-tailed test.\nIf you do use these, note they correspond to confidence bounds instead of intervals. Again, the full rejection region is placed on one side of the estimate.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#tying-it-all-together",
    "href": "content/chapters/Binomial.html#tying-it-all-together",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Tying it all together",
    "text": "Tying it all together\nLet’s return to our bird collision example and connect estimation and p-values (and teach you how to estimate confidence intervals for binomial data).\nRemember, we found 9 younger birds in our sample of 18. This means our estimate for the proportion of younger birds is 0.5. Just like for continuous data, we can consider sampling error in our estimate. Let’s think about how that might happen.\n\n\nIn short, the standard error of p is\n\\[\nSE(p) = \\sqrt{\\frac{p(1-p)}{N}}\n\\]\nbut since we don’t know p, we use our estimate\n\\[\nSE(\\hat{p}) = \\sqrt{\\frac{(\\hat{p}(1-\\hat{p})}{N}}\n\\]\nTo find out a little more, click here.\n\nFor a single draw (Bernoulli data), if we assume a success is equal to 1 and a failure to zero, we could “simply” multiply the likelihood of each our outcomes by their average squared distance from the mean\n\\[\n\\begin{split}\n\\sigma^2 = (0-p)^2(1-p)+(1-p)^2(p)\\\\\nwhich \\ eventually \\ reduces \\  to \\\\\n\\sigma^2 =p(1-p)\n\\end{split}\n\\]\nIf we move to N independent draws, we predict the average observed outcome (or the mean number of successes!) will be\n\\[\n\\mu_S = Np\n\\]\nSince we are assuming each data point is independent, the variance of N draws will be\n\\[\n\\sigma_\\mu^2 =Np(1-p)\n\\]\nso\n\\[\n\\sigma_\\mu =\\sqrt{Np(1-p)}\n\\]\nNotice in doing this we went from a proportion to a number of successes! Now we can use our typical equation for standard error of the means\n\\[\n[\\sigma_{\\mu_s} = \\frac{\\sigma}{\\sqrt{N}} = \\frac{\\sqrt{(Np(1-p)}}{\\sqrt{N}}  = \\sqrt{\\frac{(p(1-p)}{N}} \\ ] \\sim [s_{\\overline{Y}} = \\frac{s}{\\sqrt{N}} =   \\frac{\\sqrt{(N\\hat{p}(1-\\hat{p})}}{\\sqrt{N}} = \\sqrt{\\frac{(\\hat{p}(1-\\hat{p})}{N}}]\n\\]\nThis is actually a bit tricky as it assumes some connections between categorical and continuous data, and many ways have been proposed to do this (Subedi and Issos 2019), but this gets us close.\n\nIt turns out our estimate of the standard error may be biased, especially for small sample sizes or extreme (close to 0 or 1) values of p. For that reason, several ways have been suggested to calculate confidence intervals (Subedi and Issos 2019) . Note, for example, the binom.confint function in the binom package gives multiple outcomes. For the function,\n\nthe first argument is the number of successes\nthe second argument is the number of trials\n\n\nlibrary(binom)\nbinom.confint(9,18)\n\n          method x  n mean     lower     upper\n1  agresti-coull 9 18  0.5 0.2903102 0.7096898\n2     asymptotic 9 18  0.5 0.2690160 0.7309840\n3          bayes 9 18  0.5 0.2835712 0.7164288\n4        cloglog 9 18  0.5 0.2592888 0.7005143\n5          exact 9 18  0.5 0.2601906 0.7398094\n6          logit 9 18  0.5 0.2841566 0.7158434\n7         probit 9 18  0.5 0.2812976 0.7187024\n8        profile 9 18  0.5 0.2808406 0.7191594\n9            lrt 9 18  0.5 0.2808092 0.7191908\n10     prop.test 9 18  0.5 0.2903102 0.7096898\n11        wilson 9 18  0.5 0.2903102 0.7096898\n\n\nFor now, we will use method labelled the Agresti-Coull method, which adjusts for slight bias in other estimates and is useful across sample sizes.\n\nusing_distribution &lt;- dbinom(0:18,18,.75)\nfinches &lt;- data.frame (Number = 0:18, Probability = using_distribution)\nfinches$Proportion &lt;- finches$Number/18\nfinches$criteria &lt;- \"retain\"\nfinches$criteria[pbinom(finches$Number, 18, .75) &lt; .025] &lt;- \"reject\"\nfinches$criteria[(1-pbinom(finches$Number, 18, .75)) &lt; .025] &lt;- \"reject\"\nproportion_observed = data.frame(Proportion = 9/18, Probability = .15)#sets height\nggplot(finches, aes(x = Proportion, y = Probability)) + \n  geom_bar(stat=\"identity\", aes(fill = criteria)) + \n  geom_segment(x = .29031, xend = .70968,y= .15 , yend =.15) +\n  geom_vline(xintercept = .75, color = \"blue\") + geom_vline(xintercept = 9/18, color = \"black\") +\n  geom_point(data= proportion_observed) +\n  ggtitle(\"Comparing p-values and confidence intervals for finch problem\")\n\n\n\n\n\n\n\n\nNote we see our rejection region in red; it also contains our estimate! Similarly, the 95% confidence interval for our estimate does not contain the paramater value under the null hypothesis!",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Binomial.html#next-steps",
    "href": "content/chapters/Binomial.html#next-steps",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Next steps",
    "text": "Next steps\nMake sure you understand the above concepts (i.e., how p-values are is related to null hypotheses and how to interpret them!). Our following chapters will extend this idea to different types of data, starting with continuous data from a single sample in the next chapter.",
    "crumbs": [
      "Chapters",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html",
    "href": "content/chapters/Compare_means_among_populations.html",
    "title": "Comparing means among groups",
    "section": "",
    "text": "In the last chapter we introduced the idea of comparing parameters among populations. Now we will extend those ideas to instances when continuous data is collected.",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#example-back-to-the-iris",
    "href": "content/chapters/Compare_means_among_populations.html#example-back-to-the-iris",
    "title": "Comparing means among groups",
    "section": "Example: Back to the iris",
    "text": "Example: Back to the iris\nWhen we introduced NHST for continuous data, we focused on sepal length from I. virginica.\n\nset.seed(42)\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nand tested if it was equal to a given value (7.0 cm)\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\nWe then considered how to assess these types of hypotheses using z, t, Wilcoxon, and sign tests.\nHowever, as we noted in the last chapter, we often instead have data from multiple populations. For example, we may have data from 3 species of flowers. We commonly see this data plotted as a bar chart with error bars\n\n\n\n\n\n\n\n\n\nWhat do we test now and how?",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#welcome-to-anovas",
    "href": "content/chapters/Compare_means_among_populations.html#welcome-to-anovas",
    "title": "Comparing means among groups",
    "section": "Welcome to ANOVAs",
    "text": "Welcome to ANOVAs\nAs previously noted, we can’t compare heights among group. Height is a random variable, and it’s highly unlikely they will be exactly the same. Seeing the actual data may help us remember this.\n\nggplot(iris, aes(y=Sepal.Length, x=Species, color=Species)) +\n  geom_jitter() +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\n\n\n\n\nSo we typically focus on a parameter that describes the distribution of a focal trait, such as the mean. Just like binomial data, our hypotheses are then\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length, \\ setosa} = \\mu_{sepal \\ length, \\ virginica} = \\mu_{sepal \\ length, \\ versicolor}\\\\  \nH_A: \\mu_{sepal \\ length, \\ setosa} \\neq \\mu_{sepal \\ length, \\ virginica} \\neq \\mu_{sepal \\ length, \\ versicolor}\\\\\n\\end{split}\n\\]\nGiven that, our overall idea is to consider if the data are better explained by an overall group average or by species-specific averages. To visualize this, we could use\n\ncolors &lt;- c(\"group means\" = \"black\", \"overall average\" = \"orange\")\nggplot(iris, aes(Species,Sepal.Length)) + \n  geom_jitter(aes(colour=Species), size = 3) +\n  geom_errorbar(aes(ymin=Sepal.Length, ymax=Sepal.Length, color=\"group means\"), \n                data = function_output) +\n    geom_hline(aes(yintercept=mean(Sepal.Length),  color = \"overall average\"))+\n  scale_color_manual(values=colors)+\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\", \n       color= \"Focus\")\n\n\n\n\n\n\n\n\nLike our earlier considerations of variance and SSE, the data will obviously be fit better by species-specific averages. Its impossible for them to do worse than the overall average, and at worst they all are the group average. However, we should also remember that these are samples, so we know sampling error is an issue. Therefore, we have to consider if the species-specific averages do enough of a better job explaining the data to warrant using them. To put this in our SSE and hypothesis framework, we need to consider if a more complicated view of the world is worth it.\nTo test this, we can (as always) carry out a sampling experiment. The general idea is that species does snot matter (just like we saw in contingency analysis). Given that, we can draw samples that match our respective sample sizes for each population from a single population. The mean can be set as the pooled mean for the data (since under the null tested factors don’t matter). Since we don’t know or set sigma, we can again estimate it from the data. One such sample might look like\n\nvariance_estimate &lt;- sum((function_output$N -1) * (function_output$sd)^2)/(sum(function_output$N)-length(function_output$N))\nmean_sepal &lt;- mean(iris$Sepal.Length)\nsimulated_data &lt;- data.frame(Species=c(rep(\"setosa\", 50), \n                                       rep(\"versicolor\", 50),\n                                       rep(\"virginica\",50)),\n                             Sepal.Length=rnorm(150, mean_sepal, \n                                          sd= sqrt(variance_estimate)))\n\nfunction_output &lt;- summarySE(simulated_data, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(simulated_data, aes(Species,Sepal.Length)) + \n  geom_jitter(aes(colour=Species), size = 3) +\n  ylab(\"Sepal Length (cm)\")+ggtitle(\"Sepal Length of various iris species\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\")) +\n  geom_errorbar(aes(ymin=Sepal.Length, ymax=Sepal.Length, color=\"group means\"), \n                data = function_output) +\n    geom_hline(aes(yintercept=mean(Sepal.Length),  color = \"overall average\"))+\n  scale_color_manual(values=colors)\n\n\n\n\n\n\n\n\nAs expected, under the null hypothesis the overall and species-specific averages are closer. Now that we have the data, however, we are stuck with a new question: What is our test statistic?\nIn general, using a difference among means makes sense for cases when we have only 2 populations. This will be used when we introduce t-tests. However, it does not work for 3+ populations, so we will need a different approach.\nANOVAs offer an approach that can be used for any group of 2+ populations when certain assumptions are met. ANOVAs stands for analysis of variance which may seem odd given our hypotheses are focused on means. However, the idea (not fully developed here) is that we can get an overall estimate of variance by\n\ncalculating variance for each point around its respective group-specific mean\n\nthis leads to 3 estimates of variance, which we can multiple by (n-1) to account for differences in sample size and then divide by the number of groups to get an overall estimate of variance\n\nthis is referred to as mean square error\n\n\n\\[\n\\begin{split}\n\\textrm{Remember, }s^2 = \\frac{\\sum_{i=1}^{n} (Y_{i}-\\overline{Y})^2}{n-1} \\sim \\sigma^2\\\\\n\\textrm{So if we have j groups, for each group we can see}\\\\\ns_j^2 = \\frac{\\sum_{i=1}^{n_j} (Y_{ij}-\\overline{Y_j})^2}{n_j-1} \\sim \\sigma_j^2\\\\\n\\textrm{which we can combine to estimate }\\sigma_{overall}\\\\\n\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2 ...(n_j-1)s_j^2}{n_1+n_2+...n_j-1} = s_{overall}^2\\\\\n\\end{split}\n\\]\ncalculating variance for each group mean around the overall mean\n\nthis is called mean square treatment\n\n\n\\[\n\\begin{split}\n\\frac{\\sum_{j=1}^{j} (\\overline{Y_j}-Y_{overall}{i})^2}{j-1} = \\frac{s^2}{n} \\\\\n\\textrm{where j is the number of groups. This can be multiplied by n to get }s^2 \\\\\n\\end{split}\n\\]\nIn other words, variance among groups should be equal to variance within groups. You should also note this means we can partition the variance for any given observation as its distance from its group mean and its group means distance from the overall\nUnder the null hypothesis, the ratio of these estimates should tend towards 1. We can see this using a sampling experiment.\n\n#sample\n  ratio &lt;- data.frame(rep = 1:10000, mse = rep(NA,10000), \n                      msg = rep(NA,10000), ratio = rep(NA,10000))\nfor(i in 1:10000){\n    setosa &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    versicolor &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    virginica &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    mean_overall &lt;- mean(c(setosa, versicolor, virginica))\n    ratio$mse[i] &lt;- (49 * var(setosa) + 49 * var(versicolor) + 49 * var(virginica))/(150 - 3)\n    ratio$msg[i] &lt;- (50 * (mean(setosa)-mean_overall)^2 + \n                 50 * (mean(versicolor)-mean_overall)^2 + \n                 50 * (mean (virginica)-mean_overall)^2)/2\n    ratio$ratio[i] &lt;- ratio$msg[i]/ratio$mse[i]\n}\n  \nsummary(lm(Sepal.Length~Species, iris))$fstatistic[1]\n\n   value \n119.2645 \n\nggplot(ratio, aes(ratio)) +\n    geom_histogram(aes(y=..count../sum(..count..)), fill = \"orange\", bins=15)+\n    labs(main = \"Ratio under null hypothesis\", y= \"Probability\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\n\n\n\n\nUsing this approach, we could determine how unusual our data were (get a p-value!). However, finding a distribution that approximates this shape would make future work easier. It turns out all the squared terms above lead to this being a rato of \\(\\chi^2\\) distributions, where the numerator has degrees of freedom j-1 (# of groups - 1) and the numerator had degrees of freedom n-j-1; the “lost” degrees of freedom are used to estimate group and overall means.\n\nggplot(ratio, aes(ratio)) +\n    geom_histogram(aes(y=..count../sum(..count..)), fill = \"orange\", bins = 15) +\n    labs(main = \"Ratio under null hypothesis\", y= \"Probability\")+\n    stat_function(fun = df, args = list(df1 =2, df2 = 147), color = \"green\")   \n\n\n\n\n\n\n\n\nIn our data, we found a signal of 119.264502184505! This is going to lead to a very low p-value.",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#welcome-to-the-linear-model",
    "href": "content/chapters/Compare_means_among_populations.html#welcome-to-the-linear-model",
    "title": "Comparing means among groups",
    "section": "Welcome to the linear model",
    "text": "Welcome to the linear model\nAn ANOVA is just one case of a linear model. We will fully explore these later, but noting this now is useful in that all linear models have the same sets of assumptions. In general, linear models assume the residuals of the model are are independent, identically distributed, and follow a normal distribution. You’ll sometime see this written as\n\\[\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n\\]\nBut what does this mean?\nResiduals are the distance between a measurement and its model-predicted value. A closely related term, error, is actually the distance between a measurement and the unknown population mean for a group. Linear models assume the residuals are independent of each other (this follows from independent data points) and that their spread (around their predicted values) is normally distributed and similar for all points.\nUnderstanding this explains two key points. The residuals, not the data, need to be normally distributed. Also, we have to build the model to get the residuals, then we check the assumptions.\nWe can do this in R using the lm function. This approach also lets us use a single set of functions to build many model types. As always, there are many ways to do anything in R, so there are specific ANOVA functions that we will not introduce here.\nFor our data, we can build an lm object\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nthen use plot to check the assumptions.\n\nplot(iris_anova)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese 4 plots focus on the residuals (not the data).\n\nThe Residuals vs fitted plot allows us to see if the residuals are identically distributed - we want to see a flat red line and no structure to the residuals in regards to their spread or location. Note we only have 3 fitted values here (matching our 3 group means), so will see “lines” of data in one-way ANOVAs (another name for what we are doing here).\n\nThe Q-Q Residuals plot allows us to assess normality - points should be on the line\nThe other 2 graphs give show different forms of residuals against the fitted values. We will return to them later.\n\nIf our assumptions are met, we can look at the output. One way to do this is using the summary function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nThis output may be confusing, however. The overall p value shown in the bottom right is for the entire model - that works for now, but soon won’t. We also see individual p values for 2 levels of species, plus an odd intercept term.\nThese are model artifacts and may be confusing. R lets the first factor level (typically alphabetical) be an intercept for the linear model, and then considers the other factor levels as deviations from that. It also shows if all the resulting Estimates are significantly different from 0. Note this means a significant intercept term does not mean your groups actually differ.\nGiven these issues, why use the summary command? It does present some other useful information. For example, the R2 values is a measure of how variation the model explains. It can range from 0 (the model explains nothing) to 1 (all residuals are zero, in this case meaning all members of a given species have the exact same height). The adjusted-R2 value is similar, but it adjusts the measure to account for the fact more complex models will always explain more variation.\nYou can also remove the intercept to get group estimates for all groups\n\nsummary(lm(Sepal.Length~Species-1, iris))\n\n\nCall:\nlm(formula = Sepal.Length ~ Species - 1, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nSpeciessetosa       5.0060     0.0728   68.76   &lt;2e-16 ***\nSpeciesversicolor   5.9360     0.0728   81.54   &lt;2e-16 ***\nSpeciesvirginica    6.5880     0.0728   90.49   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.9925,    Adjusted R-squared:  0.9924 \nF-statistic:  6522 on 3 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nNote these match our group means, which is good, but the overall p value is now less useful (it compares our data to a null that assumes everything is equal to 0), and the output is still confusing.\nSince we are doing an omnibus test, what we typically want is a single p value associated with our factor of interest (species in this case). To get that, we’ll use the Anova function from the car package.\n\nlibrary(car)\nAnova(iris_anova, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nWhat does type=“III” mean\n\nResiduals can be calculated in multiple ways. For simple models (those with one variable) most calculations lead to the same answer. When we start adding multiple factors to a model and/or interactions, however, they differ. In short, Type I residuals consider the order in which factors are added to a model, and type 2 do not consider interactions. We will stick with type III for this class.\n&lt;&gt;\nDoing this we see Species has a significant impact on explaining variation in the data (and our very high F value). So we reject the null hypothesis that mean sepal length does not differ among species. Now what?",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#post-hoc-tests",
    "href": "content/chapters/Compare_means_among_populations.html#post-hoc-tests",
    "title": "Comparing means among groups",
    "section": "Post-hoc tests",
    "text": "Post-hoc tests\nJust like for a multi-population \\(\\chi^2\\) tests, we need to do follow-up tests to compare groups while controlling for the FWER. For linear models (and more), we will use the glht function from the multcomp package to conduce these tests.\n\nlibrary(multcomp)\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nOur first approach uses a new (to us) method. It is not exactly Tukey’s method (very confusing) but is closely related to it. Tukey’s method is focuses on all possible pair-wise comparisons and controls for the FWER using a studentized range approach (not fully developed here, but similar to z-transform but focused on the range of means and using the estimated standard deviation; similar to t-statistic in this aspect and also developed by Student). It is also called Tukey’s Honestly Significant Difference/HSD, Tukey-Kramer method, and many other names. In glht, specifying “Tukey” tells the program to do all possible pairs comparison (like Tukey’s method). The post-hoc control for FWER, however, uses a slightly different approach that can handle interactions (still to be explained) and some other things a little bit easier.\nUsing this approach we see that all species differ significantly from all others; the output also provides estimates of the differences, which match up with our model summary output.\nWe can also use the methods we previously discussed such as Bonferroni and FDR. These requre us to set up the comparisons, which also means we can limit our number of tests if so desired. For example, we could focus only on differences with I. virginica.\n\ncompare_virginica_only &lt;- glht(iris_anova, linfct = mcp(Species = \n                                                                c(\"virginica - versicolor = 0\", \n                                                                  \"virginica - setosa = 0\")))\n\nAfter setting up the comparison, we can specify the method to use to correct for FWER,\n\nsummary(compare_virginica_only, test=adjusted(\"holm\")) \n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nvirginica - versicolor == 0    0.652      0.103   6.333 2.77e-09 ***\nvirginica - setosa == 0        1.582      0.103  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\nsummary(compare_virginica_only, test=adjusted(\"fdr\")) \n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nvirginica - versicolor == 0    0.652      0.103   6.333 2.77e-09 ***\nvirginica - setosa == 0        1.582      0.103  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- fdr method)\n\n\nNote for our small number of tests and relatively large differences in means and large sample sizes, differences in p values are minimal.\nThere are instances when FWER are not an issue and thus p values do not need to be adjusted. This occurs when we explore orthogonal contrasts.",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#a-little-deeper-into-linear-models",
    "href": "content/chapters/Compare_means_among_populations.html#a-little-deeper-into-linear-models",
    "title": "Comparing means among groups",
    "section": "A little deeper into linear models",
    "text": "A little deeper into linear models\nLet’s return to linear models to help explain orthogonal contrasts (and some other things). Linear models are a sysem of equations (a matrix), where\n\\[\n\\begin{split}\nY=X\\beta+\\epsilon, \\textrm{ where }\\\\\n\\textrm{Y is our observations (an nx1 matrix)}\\\\\n\\textrm{X is a matrix showing our explanatory variables (an nxk matrix)}\\\\\n\\beta \\textrm{ is our coefficient matrix(an kx1 matrix)}\\\\\n\\epsilon \\textrm{is a matrix (an nx1) of residuals)}\\\\\n\\end{split}\n\\]\nIn our case, \\(\\beta\\) is simply a 3x1 matrix where each entry is a species average (or one is an intercept and other two are distances from it - same thing) and X is a matrix with dummy variables (1 or 0) indicating which group each observation belongs too. X is sometimes called a model or design matrix. We can see this using R. First, we can pull the design matrix from our model object\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(iris_anova)))\n\n\n  \n\n\n\nWe can also pull the model coefficients, which form our \\(\\beta\\) matrix, and place them in the correct orientation.\n\nmatrix(as.numeric(iris_anova$coefficients), ncol=1)\n\n      [,1]\n[1,] 5.006\n[2,] 0.930\n[3,] 1.582\n\n\nSo for our first observation, which is\n\niris[1,]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n\n\nWe would multiply (remember, rows get multiplied by columns in matrices)\n\n1*5.006 + 0*.930+0*1.58\n\n[1] 5.006\n\n\nThis explains why all our fitted values are one of three values! We can also see our observation minus prediction\n\niris[1,\"Sepal.Length\"]-1*5.006 + 0*.930+0*1.58\n\n[1] 0.094\n\n\nmatches our first model residual\n\niris_anova$residuals[1]\n\n    1 \n0.094 \n\n\nUnderstanding this general setup explains a few things. When models get more complicated you may see errors or warnings related to singularity. This occurs when XTX isn’t invertible(linear algebra!), which it needs to be to find \\(\\beta\\). This occurs if columns in your design matrix are not independent and are actually linear combinations of each other. This happens when you have highly related measurements (we’ll discuss correlation eventually so you can actually measure this!). We will use similar manipulations to eventually find the \\(\\hat{H}\\) matrix when we consider Cook’s Distance (in regression chapter). Degrees of freedom are similarly related to the number of estimated coefficients the model required (the number of rows in the \\(\\beta\\) matrix).\nReturning to our contrasts, note when we do post-hoc tests we are effectively testing for differences in \\(\\beta\\) values. We can put these “tests” in a similar system of equations/matrix. For these tests, the coefficients have to equal 0. For pair comparisons, that means we have 1 for one coeffcient and -1 for the other (for example, (1,-1,0). However, we can also compare one coefficient to the average of the others (2,-1,-1). We could write these two contrasts as\n\\[\n\\begin{bmatrix}\n1 & -1 & 0 \\\\\n2 & 1 & 1 \\\\\n\\end{bmatrix}\n\\]\nA group of contrasts are orthogonal if the sum of the multiplied coefficients from each column equals zero. In this case\n\n1*2 + -1*1 + 0*1\n\n[1] 1\n\n\ndoes not equal 0, so these are not orthogonal contrasts. This is also because I can add add the first and third column and get the second (columns are not independent). However, if we instead carried out these contrasts\n\\[\n\\begin{bmatrix}\n2 & -1 & -1 \\\\\n0 & 1 & -1\\\\\n\\end{bmatrix}\n\\]\nthey would be independent. There are other options as well, as we can always find a number of orthogonal contrasts equal to the number of groups being compared minus one.\nResulting p values would not required correction for FWER. We can specify contrasts like this using glht. Below I do the same matrix, but note I set the maximum entry to 1 so that estimate of mean differences aren’t doubled.\n\ncontr &lt;- rbind(\"setosa - versicolor - virginica\" = c(1, -.5,-.5),\n               \"versicolor - virginica\" = c(0,1,-1))\nsummary(glht(iris_anova, linfct = mcp(Species = contr)), test=adjusted(\"none\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nsetosa - versicolor - virginica == 0 -1.25600    0.08916 -14.086  &lt; 2e-16 ***\nversicolor - virginica == 0          -0.65200    0.10296  -6.333 2.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- none method)",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#displaying-output-of-post-hoc-tests",
    "href": "content/chapters/Compare_means_among_populations.html#displaying-output-of-post-hoc-tests",
    "title": "Comparing means among groups",
    "section": "Displaying output of post-hoc tests",
    "text": "Displaying output of post-hoc tests\nOutput from post-hoc tests is often displayed using compact letter display. Groups that are not significantly differently share the same letter (so in this case they all have different letters).\n\ncld_output &lt;- fortify(cld(compare_cont_tukey))\ncld_output$Species &lt;- cld_output$lhs\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nfunction_output &lt;- merge(function_output, cld_output)\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")+\n  geom_text(aes(label=letters,y=Sepal.Length+3*ci))\n\n\n\n\n\n\n\n\nOther options include plotting the differences in means\n\nplot(compare_cont_tukey)\n\n\n\n\n\n\n\n\n\nemmeans: another option\nAnother popular package for conducting posthoc comparison in R is emmeans. The package has a great starters guide here",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#t-test-connections",
    "href": "content/chapters/Compare_means_among_populations.html#t-test-connections",
    "title": "Comparing means among groups",
    "section": "T-test connections",
    "text": "T-test connections\nSo far we have focused on comparing means among multiple groups. This can include include comparing means between only 2 groups (which we already do for the post-hoc tests). In doing this we also introduced new post-hoc tests and the ideas of a linear model.\nThe linear model framework will unify most of the remaining tests we learn in class. In fact, several tests we’ve already learned can be formulated this way. This is extremely useful given we want statistics to be a related set of tests in a comprehensive framework.\nThere are many ways to teach statistics, however, and a long history of tests. Many textbooks and approaches build up from one sample tests by moving to two-sample t-tests. These tests bridge the logic noted above and the approach we used for single-sample t-test. This is because the t-distribution is a special case of the F distribution. It occurs when the square root of an F distribution with 1 degree of freedom in the numerator is considered. Thus the degrees of freedom associated with a t-test will be equal to the degrees of freedom associated with the denominator of the associated F-test.\n2-sample t-tests may also an easier approach to first considering differences among groups since with only 2 populations the difference in means may be considered. However, it can be shown (not here) this is simply a rearrangement of our exploration of variances.\nTo demonstrate this, let’s only consider two species. Note\n\ntwo_species_subset &lt;- iris[iris$Species!=\"setosa\",]\nt.test(Sepal.Length ~ Species, two_species_subset, var.equal=T)\n\n\n    Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -5.6292, df = 98, p-value = 1.725e-07\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.8818516 -0.4221484\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nyields the same p-value as\n\nAnova(lm(Sepal.Length ~ Species, two_species_subset), type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 1761.80  1 5253.038 &lt; 2.2e-16 ***\nSpecies       10.63  1   31.688 1.725e-07 ***\nResiduals     32.87 98                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAlso note the t statistic is the square root of the F statistic.\n\n-5.6292^2\n\n[1] -31.68789\n\n\nNote the t.test function can also use columns holding data from each population as arguments as opposed to the formula interface, but we will not use that approach here.\nThe var.equal=T argument, however, is not the default in R, and this assumption is one of the major differences in 2-sample t-tests and F tests. Remember, ANOVAs and t-tests both require estimates for sigma. If we do not assume the variances are equal for each group, then the best way to estimate the variance is to calculate the variance for each group and take a weighted (by sample size mean). This approach is known as the Behren-Fisher or Welsh t-test.\n\nt.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -5.6292, df = 94.025, p-value = 1.866e-07\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.8819731 -0.4220269\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nThe resulting statistics has a distrubtion that can be approximated by a t-distribution, but the associated degrees of freedom can can be non-integer (decimal) and less than (n1+ n2 - 2).\nThis means the basic assumptions for 2-sample t-tests are independent data points, groups show the same variance, and means are normally distributed. Much like the one-sample t-test, the central limit theorem implies assumptions about the mean distribution are commonly met. However, if they are not met, we have a few common options.",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#non-parametric-connections",
    "href": "content/chapters/Compare_means_among_populations.html#non-parametric-connections",
    "title": "Comparing means among groups",
    "section": "Non-parametric connections",
    "text": "Non-parametric connections\nOptions for when assumptions of the t- and F-tests (ANOVAs) are presented below. Note given the history of t-tests being considered apart from ANOVAs, some functions only work with less than 2 populations while others work with three or more. However, the overall approaches are similar.\n\nRanks: Wilcoxon/Mann-Whitney U and Kruskal-Wallis test\nWe can extend the Wilcoxon test to 2-samples. To do so, we rank the data points from smallest to largest. The ranks are then used to calculate a U statistic. The statistic sums the ranks for each group (r), then uses them to calculate\n\\[\nU_1 = n_1n_2+\\frac{n_1(n_1+1)}{2}-r_1\n\\] The U statistics is calculated for each group. The larger U value is then taken and used to compute a p value. We can calculate this using the wilcox.test function,\n\nwilcox.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.869e-07\nalternative hypothesis: true location shift is not equal to 0\n\n\nThis test assumes the two distributions being considered have similar shape (not that the resulting means are normally-distributed). If you remove the default continuity correction (applied as we approximate discrete data with a continuous distribution)\n\nwilcox.test(Sepal.Length ~ Species, two_species_subset, correct=F)\n\n\n    Wilcoxon rank sum test\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.765e-07\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe get the same result as the Kruskal-Wallis test\n\nkruskal.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 24.989, df = 1, p-value = 5.765e-07\n\n\nwhich is a rank-based test that can be applied to 3+ populations.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\n\nIf we have more than three populations and this omnibus test reveals a significant p-value, we can follow it up with appropriate post-hoc tests.\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\n\n\nSign/Binary approach\nFor a single sample, we also considered the sign/binary test. We will return to this test in the next chapter, as it does not work for data from independent samples.\n\n\nBootstrapping\nAnother option is to extend the bootstrapping option. Although we could again develop a simulation using the boot function again, here we again use the MKinfer package.\n\nlibrary(MKinfer)\nboot.t.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Bootstrap Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nbootstrap p-value &lt; 2.2e-16 \nbootstrap difference of means (SE) = -0.6487257 (0.1144229) \n95 percent bootstrap percentile confidence interval:\n -0.8760 -0.4239\n\nResults without bootstrap:\nt = -5.6292, df = 94.025, p-value = 1.866e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.8819731 -0.4220269\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nnote we can also run this test without assuming variances are different.\n\nboot.t.test(Sepal.Length ~ Species, two_species_subset, var.equal=T)\n\n\n    Bootstrap Two Sample t-test\n\ndata:  Sepal.Length by Species\nbootstrap p-value &lt; 2.2e-16 \nbootstrap difference of means (SE) = -0.652117 (0.1316271) \n95 percent bootstrap percentile confidence interval:\n -0.910 -0.396\n\nResults without bootstrap:\nt = -5.6292, df = 98, p-value = 1.725e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.8818516 -0.4221484\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nBoth these approaches also show the corresponding t-test results, but note you should choose which test you plan to use before seeing the results!\nFor more than 2 groups, the t1waybt function in the WRS2 package can allow comparison.\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\n\nIf needed, the mcppb20 package allows for appropriate post-hoc comparisons.\n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\nbootstrap_post_hoc_df &lt;-data.frame(bootstrap_post_hoc$comp)\nbootstrap_post_hoc_df$adjusted_p &lt;- p.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\nbootstrap_post_hoc_df$Group &lt;- factor(bootstrap_post_hoc_df$Group)\nlibrary(plyr)\nbootstrap_post_hoc_df$Group &lt;- revalue(bootstrap_post_hoc_df$Group,\n                                       setNames(                                      bootstrap_post_hoc$fnames,as.character(1:length(bootstrap_post_hoc$fnames))))\n\nThe following `from` values were not present in `x`: 3\n\nbootstrap_post_hoc_df$Group.1 &lt;- factor(bootstrap_post_hoc_df$Group.1)\n\nbootstrap_post_hoc_df$Group.1 &lt;- revalue(bootstrap_post_hoc_df$Group.1,\n                                       setNames(                                      bootstrap_post_hoc$fnames,as.character(1:length(bootstrap_post_hoc$fnames))))\n\nThe following `from` values were not present in `x`: 1\n\nbootstrap_post_hoc_df\n\n       Group    Group.1     psihat  ci.lower   ci.upper p.value adjusted_p\n1     setosa versicolor -0.9100000 -1.143333 -0.7266667       0          0\n2     setosa  virginica -1.5466667 -1.836667 -1.3066667       0          0\n3 versicolor  virginica -0.6366667 -0.930000 -0.3666667       0          0\n\n\n\n\nPermutation\nA new option when comparing groups (2 or more) is known as the permutation test. We encountered a similar approach when we learned about the Fisher’s test for binomial data. Using this approach, we can move the measurements between measured populations, calculate test statistics, and consider how unusual our observed statistic was (a p value!). We can do this for 2\n\nlibrary(coin)\nindependence_test(Sepal.Length ~ Species, data =  two_species_subset)\n\n\n    Asymptotic General Independence Test\n\ndata:  Sepal.Length by Species (versicolor, virginica)\nZ = -4.9183, p-value = 8.731e-07\nalternative hypothesis: two.sided\n\n\nor 3+ populations\n\nindependence_test(Sepal.Length ~ Species, data =  iris)\n\n\n    Asymptotic General Independence Test\n\ndata:  Sepal.Length by Species (setosa, versicolor, virginica)\nmaxT = 8.7572, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nPost-hoc test options are available in the rcompanion package.\n\nlibrary(rcompanion)\npairwisePermutationTest(Sepal.Length ~ Species,\n                             data = iris,\n                             method=\"holm\")\n\n                  Comparison   Stat   p.value  p.adjust\n1    setosa - versicolor = 0 -7.246  4.28e-13 8.560e-13\n2     setosa - virginica = 0 -8.368 5.883e-17 1.765e-16\n3 versicolor - virginica = 0 -4.918 8.731e-07 8.731e-07",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#next-steps",
    "href": "content/chapters/Compare_means_among_populations.html#next-steps",
    "title": "Comparing means among groups",
    "section": "Next steps",
    "text": "Next steps\nOur following chapters will extend ANOVAs to consider the impact of multiple measured categories. In doing so, we will also explain paired t-tests and sign tests for paired data.",
    "crumbs": [
      "Chapters",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html",
    "href": "content/chapters/Estimation.html",
    "title": "Estimation and uncertainty",
    "section": "",
    "text": "Now that we can describe data distributions, we want to start thinking about how we quantify the uncertainty in our estimates (of \\(\\mu\\), for example). Remember, we typically want to describe a population but need to rely on a sample, and we’ve already talked about sampling error. So now we just want to think about how much error we typically have (or, alternatively, how precise are our estimates).\nAnswering this question is hard. Quantifying sampling error requires you to know the “true” value for a population parameter, but we only have estimates! Statisticians solve this problem by investigating sampling error in populations they fully know because they created them.",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html#lets-start-with-an-example",
    "href": "content/chapters/Estimation.html#lets-start-with-an-example",
    "title": "Estimation and uncertainty",
    "section": "Let’s start with an example",
    "text": "Let’s start with an example\nFor example, let’s assume we measure all the males in a population. Furthermore, let’s assume the distribution of heights is normal. Remember, this means the distribution is roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate. In fact, in turns out ~95% of the data lies within two standard deviations (remember those?) of the mean (so we calculate the mean and then the standard deviation. We then subtract the standard deviation from the mean to find a lower bound. We then add the standard deviation from the mean to find an upper bound. These bounds denote where 95% of the data points will be found).\nLet’s see this in action. First, lets make a population with a trait (let’s assume height, measured in cm, that follows a normal distribution. We can set the mean to 70 and the standard deviation to 3.\n\nset.seed(42)\npopulation_size &lt;- 10000\npopulation_norm &lt;- data.frame(id = 1:population_size, \n                         height = rnorm(population_size, 70, 3))\n\nNow’s let graph it.\n\nlibrary(ggplot2)\n\nggplot(population_norm, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow let’s add the mean (69.97 cm) and mark two standard deviations (sd = 3.02 in) above and below it. Remember we noted a benefit of using standard deviations to describe spread was that they were in the same units as the mean? Now we can use that!\n\ncolors &lt;- c(\"mean\" = \"black\", \"2 standard deviations below\" = \"red\", \n            \"2 standard deviations above\" = \"green\")\nggplot(population_norm, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(height), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(height)-\n                     2*sd(height), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(height)+\n                     2*sd(height), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 1200, x = mean(population_norm$height), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 1200, x = mean(population_norm$height)-\n                     2*sd(population_norm$height), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 1200, x = mean(population_norm$height)+\n                     2*sd(population_norm$height), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 1: Our imaginary population!\n\n\n\n\n\nThis bound captures 95.53% of the data.\nNow let’s sample the population. We’ll start by drawing a sample of 100 from the population. This is true random sampling, so any differences are due to sampling error.\n\nsample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\nggplot(sample_1, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of 100 random males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nFor this sample, we have a mean of 69.78 cm and a standard deviation of 3.11 cm.",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html#moving-to-a-sample-of-means",
    "href": "content/chapters/Estimation.html#moving-to-a-sample-of-means",
    "title": "Estimation and uncertainty",
    "section": "Moving to a sample of means",
    "text": "Moving to a sample of means\nHere’s the tricky part. We typically only have one sample, but we want to discuss the uncertainty in our estimate. So, let’s explore this by drawing multiple samples (each of 100 individuals) from our population and finding the mean for each sample.\n\nnumber_of_samples &lt;- 1000\nsample_outcomes_1 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes_1$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes_1$sd[i] &lt;- sd(sample_1$height)\n  \n}\n\nThen let’s plot the means.\n\nggplot(sample_outcomes_1, aes(mean)) + \n    geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 100)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_1$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_1$mean)-\n                     2*sd(sample_outcomes_1$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_1$mean)+\n                     2*sd(sample_outcomes_1$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nFor our sample of means (this should sound weird!), we have a mean of 69.98 in and a standard deviation of 0.3 cm\nNote this suggests the mean of our means is close to the true population value of \\(\\mu\\). But the spread of our means (their standard deviation) is much less than the spread of the actual population! How much less? Let’s consider a set of smaller samples (n = 20).\n\nsample_outcomes_2 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_2 &lt;- population_norm[sample(nrow(population_norm), 20),]\n  sample_outcomes_2$mean[i] &lt;- mean(sample_2$height)\n  sample_outcomes_2$sd[i] &lt;- sd(sample_2$height)\n  \n}\n\nggplot(sample_outcomes_2, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 20)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_2$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_2$mean)-\n                     2*sd(sample_outcomes_2$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_2$mean)+\n                     2*sd(sample_outcomes_2$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nThis new sample of means has a mean of 69.96 in and a standard deviation of 0.66 cm So, the estimate for \\(\\mu\\) is still close to the same, but the standard deviation of our estimates is growing.\nThis is even more clear if we sample only 5 individuals.\n\nsample_outcomes_3 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_3 &lt;- population_norm[sample(nrow(population_norm), 5),]\n  sample_outcomes_3$mean[i] &lt;- mean(sample_3$height)\n  sample_outcomes_3$sd[i] &lt;- sd(sample_3$height)\n  \n}\n\nggplot(sample_outcomes_3, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 5)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_3$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_3$mean)-\n                     2*sd(sample_outcomes_3$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_3$mean)+\n                     2*sd(sample_outcomes_3$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nwhere we find a mean of 69.97 in and a standard deviation of 1.33 cm.\nIf we facet the graphs (and let them share an x-axis) we can see this even better\n\nsample_outcomes_1$n=100\nsample_outcomes_2$n=20\nsample_outcomes_3$n=5\nsamples_all &lt;- rbind(sample_outcomes_1,sample_outcomes_2, sample_outcomes_3)\n\nggplot(samples_all, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples\",\n       color=\"Measure\") +  facet_wrap(~n, ncol=1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nYou can clearly see larger sample sizes lead to a more “clustered’ group of means (so there is less uncertainty in the measurements!). This is why larger estimates make us more confident in our estimates - the means we get are less likely to be far away! In other words, larger samples yield more precise estimates with lower spread (lower sampling error).\nWe call the standard deviation of our means the standard error. We can calculate this as\n\\[\n[\\sigma_{\\overline{Y}} = \\frac{\\sigma}{\\sqrt{n}}] \\sim [s_{\\overline{Y}} = \\frac{s}{\\sqrt{n}}]\n\\]\nAlso, note distribution of means was normal (which we will define even better in a few lectures!). For now, that means we can get 95% of the sample means within ~2 standard deviations of the mean of means, which is very close to the true mean. Conversely, if we use data from each sample to generate a an interval ~2 standard deviations above and below each sample mean, these intervals will contain the true mean 95% of the time. We call this range a 95% confidence interval. For example, let’s take take 20 samples of 100 individuals from our fake population, then calculate and plot their confidence intervals.\n\nnumber_of_samples &lt;- 20\nsample_outcomes &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA, se = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes$sd[i] &lt;- sd(sample_1$height)\n  sample_outcomes$se &lt;- sd(sample_1$height)/sqrt(100)\n}\nsample_outcomes$sample &lt;- as.factor(1:number_of_samples)\nggplot(sample_outcomes\n       , aes(x=sample, y=mean)) +\n  geom_point() +\n  geom_errorbar(aes(ymin=mean-(2*se), ymax=mean+(2*se)))+\n  geom_hline(aes(yintercept=mean(population_norm$height))) +\n  ylab(\"Mean\")+\n  xlab(\"Sample\")+\n  ggtitle(\"Variation in error bars\")\n\n\n\n\n\n\n\n\nNotice one of samples (#2) has a range that does not include the true mean of the population!\nA few other notes about confidence intervals\n\nConfidence interval for normally-distributed samples (like those described here!) should be symmetric around the mean. This will change slightly for non-normal data (which we may address with generalized linear models that use a binomial, Poisson, or gamma distribution).\nThe “~2” is based on sample size. The value actually trends towards 1.96 at large sample sizes, but at sample sizes over ten 2 is a good estimate. You may also here this total (the 2 multiplied by the standard error) referred to as the margin of error. We could also have other numbers. For example, we could have a 90% confidence interval.\n\n\n\nWould it be wider or narrower compared to a 95% interval?\n\nIf you are less confident in the interval (90% vs 95%), the interval itself will get smaller (only 90% of samples need to have the true mean!)\n\n\nConfidence bounds also exist. These are slightly different - we’ll explain them in a few chapters.\n(more complicated) Note these calculations assumes we have lots of samples, but we typically only have one. The average probability of the first 95% CI capturing the true sample mean is only around 83%\n\n\n\n\n\n\nNeed to see this another way?\n\nThese two simulations (produced by UBC) will allow you to see this another way!\n\nRelationship between sample size and distribution of sample means for samples from a normally distributed population\nConfidence intervals",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html#what-if-the-population-isnt-normal",
    "href": "content/chapters/Estimation.html#what-if-the-population-isnt-normal",
    "title": "Estimation and uncertainty",
    "section": "What if the population isn’t normal?",
    "text": "What if the population isn’t normal?\nFinally, it turns out the underlying distribution of data doesn’t matter; only that of the trait we are focused on does. For example, the means of the data will be normally distributed as long as you have a large sample size. This is know as the central limit theorem.\nTo prove this, let’s instead consider a uniform distribution:\n\npopulation_unif &lt;- data.frame(id = 1:population_size, \n                         height = runif(population_size, 60, 80))\nggplot(population_unif, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNow, let’s do what we did above. First, draw a sample of 100\n\nsample_unif &lt;- population_unif[sample(nrow(population_unif), 100),]\nggplot(sample_unif, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of 100 random males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote the sample is still relatively uniformly distributed. This makes sense. In general, a good sample should resemble the underlying population, so this makes sense.\nNow let’s sample a 100 of these numerous times and plot the means of each sample.\n\nnumber_of_samples &lt;- 1000\nsample_outcomes_unif &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_unif &lt;- population_norm[sample(nrow(population_unif), 100),]\n  sample_outcomes_unif$mean[i] &lt;- mean(sample_unif$height)\n  sample_outcomes_unif$sd[i] &lt;- sd(sample_unif$height)\n}\nggplot(sample_outcomes_unif, aes(mean)) + \n    geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 100)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_unif$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_unif$mean)-\n                     2*sd(sample_outcomes_unif$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_unif$mean)+\n                     2*sd(sample_outcomes_unif$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNotice we are back to a normal distribution!\n\n\nNeed to see this another way?\n\nAnother UBC visualization will allow you to see this another way!\n\nCentral limit theorem: Sampling from non-normal distributions.",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html#visualization-issues",
    "href": "content/chapters/Estimation.html#visualization-issues",
    "title": "Estimation and uncertainty",
    "section": "Visualization issues",
    "text": "Visualization issues\nAs you can see above, 95% confidence intervals are commonly graphed to show the potential spread of mean values. This distinction is important, as one could plot the standard deviation of the raw the data, the standard error of the related means, or the 95% confidence interval. These can be very different. As an example,let’s return to our normal population.\n\nnumber_of_samples &lt;- 1\nsample_outcomes &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA, se = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes$sd[i] &lt;- sd(sample_1$height)\n  sample_outcomes$se &lt;- sd(sample_1$height)/sqrt(100)\n}\nsample_outcomes$sample &lt;- as.factor(1:number_of_samples)\n\nsample_1$sample &lt;- \"Data\"\nsample_1$data &lt;- sample_1$height\nonese &lt;- sample_outcomes\nonese$sample &lt;- \"+- 1 standard error\"\nonese$data &lt;- onese$mean\nonese$bar_length &lt;-  onese$se\ntwosd &lt;- sample_outcomes\ntwosd$sample &lt;- \"+- 2 standard error ~ \\n 95% confidence interval\"\ntwosd$data &lt;- twosd$mean\ntwosd$bar_length &lt;-  onese$se * 2\nonesd &lt;- sample_outcomes\nonesd$sample &lt;- \"+- 1 standard deviation\"\nonesd$data &lt;- onesd$mean\nonesd$bar_length &lt;-  onese$sd\n\nexample_clarity &lt;- merge(sample_1, onese, all.x =T, all.y = T)\nexample_clarity &lt;- merge(example_clarity, twosd, all.x =T, all.y = T)\nexample_clarity &lt;- merge(example_clarity, onesd, all.x =T, all.y = T)\n\nlibrary(plyr)\nexample_clarity$sample &lt;- relevel(as.factor(example_clarity$sample), \"Data\")\n\nggplot(example_clarity\n       , aes(x=sample, y=data)) +\n  geom_point() +\n  geom_errorbar(aes(ymin=mean-bar_length, ymax=mean+bar_length))+\n  labs(y =\"Height (cm)\", x= \"Frequency\",\n       title = \"Variation in error bar display\")\n\n\n\n\n\n\n\n\nNotice the differences! We will typically use 95% confidence intervals in class, but you should always specify in your captions and note when you read other papers!\nVisualizations of spread are commonly used with bar graphs (despite the earlier issues we noted with bar graphs!). For example, we can return to our iris data and add\n\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\n\n\n\n\nIn general, presenting the estimate for a parameter and measures of sampling error (or uncertainty) allow you to state the magnitude of a statistic. This is a different but related approach to the more commonly observed p-values (which we’ll get to!). For example, for a single population we can ask if the confidence interval includes a relevant value (like 0!). For multiple groups,we can consider if the true means are in the same range by looking at overlap in confidence intervals among the groups.",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Estimation.html#next-steps",
    "href": "content/chapters/Estimation.html#next-steps",
    "title": "Estimation and uncertainty",
    "section": "Next steps",
    "text": "Next steps\nIn this chapter we’ve started to talk about probability. In the next we will review some probability basics before we move onto testing hypotheses.",
    "crumbs": [
      "Chapters",
      "Estimation"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html",
    "href": "content/chapters/Linear_model_extensions.html",
    "title": "Linear model extensions",
    "section": "",
    "text": "The past several chapters/lessons have focused on linear models. Here we explore options for analysis when linear model assumptions are not met. In doing so, we review several different approaches, many of which could be (and are) the focal topic of courses and books. The goal here is to\nCitations to relevant articles papers and books are noted throughout for further exploration.",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#sticking-with-the-linear-model",
    "href": "content/chapters/Linear_model_extensions.html#sticking-with-the-linear-model",
    "title": "Linear model extensions",
    "section": "Sticking with the linear model",
    "text": "Sticking with the linear model\nLinear models are useful for a number of reasons. They are a great way to unify most/many tests from classical statistics. In fact, most of the ranked tests we’ve developed can actually be run as linear models when n &gt;15. For example, we can go back to our Wilcox-Mann Whitney U tests (for 2 populations) and Kruskal-Wallis (for 3+) from the comparing means among groups chapter and note the outcome from a wilcox.test\n\ntwo_species_subset &lt;- iris[iris$Species!=\"setosa\",]\nwilcox.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.869e-07\nalternative hypothesis: true location shift is not equal to 0\n\n\nis very close to a linear model predicting the signed rank of the data\n\nlibrary(car)\nsigned_rank = function(x) sign(x) * rank(abs(x))\nAnova(lm(signed_rank(Sepal.Length) ~ Species, two_species_subset), type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: signed_rank(Sepal.Length)\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  64872  1 102.378 &lt; 2.2e-16 ***\nSpecies      20967  1  33.089 1.003e-07 ***\nResiduals    62098 98                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIn fact, we could run simulations and show that p values from these 2 approaches are highly correlated (now you know what that means) with a \\(\\beta\\) of almost 1 (from Lindelov (n.d.)).\n\n\n\n\n\n\n\n\n\nLinear models are also extremely robust. Consider the basic assumptions of a linear model\n\\[\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n\\]\nAlthough the residuals are meant to be homoscedastic (equal or constant across all groups), it turns out the model is robust of when the largest group variance is 4-10x larger than the smallest group variance and sample sizes are approximately equal (Blanca et al. 2018; Fox 2015; A. F. Zuur, Ieno, and Elphick 2010), though highly uneven group sizes begin to cause issues (Blanca et al. 2018).\nSimilarly, non-normal data is not an issue. This is partially because the assumptions are focused on residuals, but also because the procedure is highly robust (Blanca et al. 2017). This finding further supports the graphical consideration of assumptions , especially since many tests for normality are conservative (samples are almost never perfectly normal, and slight deviations are easier to pick up with larger sample sizes despite the fact the central limit theorem suggests this is when the issue is least important) (A. F. Zuur, Ieno, and Elphick 2010; Shatz 2023).\nThese issues have led some authors to argue violations of the linear model assumptions are less dangerous than trying new, and often less-tested, techniques that may inflate type I error rates (Knief and Forstmeier 2021; D. I. Warton et al. 2016). However, new techniques (or sometimes old techniques that are new to a given field) may be more appropriate when assumptions are clearly broken (D. Warton and Hui 2010; Reitan and Nielsen 2016; Geissinger et al. 2022). In this section we explore common-ish approaches for analyzing data when the assumptions of a linear model are broken. Our goal here is to introduce these methods. Each could be the focus of their own class, book, or much larger study. Fortunately most can be viewed as extensions to our existing knowledge, although many of the assumptions and techniques for them are less developed/still being argued about.\nThe various assumptions related to linear models may be prioritized on their relative importance. One such order is provided (roughly) by Gelman and Hill (2006).\n\nModel validity\n\nAs noted in the multiple regression chapter, we only should investigate relationships we have a mechanism to explain\n\nLinear relationship and additive effects of predictor variables\nErrors are\n\nindependently distributed\nidentical (homoscedastic)\nfollow a normal distribution\n\n\nMany datasets will violate multiple of these assumptions simultaneously, so addressing issues is often best resolved by understanding why this is happening.",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#linear-relationship-is-inappropriate",
    "href": "content/chapters/Linear_model_extensions.html#linear-relationship-is-inappropriate",
    "title": "Linear model extensions",
    "section": "Linear relationship is inappropriate",
    "text": "Linear relationship is inappropriate\nA central (and often overlooked assumption) of linear models is that the relationship between the predictors and the outcome variable is linear and addtive. When the relationship is not linear, the resulting residuals are often not appropriately distributed as well.\n\n\nWhat’s linear anyway?\n\nTo be clear, the linear model only focuses on the linear and additive relationship between the predictors and the outcome variable (this will become more important/obvious later in this section!). The model doesn’t know what the variables are. For that reason, we can add predictor variables to a model that are squares or cubes of predictors, or we can transform the outcome variable. We just need the \\(Y = X\\beta\\) relationship to be additive and linear.\n\nWhen non-linearity occurs, several options to address it exist. The best approach may depend on why the relationship is non-linear, as relationships among variables may be non-linear for a number of reasons. For example, the outcome may not actually be continuous (e.g. counts. proportions), and thus true linear relationships are not possible; outcomes may also be related to the predictors in different ways (e.g., logarithmic).\n\nTransform the data (least advisable, sometimes)\nOne way to address non-linearity is to transform the data (typically focusing on the dependent variable) so that the resulting variable meets the linear model assumptions (and thus uses the strengths of linear models that we noted above). As shown above, our rank-based approaches are using a similar method (not technically the same, but it works for larger sample sizes). This approach was often used in the past (e.g., arc-sin transforms of proportion data D. Warton and Hui (2010)) and supported by various approaches. For example, the Box-Cox transformation helped researchers find the best way to transform data to reduce issues with the distribution of residuals; this method also tended to impact linearity and differences in variances.\nTwo things should be noted regarding this approach and transformations in general:\n\nThe Box-Cox approach requires a model - it still focused on transforming data so that residuals meet assumptions. Data should not be transformed before model assumptions are analyzed to ensure it is necessary. For example, highly skewed data may arise due to unequal sample sizes (which may pose their own problems, but not outright), but models using this data may meet assumptions.\n\n\nset.seed(8)\nexample_skewed &lt;- data.frame(Population= c(rep(\"a\",40),\n                                           rep(\"b\", 30),\n                                           rep(letters[3:4], each=15)), \n                             Growth = c(rnorm(40,1),\n                                    rnorm(30, 4),\n                                    rnorm(15, 7),\n                                    rnorm(15,10)))\nlibrary(ggplot2)\nggplot(example_skewed,aes(x=Growth))+\n  geom_histogram()+\n  labs(y=\"Some value\",\n       title=\"Example of skewed data appearing due to unequal sample size\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nplot(lm(Growth~Population, example_skewed))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(lm(Growth~Population, example_skewed), type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Growth\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   38.75  1  32.436 1.344e-07 ***\nPopulation  1007.71  3 281.175 &lt; 2.2e-16 ***\nResiduals    114.69 96                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nSimilary (and already noted!). non-normal data may lead to models with normal residuals. However, normal data (or data transformed to be more normal) does typically lead to normal residuals, so if residuals are not normal transformations may help.\nThe transformed variable is now linear in respect to the predictors. This highlights the actual assumption of the model. Similarly, higher-terms (squares, cubes, etc) may be added to a linear model. The model does not care what the data represent - it only focuses on if linear relationships exist among them.\nTransformations can make model interpretation and prediction difficult.\n\nIf the decision is made to transform the data, several approaches exist. Some are driven by the distribution of the data, and all depend on it. For example, log and related root transformations are useful for right-skewed data, but some can only be carried out for non-negative (e.g., square root) or strictly positive (e.g., log) values. To address this for log transformations, a small value is often added to 0 measurements.\nLet’s use data (not residuals) to show what different types of data look like and consider possible fixes (always fit a model first for real analysis!). For example, we can return to our right-skewed blue jay data from the summarizing data chapter(target=“_blank”)(idea from (Hunt, n.d.)) .\n\nset.seed(19)\nblue_jays &lt;- round(rbeta(10000,2,8)*100+runif(10000,60,80),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nNote the right-skewed data shows a convex curve on the Q-Q plot.\n\nqqnorm(blue_jays)\nqqline(blue_jays)\n\n\n\n\n\n\n\n\nTo help you understand Q-Q plots, remember they are comparing the relative spread of data (quantiles) from a target and theoretical distribution. For right-skewed data, points are shifted right (both smallest and largest observations are larger than you would expect from a normal distribution).\nConversely, we could also return to our left-skewed cardinal data\n\nset.seed(19)\ncardinals &lt;- round(rbeta(10000,10,2)*50+runif(10000,5,10),3)\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nand note a concave shape is seen in the Q-Q plot,as all points are shifted left.\n\nqqnorm(cardinals)\nqqline(cardinals)\n\n\n\n\n\n\n\n\nFor this type of data, power transformations (raising the variable to the 2, 3, or higher power) may be useful.\nMeanwhile, our uniformly-distributed distributed robin data\n\nset.seed(19)\nrochester &lt;- round(c(runif(1000,75,85)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nshows as a s-shape on the Q-Q plot\n\nqqnorm(rochester)\nqqline(rochester)\n\n\n\n\n\n\n\n\nbecause it is under-dispersed (has no tails, and thus the lower points are larger than expected and the higher points are smaller than expected). Alternatively, data may be over-dispersed, like this (fake) finch data where lower points are lower than expected and higher points are higher.\n\nset.seed(19)\nlibrary(VGAM)\nfinch &lt;- rlaplace(1000,location=50, scale=4)\nggplot(data.frame(finch), \n       aes(x=finch)) +\n  geom_histogram( fill=\"cyan\", color=\"black\") +\n  labs(title=\"Weight of finches\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\nqqnorm(finch)\nqqline(finch)\n\n\n\n\n\n\n\n\nOver- and under-dispersed data may mean there’s a missing factor in your analysis. For example, our bi-modal woodpecker data\n\nset.seed(19)\nwoodpeckers &lt;- round(c(rnorm(100,60,4),rnorm(100,80,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nis under-dispersed due the shape of the distribution, but there also signs of other issues.\n\nqqnorm(woodpeckers)\nqqline(woodpeckers)\n\n\n\n\n\n\n\n\nUnder-dispersion could also happen if data are bounded (e.g., by practicality or due to a measurement issue). Over-dispersion can similarly occur if the model does not account for variability (e.g., missing factors, non-linear relationship) and/or outliers, which might be related to the underlying form of the data (Payne et al. 2017) (more to come on this). In this way, over- and under-dispersion relate to both the linear relationship.\n\n\nDifferent data require a different approach: Introducing generalized linear models\nThe linear relationship may be inappropriate because our data doesn’t fit it! For example, if we are modeling proportions, estimates less than 0 or below 1 do not make sense, but a linear model doesn’t account for that. The same issues arise for binary outcomes (outcome must be 0 or 1) and count data (where outcomes can’t be non-integer). While we may be able to transform the response variable to make relationships linear, another option is to translate the link function.\nAlthough we haven’t fully explained it yet, a linear model contains three components. There is always a random component that focuses on the distribution of the data. There is also a systematic component, where a number of covariates and data points produce an estimate. Finally, there is the link function, which connects that estimate to the data distribution (this maintains the linearity of the model).\nNotice this means the link connects to the distribution of the data, not the data itself (which is what transforming the data is doing). So far we have focused on the mean of the data, and the estimate is the mean, so the link has been implied. We can generalize this setup to include other distributions in the exponential family (and now others (“Applied Regression Analysis and Generalized Linear Models” 2022, ch. 15)).\nWhile we won’t develop all the math, exponential family distributions all have a canonical parameter (the mean for Gaussian, or normal, data) and a dispersion parameter (the variance for normal data). Different distributions have different relationships between these two parameters. For normal data, there is no relationship, so the variance is constant. This is not true for other families; for example, the variance in binomial data depends on the p parameter (as we noted in the [chapter introducing binomial data](Binomial.qmd){target=“_blank”))!\nWe can specify other families using generalized linear models (which are different than general linear models, which is another term used to describe our “regular” linear models). These models are also known as glm or glim (we’ll use the glm jargon here). GLM make different assumptions (though everyone does not agree on what they are!). While we still need independence of the residuals (or some extension, see below), they no longer need to be normally distributed (A. Zuur, Ieno, and Smith 2007, 86–87; A. Zuur et al. 2009, sec. 9.8.3) (though normality may hold at large sample sizes for Pearson (Agresti 2007, 87) or deviance (Montgomery, Peck, and Vining 2012, sec. 13.4.4)  residuals, and some authors argue normality is required for testing (Feng, Li, and Sadeghpour 2020)) . As noted above, non-Gaussian families don’t assume a constant variance, so homogeneity assumptions would not be appropriate (Fox 2016). However, we need to ensure the correct family (and thus mean-variance link) is chosen. In general, plotting the residuals against (A. Zuur et al. 2009)\n\nthe predicted values\n\nto check for model fit\n\neach explanatory variable in model\n\nto check for linearity\n\neach explanatory not retained/used in model\n\nto check for missing patterns\n\nagainst time and space (if applicable)\n\nto check for patterns and correlation\n\n\nwill be useful. Any patterns may suggest missing predictors or lack of independence/correlation among measurements. Patterns in the residuals may also indicate the incorrect family has been chosen (A. Zuur et al. 2009, sec. 9.8.4); for families with fixed dispersion parameters, inspection of the estimated dispersion parameter can also be a related diagnostic.\n\n\nWhat are residuals for a GLM?\n\nResiduals for a Gaussian/normal glm (what we’ve been doing) are easy to calculate. We simply subtract the estimate for each data point (which is the average for similar observations!) from the observed. However, though these raw or response residuals exist for GLM, they rarely make sense. Variance may increase with mean for some distributions, for example, or outcomes may be binary (so every residual is 0 or 1!).\nTo account for this, we could divide the residuals by the standard deviation of the observations. This normalizes the residuals and leads to Pearson residuals. Another option is based on something called deviance. Deviance is similar to sums of squares but based on likelihood (which we shortly see is what we use to test for significance in GLM); it can also be considered the generalized form of variance or residual sums of squares. It is calculated as the difference of log-likelihoods between the focal model and the saturated model (or a model that has a coefficient for every observation and thus will have perfect fit). Deviance residuals consider how important each point is to the overall deviance. You can also compare the deviance of a model to a perfect fit (no deviance/saturated) model and an intercept-only model (worst fit, DO) and generate a pseudo-R2 measure using the formula\n\\[\n1-\\frac{D}{D_O}\n\\]\nThis is known as McFadden’s pseudo-R2 value.\n\nOnce developed, GLMs can use most of the tools we developed for basic linear models. However, a few key differences exist. Estimation of parameters and significance for these models rely on maximum-likelihood methods (remember, the ratio of likelihood values follow a \\(\\chi^2\\) distribution and can thus provide a p-value to compare possible models as noted in introducing G tests{target=“_blank”)).This may be represented as a Z test for single parameters (since a \\(\\chi^2\\) distribution is a Z distribution squared - sometimes labelled a Wald test/statistic). F test reappear for distributions where we estimate the dispersion parameter (like the normal), but otherwise we can use the dispersion parameter to check that the right approach was taken.\nIt should be noted that solving for coefficents also requires iterative approaches due to non-linearity; common methods (not described here) include the Newton-Raphson or Fisher scoring methods. The key point here for practice is any noted issues with optimization are due to this process. Finally, it should be noted that coefficients and predictions are related to the estimate, which is no longer the actual mean. This means impacts and outcomes will need to be transformed (based on the link) to the actual scale.\nThere are numerous types of GLMs. Here we outline some of the more common ones. Each of these deserves a much fuller treatment - remember, the intent here is to get you to a place to where you can begin working with them. Harrison et al. (2018) (which also covers mixed models (coming up!)) provides an excellent review of these models, and fuller treatments are provided by A. Zuur et al. (2009) (chapters 8-11) and Fox (2016) (chapters 14 - 15). For each I provide the most relevant math, an example (or two), and some immediate extensions.\n\nLogistic regression: Bernoulli and binomial outcomes\nLogistic regression focuses on modelling yes/no or success/failure outcomes (Bernoulli or binomial data) using the logit link (thus logistic regression). The easy-to-understand issue here is that we want to focus on probability (\\(\\pi\\)), but that can only vary from 0 to 1. Linear models are thus inappropriate, but the logit link can be used where the systematic component of the model predicts\n\\[\nlogit(\\pi) = \\ln(\\frac{\\pi}{1-\\pi}), \\text{where } \\pi \\text{ is the probability for a given set of outcomes}\n\\]\nThis logit link is useful as it effectively connects the systematic component and real data (the purpose of the link). This link also allows coefficients to be interpreted as odds and odds ratios (introduced in the comparing proportions among groups- we’ll continue to see connections this chapter for logistic regression). Remember, the odds can be written as\n\\[\n\\frac{\\pi}{1-\\pi}\n\\]\nFor a given coefficient \\(\\beta\\), the logit link also means we can say a 1 unit increase in that single variable leads to a change in the odds ratio of \\(e^{\\beta}\\). This also means no impact is shown as \\(\\beta = 0\\), with positive and negative numbers implying increases or decreases in odds, which is convenient. Other link options (not discussed here) include the probit and complementary log-log approaches. For a final piece of math, note the dispersion parameter for binomial data is not estimated - it is assumed to be 1.\nFor example, Blais, Johnson, and Koprowski (2023) investigated how various factors impacted behavior in garter snakes (Thamnophis cyrtopsis).\n\n\n\nJuan Carlos Fonseca Mata, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\n\n\nOne of their analyses considered how snake movement(labelled 0 for no movement, 1 for movement) differed among age classes (adults and juveniles).\n\nbehavior &lt;- read.csv(\"data/database_Thamnophis_crytopsis_study - Copy of THCY_MH_BEH.csv\",\n                     stringsAsFactors = T)\nbehavior_table &lt;- table(behavior$movement, behavior$ageclass)\nbehavior_table\n\n   \n    adult juvenile\n  0    29       29\n  1    14       16\n\n\nYou may recognize this analyses could be carried out using \\(\\chi^2\\) tests.\n\nchisq.test(behavior_table)\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  behavior_table\nX-squared = 0.0051228, df = 1, p-value = 0.9429\n\n\nwhich indicate no impact of age class on movement (p=.9429). You (hopefully) also remember we mentioned the Yate’s correction (noted in the output) was due to using a continuous distribution to fit counts. If we remove it,\n\nchisq.test(behavior_table, correct = F)\n\n\n    Pearson's Chi-squared test\n\ndata:  behavior_table\nX-squared = 0.087924, df = 1, p-value = 0.7668\n\n\nwe find an answer that we can replicate using glm (since the outcome is a 0 or 1 here!). We do this using the glm function in base R, which is very similar to the lm function; the only difference is we now note the distribution we are exploring using the “family” argument. Note Bernoulli data is considered a subset of binomial data and thus classified as “binomial”.\n\nas_glm &lt;- glm(movement~ageclass, behavior, family = \"binomial\")\n\nWe can then use our normal approach (including summary, Anova, and glht functions) to consider the outcomes. Checking assumptions is a little trickier than for linear models (as noted above). One major check is typically ensuring the dispersion parameter is correct. We can typically check the parameter by dividing the residual deviance by its associated degrees of freedom; this information is provided by the summary function (here, 112.84/86);\n\nsummary(as_glm)\n\n\nCall:\nglm(formula = movement ~ ageclass, family = \"binomial\", data = behavior)\n\nCoefficients:\n                 Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)       -0.7282     0.3254  -2.238   0.0252 *\nageclassjuvenile   0.1335     0.4504   0.296   0.7669  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 112.93  on 87  degrees of freedom\nResidual deviance: 112.84  on 86  degrees of freedom\n  (15 observations deleted due to missingness)\nAIC: 116.84\n\nNumber of Fisher Scoring iterations: 4\n\n\nFor Bernoulli data like this, however, over-dispersion is not an issue (Molenberghs et al. 2012). Forbinomial and Poisson data, this should be approximately. We can note the impact of given factors using Anova\n\nAnova(as_glm, type=\"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: movement\n         LR Chisq Df Pr(&gt;Chisq)\nageclass 0.087974  1     0.7668\n\n\nwhich now uses likelihood-based tests by default. Similarly, the summary output notes details related to fitting the model (Number of Fisher scoring iterations). To interpret the coefficient from the glm, we need to consider the link function (here, the logit). If we backtransform the logit link function, we can actually say that juveniles had a \\(e^\\beta\\) greater odds of movement than adults, which is equal to\n\nexp(.1335)\n\n[1] 1.142821\n\n\nand very close to 1 (thus the high p-value given our small sample size).\nWhile this example simply replicates the \\(\\chi^2\\) tests we learned earlier (deviations may arise when counts are low or high for any group, and thus \\(\\hat{p}\\) approaches extreme values and breaks the assumptions!), the power of these models comes from the ability to consider multiple variables (which we couldn’t do before). These models are sometimes called log-linear models.\nTo consider this approach and extend glm to binomial data, consider work by Bueno, Machado, and Leite (2020). The authors carried out a series of experiments to determine how various factors impacted colonization of a host algae, Sargassum filipendula, by a small amphipod, Cymadusa filosa.\n\n\n\nRob Young, Centre for Biodiversity Genomics - CC - BY - NC - S\n\n\nFor one experiment, they stocked portions of aquariums with pieces of algal. Half the algae pieces had adult amphipods present(4 total; the species builds tubes to live on algae) while the other half had no adult residents. Juveniles were initially placed on patches of natural substrate, artificial substrate, or bare areas(no substrate) in the aquarium. After 24 hours, the number of juveniles that colonized the focal algae were counted. Since the number of introduced juveniles was known, the number that did not colonize was also accounted for (raw data estimated from supplemental data given variation in sample size).\n\njuvenile &lt;- read.csv (\"data/Supplemental_Data_Bueno_2020-S1-Presence of adults_lab.csv\", \n                      stringsAsFactors = T)\n\nsince the adults column indicates the presence or absence of adults, let’s update it for clarity\n\nlibrary(plyr)\njuvenile$adults_updated &lt;- factor(revalue(as.character(juvenile$adults), c(\"0\"= \"absent\", \"4\" =\"present\")))\n\nThis is an example of a factorial-design with the following hypotheses:\n\nnull hypothesis\n\nHO: There is no impact on the habitat type juveniles start in on their likelihood to move\nHO: There is no impact on adult presence in the new habitat on the likelihood of juveniles to move\nHO: There is no interaction between the impacts of the habitat type juveniles start in and adult presence in the new habitat on the likelihood of juveniles to move\n\nalternative hypothesis\n\nHA: There is an impact on the habitat type juveniles start in on their likelihood to move\nHA: There is an impact on adult presence in the new habitat on the likelihood of juveniles to move\nHA: There is an interaction between the impacts of the habitat type juveniles start in and adult presence in the new habitat on the likelihood of juveniles to move\n\n\nThe outcome, however, is a proportion. Note we can fit a linear model to the data:\n\njuvenile_fit_lm &lt;- lm(Colonized ~ adults_updated*source.habitat, \n    juvenile)\nplot(juvenile_fit_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe assumptions don’t even look that bad, but note the data is over-dispersed (will come back to this). We also know the model will make predictions that aren’t logical (outcomes outside of the 0-1 range). For this reason we will use a generalized linear model (or a log linear model) to analyze the data. We can fit a glm using the binomial family.\n\njuvenile_fit_glm &lt;- glm(cbind(Colonized, Not_colonized) ~ adults*source.habitat, \n    juvenile, family = \"binomial\")\n\nThe summary again allows us to estimate the dispersion parameter by dividing the residual deviance by its associated degrees of freedom, and we can now consider the impact of multiple variables (including interactions, which are significant here!).\n\nsummary(juvenile_fit_glm)\n\n\nCall:\nglm(formula = cbind(Colonized, Not_colonized) ~ adults * source.habitat, \n    family = \"binomial\", data = juvenile)\n\nCoefficients:\n                             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                   1.84583    0.31063   5.942 2.81e-09 ***\nadults                       -0.28417    0.09507  -2.989 0.002799 ** \nsource.habitatnatural        -3.88271    0.43669  -8.891  &lt; 2e-16 ***\nsource.habitatnone            1.02207    0.55484   1.842 0.065459 .  \nadults:source.habitatnatural  0.46383    0.13819   3.356 0.000789 ***\nadults:source.habitatnone    -0.38722    0.15665  -2.472 0.013441 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 347.435  on 35  degrees of freedom\nResidual deviance:  97.393  on 30  degrees of freedom\nAIC: 186.64\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(juvenile_fit_glm, type=\"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(Colonized, Not_colonized)\n                      LR Chisq Df Pr(&gt;Chisq)    \nadults                   9.712  1   0.001831 ** \nsource.habitat         195.748  2  &lt; 2.2e-16 ***\nadults:source.habitat   34.738  2  2.862e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe see that there is a significant interaction between the presence of adults and source habitat on the proportion of amphipods that move to colonize algae.\nADD RESULTS…break up one way anova, etc.\nHowever, we also note that our dispersion estimate is 97.393/30 ~ 3; this should be closer to 1! What should we do? One option is to use an approach that estimates the dispersion parameter. Though not fully developed here, this approach uses a “quasi-binomial” family.\n\njuvenile_fit_glm_quasi &lt;- glm(cbind(Colonized, Not_colonized) ~ adults*source.habitat, \n    juvenile, family = \"quasibinomial\")\nsummary(juvenile_fit_glm_quasi)\n\n\nCall:\nglm(formula = cbind(Colonized, Not_colonized) ~ adults * source.habitat, \n    family = \"quasibinomial\", data = juvenile)\n\nCoefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    1.8458     0.5562   3.319  0.00238 ** \nadults                        -0.2842     0.1702  -1.669  0.10544    \nsource.habitatnatural         -3.8827     0.7819  -4.966 2.56e-05 ***\nsource.habitatnone             1.0221     0.9934   1.029  0.31177    \nadults:source.habitatnatural   0.4638     0.2474   1.875  0.07060 .  \nadults:source.habitatnone     -0.3872     0.2805  -1.381  0.17760    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for quasibinomial family taken to be 3.205612)\n\n    Null deviance: 347.435  on 35  degrees of freedom\nResidual deviance:  97.393  on 30  degrees of freedom\nAIC: NA\n\nNumber of Fisher Scoring iterations: 5\n\nAnova(juvenile_fit_glm_quasi, type=\"III\")\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: cbind(Colonized, Not_colonized)\n                      LR Chisq Df Pr(&gt;Chisq)    \nadults                   3.030  1   0.081751 .  \nsource.habitat          61.064  2  5.496e-14 ***\nadults:source.habitat   10.837  2   0.004435 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ndd in McFadden’s R^2.rcompanion:compareglm\n\n\nBeta regression\nBeta regression focuses on true proportion data where the outcome is between 0 and 1.\n\n\nPoisson regression\nPoisson regression focuses on count-based data.\n\n\nNon-linear options",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#data-are-not-independent",
    "href": "content/chapters/Linear_model_extensions.html#data-are-not-independent",
    "title": "Linear model extensions",
    "section": "Data are not independent",
    "text": "Data are not independent\n\nIn respect to predictors\nA major issue for linear models is when predictors are co-linear. Mathematically speaking, perfect collinearity occurs when any column of the design (X) matrix can be derived by combining other columns. Perfect collinearity will lead to a message noting singularity issues, which is R’s way of telling you the matrix isn’t invertible (which it has to be to solve the equation).\nEven partial collinearity will lead to an increase in Type II errors (A. F. Zuur, Ieno, and Elphick 2010). To put it simply, partitioning variance among related predictors is hard. For this reason, a few approaches may be used.\n\nCheck for issues\nThe first step is identifying issues. From the outset, relationships among predictor variables can be assessed using the pairs function in R. If two variables are highly correlated (r2 &gt; .8 is a general limit), only one should be included in the model. Similarly, variance inflation factors (vif) can be assessed for the final and other models to consider this issues (all this is covered in the previous chapter that introduces multiple regression.\n\n\n\nIn respect to measured outcomes\nWhen outcome variables are linked together, a few options exist. Note this issue may be obvious from checks of assumptions, but it also may be due to experimental design.\nConsider this example. In order to investigate impacts of climate stress on oysters, specimens are placed in individual tanks and held at normal summer (calculated using recent data) temperature or at temperatures predicted under 2 IPCC — Intergovernmental Panel on Climate Change- scenarios. Oysters were also exposed to predator cues by dropping in water from tanks with 0, low (.25/m2), or high (2/m2) predators. After two months changes in oyster shell length (growth) was measured. Twenty-five oysters were measured for each treatment combination.\nYou hopefully recognize this as a factorial ANOVA experiment that you know how to analyze. If you need a reminder, see the chapter on ANOVA extensions. Experiments like this are odd, however, given the space they require. It is far more common to put lots of organisms in a single container given space and costs. However, this means our measurements are connected; remember blocking and paired tests)?\nThere are several ways to deal with this. Here we explore each for our oyster example.\n\nIgnore it (don’t do this!)\nFirst, let’s ignore the lack of independence. This is not an option, but it let’s you see the impact.\n\ngrowth_lm &lt;- lm(growth~predator_cue*temperature, experiment)\nplot(growth_lm)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(growth_lm, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: growth\n                          Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)               15.576   1 16.3673 7.265e-05 ***\npredator_cue              22.085   2 11.6031 1.635e-05 ***\ntemperature               70.061   2 36.8090 1.753e-14 ***\npredator_cue:temperature  21.376   4  5.6154 0.0002558 ***\nResiduals                205.563 216                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe find significant main effects and interactions using this wrong approach.\n\n\nFind average for each unit\nOne way of doing this focuses on the average for each unit\n\nlibrary(Rmisc)\naveraged_experiment &lt;- summarySE(experiment, measurevar = \"growth\",\n                             groupvars = c(\"predator_cue\", \"temperature\", \"container\"))\nlibrary(rmarkdown)\npaged_table(averaged_experiment)\n\n\n  \n\n\n\nand use that for your analysis.\n\naverage_analysis &lt;- lm(growth~predator_cue*temperature, averaged_experiment)\nAnova(average_analysis, type = \"III\")\n\nError in Anova.lm(average_analysis, type = \"III\"): residual df = 0\n\n\nbut that leads to an issue! Since we only get 9 average outcomes and our model requires 10 degrees of freedom (consider why), we are left with no “noise” to make the denominator for our F ratio! Even when this doesn’t happen, you have reduced your data to a much smaller number of points and are not getting credit for all your work! This is a good example of why you should analyze simulated data before you run an experiment, but there are other options.\n#####Blocking\nThe blocking approach we’ve already covered works might seem appropriate here.\n\nblocking_analysis &lt;- lm(growth~predator_cue*temperature+container, experiment)\nAnova(blocking_analysis, type = \"III\")\n\nError in Anova.III.lm(mod, error, singular.ok = singular.ok, ...): there are aliased coefficients in the model\n\n\nbut its not? Why? This error means now our model matrix has collinearity issues. WE can actually see where\n\nalias(blocking_analysis)\n\nModel :\ngrowth ~ predator_cue * temperature + container\n\nComplete :\n                                                 (Intercept) predator_cuenone\ncontainerf                                        0           0              \ncontainerg                                       -1           1              \ncontainerh                                        0           0              \ncontaineri                                        1          -1              \npredator_cuenone:temperatureelevated_scenario1    0           0              \npredator_cuenormal:temperatureelevated_scenario1  0           0              \npredator_cuenone:temperatureelevated_scenario2   -1           1              \npredator_cuenormal:temperatureelevated_scenario2  0           0              \n                                                 predator_cuenormal\ncontainerf                                        0                \ncontainerg                                        0                \ncontainerh                                        1                \ncontaineri                                       -1                \npredator_cuenone:temperatureelevated_scenario1    0                \npredator_cuenormal:temperatureelevated_scenario1  0                \npredator_cuenone:temperatureelevated_scenario2    0                \npredator_cuenormal:temperatureelevated_scenario2  1                \n                                                 temperatureelevated_scenario1\ncontainerf                                        1                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                       -1                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 temperatureelevated_scenario2\ncontainerf                                        0                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                        0                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 containerb containerc\ncontainerf                                        0          0        \ncontainerg                                        1          1        \ncontainerh                                       -1          0        \ncontaineri                                        0         -1        \npredator_cuenone:temperatureelevated_scenario1    0          0        \npredator_cuenormal:temperatureelevated_scenario1  0          0        \npredator_cuenone:temperatureelevated_scenario2    1          1        \npredator_cuenormal:temperatureelevated_scenario2 -1          0        \n                                                 containerd containere\ncontainerf                                       -1         -1        \ncontainerg                                       -1          0        \ncontainerh                                        0         -1        \ncontaineri                                        1          1        \npredator_cuenone:temperatureelevated_scenario1    1          0        \npredator_cuenormal:temperatureelevated_scenario1  0          1        \npredator_cuenone:temperatureelevated_scenario2   -1          0        \npredator_cuenormal:temperatureelevated_scenario2  0         -1        \n\n\nthough the output is confusing. In general, the issue here is each unit only contributes to one level of other traits..so if we know the average impact of ambient temperatures, for example, and the impacts in two of the treatments that were held at that temperature, we can predict the other. If instead each unit contributed to multiple levels, like in feather experiment) this isn’t an issue.\n\n\nRandom effects\nOur final option takes a new approach. It considers the units we measured as simply a sample from a larger population. Using that background, we use the information from the units to consider the distribution of sample effects we might see. The impact of unit is then considered a random-effect. For this to work, you probably want 5+ levels of the unit variable. This is because we are using the means to estimate variance (confusing?). For factors with &lt;5 levels, random effects likely offer no benefit (Gomes 2022).\nWhen models contain fixed (what we’ve done before) and random effects, we call them mixed-effects models. Two common packages for carrying out this analysis in R are the nlme and lme4 packages. We will focus on the lme4 package here. Random effects can be entered in the lmer (linear mixed-effects regression) function and specified as (1|Grouping Unit). One nice thing about lme4 is it will handle crossed and random effects on it’s own as long as you don’t repeat unit names. For example, we could note\n\nmixed_analysis &lt;- lmer(growth~predator_cue*temperature+(1|container), experiment)\n\nOnce built, we need to consider assumptions. The main assumption we add here is that the random effects are normally distributed. This should be checked at each level of grouping. The check_mixed_model function (provided below) offers an automated approach for one level (also known as one-way random effects).\n\ncheck_mixed_model &lt;- function (model, model_name = NULL) {\n  #collection of things you might check for mixed model\n  par(mfrow = c(2,3))\n  if(length(names(ranef(model))&lt;2)){\n    qqnorm(ranef(model, drop = T)[[1]], pch = 19, las = 1, cex = 1.4, main= paste(model_name, \n                                                                                  \"\\n Random effects Q-Q plot\"))\n    qqline(ranef(model, drop = T)[[1]])\n  }\n  plot(fitted(model),residuals(model), main = paste(model_name, \n                                                    \"\\n residuals vs fitted\"))\n  qqnorm(residuals(model), main =paste(model_name, \n                                       \"\\nresiduals q-q plot\"))\n  qqline(residuals(model))\n  hist(residuals(model), main = paste(model_name, \n                                      \"\\nresidual histogram\"))\n}\n\n\ncheck_mixed_model(mixed_analysis)\n\n\n\n\n\n\n\n\nHere we have only 9 levels of units, so the spread is not perfect. However, we also know each of these is itself an average,and averages should be normally-distributed under the central limith theorem, so we can plow ahead.\nWe can consider the outcome using our summary command - note the output denotes we have 225 observations and 9 grouping levels.\n\nsummary(mixed_analysis)\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: growth ~ predator_cue * temperature + (1 | container)\n   Data: experiment\n\nREML criterion at convergence: 631.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.68605 -0.79915 -0.02646  0.70023  2.72393 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n container (Intercept) 4.6171   2.1487  \n Residual              0.9517   0.9755  \nNumber of obs: 225, groups:  container, 9\n\nFixed effects:\n                                                 Estimate Std. Error t value\n(Intercept)                                       0.78934    2.15758   0.366\npredator_cuenone                                  1.28982    3.05129   0.423\npredator_cuenormal                                0.92308    3.05129   0.303\ntemperatureelevated_scenario1                     0.03073    3.05129   0.010\ntemperatureelevated_scenario2                     2.06547    3.05129   0.677\npredator_cuenone:temperatureelevated_scenario1    0.46256    4.31517   0.107\npredator_cuenormal:temperatureelevated_scenario1 -0.24377    4.31517  -0.056\npredator_cuenone:temperatureelevated_scenario2   -1.22466    4.31517  -0.284\npredator_cuenormal:temperatureelevated_scenario2 -0.63903    4.31517  -0.148\n\nCorrelation of Fixed Effects:\n             (Intr) prdtr_cnn prdtr_cnr tmpr_1 tmpr_2 prdtr_cnn:_1 prdtr_cnr:_1\npredatr_cnn  -0.707                                                            \nprdtr_cnrml  -0.707  0.500                                                     \ntmprtrlvt_1  -0.707  0.500     0.500                                           \ntmprtrlvt_2  -0.707  0.500     0.500     0.500                                 \nprdtr_cnn:_1  0.500 -0.707    -0.354    -0.707 -0.354                          \nprdtr_cnr:_1  0.500 -0.354    -0.707    -0.707 -0.354  0.500                   \nprdtr_cnn:_2  0.500 -0.707    -0.354    -0.354 -0.707  0.500        0.250      \nprdtr_cnr:_2  0.500 -0.354    -0.707    -0.354 -0.707  0.250        0.500      \n             prdtr_cnn:_2\npredatr_cnn              \nprdtr_cnrml              \ntmprtrlvt_1              \ntmprtrlvt_2              \nprdtr_cnn:_1             \nprdtr_cnr:_1             \nprdtr_cnn:_2             \nprdtr_cnr:_2  0.500      \n\n\nWe can also still use Anova to get p-values. However, these are now calculated by default using likelihood-associated \\(\\chi^2\\) tests.\n\nAnova(mixed_analysis, type = \"III\")\n\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: growth\n                          Chisq Df Pr(&gt;Chisq)\n(Intercept)              0.1338  1     0.7145\npredator_cue             0.1898  2     0.9095\ntemperature              0.6020  2     0.7401\npredator_cue:temperature 0.1837  4     0.9960\n\n\nYou can also ask for F tests, but note the degrees of freedom associated with these tests is not clear. It’s somewhere between the “average” and “ignore” approach used above.\n\nAnova(mixed_analysis, type = \"III\", test=\"F\")\n\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: growth\n                              F Df  Df.res Pr(&gt;F)\n(Intercept)              0.1338  1 3230137 0.7145\npredator_cue             0.0949  2 3230137 0.9095\ntemperature              0.3010  2 3230137 0.7401\npredator_cue:temperature 0.0459  4 3230137 0.9960\n\n\nNote this approach suggests we do not have enough data to reject the null hypothesis. Ignoring the linkages among data led to very different results. This issue (pseudopreplication) has been noted in ecology and other fields (Hurlbert 1984; Heffner, Butler, and Reilly 1996; Lazic 2010).",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#errors-are-not-equal-among-groups",
    "href": "content/chapters/Linear_model_extensions.html#errors-are-not-equal-among-groups",
    "title": "Linear model extensions",
    "section": "Errors are not equal among groups",
    "text": "Errors are not equal among groups\nAnother option is to use weighted-least squares regression - this approach specifically helps when residuals are not evenly distributed among groups (or when a funnel/cone appears when you plot the model to check assumptions). For example, we could take the model on below-ground biomass that we developed in the More Anovas chapter. As a reminder, Valdez et al. (2023) wanted to consider the impact of top-down (snail grazing) and bottom- up (nutrient availability) on marsh plant (Spartina alterniflora) growth. To do this, they assigned plots to one of 3 grazer treatments and one of 2 nitrogen treatments. We focused on the impact of these treatments on standing dead mass and noted a funnel-shape when reviewing the residuals.\n\nvaldez_2023 &lt;- read.csv(\"data/Spartina_alterniflora_traits.csv\", stringsAsFactors = T)\nsdm_model &lt;-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\nplot(sdm_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTo address the, we can use weighted least squares. This approach assume you built the model and then noted an issue with heteroscedasticity. To use, we can calculate a weight for each residual that is based on its variance. Doing this requires an iterative process similar to those used for estimation for generalized linear models (we’ll get to these) - below makes a value that increases with low variance.\n\nwt_sdm &lt;- 1 / lm(abs(sdm_model$residuals) ~ sdm_model$fitted.values)$fitted.values^2\n\nWe can then add a new argument to the lm function to use these weights.\n\nsdm_model_wls &lt;-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], weights = wt_sdm)\n\nWe can then continue on our normal route:\n\nplot(sdm_model_wls) \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_wls, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n                            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)                203.228  1  76.442 1.497e-06 ***\nSnail.Level                157.447  2  29.611 2.288e-05 ***\nNitrogen.level             130.416  1  49.054 1.427e-05 ***\nSnail.Level:Nitrogen.level 143.013  2  26.896 3.681e-05 ***\nResiduals                   31.903 12                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf you compare the two models you notice slight differences - these are minimal here due to lack of differences in variance.\n\nsummary(sdm_model) \n\n\nCall:\nlm(formula = Standing.Dead..dry..m2. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5800 -0.8350 -0.0317  0.6600  3.7400 \n\nCoefficients:\n                                                Estimate Std. Error t value\n(Intercept)                                       18.710      1.032  18.124\nSnail.Levelremoval                               -14.150      1.460  -9.692\nSnail.Levelsnail addition                         -7.567      1.460  -5.183\nNitrogen.levelwithout                            -15.240      1.460 -10.439\nSnail.Levelremoval:Nitrogen.levelwithout          16.153      2.065   7.824\nSnail.Levelsnail addition:Nitrogen.levelwithout   10.357      2.065   5.016\n                                                Pr(&gt;|t|)    \n(Intercept)                                     4.39e-10 ***\nSnail.Levelremoval                              5.02e-07 ***\nSnail.Levelsnail addition                       0.000228 ***\nNitrogen.levelwithout                           2.25e-07 ***\nSnail.Levelremoval:Nitrogen.levelwithout        4.72e-06 ***\nSnail.Levelsnail addition:Nitrogen.levelwithout 0.000301 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.788 on 12 degrees of freedom\nMultiple R-squared:  0.9284,    Adjusted R-squared:  0.8986 \nF-statistic: 31.14 on 5 and 12 DF,  p-value: 1.792e-06\n\nsummary(sdm_model_wls)\n\n\nCall:\nlm(formula = Standing.Dead..dry..m2. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ], weights = wt_sdm)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-2.31784 -0.89013 -0.03702  0.92266  2.46121 \n\nCoefficients:\n                                                Estimate Std. Error t value\n(Intercept)                                       18.710      2.140   8.743\nSnail.Levelremoval                               -14.150      2.202  -6.426\nSnail.Levelsnail addition                         -7.567      2.490  -3.039\nNitrogen.levelwithout                            -15.240      2.176  -7.004\nSnail.Levelremoval:Nitrogen.levelwithout          16.153      2.322   6.956\nSnail.Levelsnail addition:Nitrogen.levelwithout   10.357      2.620   3.953\n                                                Pr(&gt;|t|)    \n(Intercept)                                     1.50e-06 ***\nSnail.Levelremoval                              3.27e-05 ***\nSnail.Levelsnail addition                        0.01030 *  \nNitrogen.levelwithout                           1.43e-05 ***\nSnail.Levelremoval:Nitrogen.levelwithout        1.53e-05 ***\nSnail.Levelsnail addition:Nitrogen.levelwithout  0.00192 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.631 on 12 degrees of freedom\nMultiple R-squared:  0.8747,    Adjusted R-squared:  0.8225 \nF-statistic: 16.75 on 5 and 12 DF,  p-value: 4.789e-05\n\n\nWhy not just always do this? Because weighted least squares implicitly assumes we know the weights. We are actually estimating them, so small datasets may lead to bad estimates and outcomes.",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#residuals-are-not-normally-distributed",
    "href": "content/chapters/Linear_model_extensions.html#residuals-are-not-normally-distributed",
    "title": "Linear model extensions",
    "section": "Residuals are not normally distributed",
    "text": "Residuals are not normally distributed\nA very common concern regarding linear models is normality. I list it first here due to how often I see it noted, but in fact this assumption is one of the least important (and the assumption is based on residuals, not data!). However, non-normal residuals are often (not always) connected to other issues, namely linearity, as noted above.",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#combinining-these",
    "href": "content/chapters/Linear_model_extensions.html#combinining-these",
    "title": "Linear model extensions",
    "section": "Combinining these",
    "text": "Combinining these",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Linear_model_extensions.html#next-steps",
    "href": "content/chapters/Linear_model_extensions.html#next-steps",
    "title": "Linear model extensions",
    "section": "Next steps",
    "text": "Next steps\nThese methods can be extended to other models that are used when linear model assumptions are not met, which is the focus of the next chapter.",
    "crumbs": [
      "Chapters",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/chapters/Probability.html",
    "href": "content/chapters/Probability.html",
    "title": "Probability",
    "section": "",
    "text": "We’ve already address probability. When we stated the 95% confidence interval means that if we make these intervals from 100 samples that we expect 95 of them to contain the true mean, we are discussing probability. An even easier example is flipping a coin. You probably know there is a 50% chance of a coin landing on heads. That doesn’t mean given flip will be half heads and half tails. Both of these statements refer to likely outcomes if we do something many, many times!",
    "crumbs": [
      "Chapters",
      "Probability"
    ]
  },
  {
    "objectID": "content/chapters/Probability.html#what-is-probability",
    "href": "content/chapters/Probability.html#what-is-probability",
    "title": "Probability",
    "section": "What is probability?",
    "text": "What is probability?\nTo put it specifically, the probability of an outcome is its true relative frequency, the proportion of times the event would occur if we repeated the same process over and over again. We can describe the probability if an outcome by considering all the potential outcomes and how likely each is. If we describe all the outcomes, the total probability must be equal to 1 (since frequency is typically measured as a fraction!). Some probability distributions can be described mathematically, others are a list of possible outcomes, and others are almost impossible to solve. The “impossible” ones require simulations, and we will return to this for our introduction to Bayesian analysis.\nThe simplest case is when we focus on outcomes for a single trait that falls into specific categories. These outcomes are often mutually exclusive, meaning only one can happen (like our heads and tails example!), and lead to discrete probability distributions (meaning each outcome has to be a specific value). Another example is rolling a 6-sided die. The die can only land on numbers 1 to 6 (so 2.57 is not an option!).\n\ndie_roll &lt;- data.frame(Number = 1:6, Probability = rep(1/6,6))\ndie_roll$Number &lt;- factor(die_roll$Number)\n\nlibrary(ggplot2)\nggplot(die_roll, aes(x=Number, y= Probability, fill=Number)) +\n  geom_col() \n\n\n\n\n\n\n\n\nin this example, the probability of rolling a 6 is .167. You may see this written as\n\\[\nP[roll=6]= \\frac{1}{6} \\sim .167\n\\]Obviously when you roll a die you don’t roll .167 of a 6. You roll a 1, 2, 3, 4, 5, or 6. Again, probability refers to the expected outcome over multiple attempts.\nCompare this to a continuous probability distribution, where the outcome can take any value in a given range.\n\nggplot(data = data.frame(x = c(-3, 3)), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), color = \"orange\")+\n  labs(y=\"Probability\", x=\"Outcome\")\n\n\n\n\n\n\n\n\nHere’s an odd outcome: Since the outcome can take on any value in a given range, the chance of it being a specific value is 0. Think about it this way - for any value you mention, I can zoom in more. For example, if you ask the probability of x in the above graph being equal to 0, we could zoom in to 0.0, or 0.00, or 0.000. At some limit of resolution, the area under the curve (which denotes the probability and would be found using integral calculus, which we won’t do here) would be equal to 0!\nThis may seem like an odd aside, but it is actually very important. It explains why when we will discuss probabilities the probability of an outcome being less than, more than, or between two values in upcoming chapters. For example, we can note (again) that for a normal distribution (what we see above and will (still eventually) define more appropriately) that 67% of the data falls within one standard devation for perfectly (very rare!) normally-distributed data.\n\n#function from https://dkmathstats.com/plotting-normal-distributions-in-r-using-ggplot2/\ndnorm_one_sd &lt;- function(x){\n  norm_one_sd &lt;- dnorm(x)\n  # Have NA values outside interval x in [-1, 1]:\n  norm_one_sd[x &lt;= -1 | x &gt;= 1] &lt;- NA\n  return(norm_one_sd)\n}\n\nggplot(data = data.frame(x = c(-3, 3)), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), color = \"orange\")+\n  labs(y=\"Probability\", x=\"Outcome\") + \n  stat_function(fun = dnorm_one_sd, geom = \"area\", fill = \"purple\")\n\n\n\n\n\n\n\n\n\nWhat if more than one thing is of importance?\nSometimes we focus on the probability of more than one outcome for a given event. This requires adding or combining probabilities. The first step in doing this is deciding if the outcomes are mutually exclusive. This means they can not occur in the same unit of focus. For example, we could ask the probability of rolling a 1 or a 6, or of being &gt;2 and &lt;-2. In both cases, a single outcome can’t be both of these things, so the outcomes are mutually exclusive. When this is the case, we simply add the probabilities. This is sometimes called the union of two outcomes.\nContrast this with when we want to know the probability of two things occurring that may occur in the same unit. For example, assume our die not only had dots on it, but these dots were a different color. For example, odd numbers were blue and even numbers were red.\n\ncolors &lt;- c(\"blue\" = \"blue\", \"red\" = \"red\")\ndie_roll$Color &lt;- NA\ndie_roll[as.numeric(as.character(die_roll$Number)) %% 2 == 0, \"Color\"] &lt;- \"blue\"\ndie_roll[as.numeric(as.character(die_roll$Number)) %% 2 != 0, \"Color\"] &lt;- \"red\"\nggplot(die_roll, aes(x=Number, y= Probability, fill=Color)) +\n  geom_col() +\n  scale_fill_manual(values = colors)\n\n\n\n\n\n\n\n\nNow, the probability of rolling any given group of numbers can be found by adding probabilities since the outcomes are mutually exclusive. Same for die color. However, what about the probability of rolling a blue (even) outcome or a 6? Note we can’t simply add these. Why not?\nBecause a single roll can result in a 6 and blue dots! So adding the probability of getting blue dots (.5) and of getting a 6 (.167) will double-count the 6. In other words, there is an an intersection of the possible outcomes. So, the probability of rolling a 6 or blue is equal to\n\\[\nP[roll=blue] + P[roll=6] - P[roll=6 \\ and \\ blue]= \\frac{1}{2} + \\frac{1}{6} -\\frac{1}{6}\n\\]\nThis is sometimes called the general addition principle.\nIf we are measuring multiple outcomes (note this slightly different than the probability of two or more outcomes for a specific event), we need to consider if the events are independent. This means the outcome of one does not influence the outcome of the other. If this is true, the probability of both events occurring can be found by simply multiplying the probability of each (the multiplication rule). For example, consider the probability of flipping a coin twice and seeing a heads followed by a tails. We can write out all the options (T, HH, TH, TT); assuming independence, the probability for each is \\(\\frac{1}{4}\\). We can also say the probability of heads on the first flip is \\(\\frac{1}{2}\\) and the probability of tails on the second flip is \\(\\frac{1}{2}\\); multiplying these yields \\(\\frac{1}{2}\\).\nConsider instead that we roll 2 dice and measure the sum of the rolls. Since one roll does not influence the other, these are independent events. As noted above, we can work out the probability distribution by writing out all possible outcomes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Fi\n\nrst\nDic\ne\n**\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n* Sec\n\nond\nDic\ne\n**\n1\n( 1 ,1)\n( 1 ,2)\n( 1 ,3)\n\n\n*(1\n,\n4\n\n)\n**\n( 1 ,5)\n( 1 ,6)\n\n\n\n2\n( 2 ,1)\n( 2 ,2)\n\n\n*(2\n,\n3\n\n)\n**\n( 2 ,4)\n( 2 ,5)\n( 2 ,6)\n\n\n\n3\n( 3 ,1)\n\n\n*(3\n,\n2\n\n)\n**\n( 3 ,3)\n( 3 ,4)\n( 3 ,5)\n( 3 ,6)\n\n\n\n4\n\n\n*(4\n,\n1\n\n)\n**\n( 4 ,2)\n( 4 ,3)\n( 4 ,4)\n( 4 ,5)\n( 4 ,6)\n\n\n\n5\n( 5 ,1)\n( 5 ,2)\n( 5 ,3)\n( 5 ,4)\n( 5 ,5)\n( 5 ,6)\n\n\n\n6\n( 6 ,1)\n( 6 ,2)\n( 6 ,3)\n( 6 ,4)\n( 6 ,5)\n( 6 ,6)\n\n\n\nNow assume we want to know the probability of the sum of the dice being equal to 5. If we assume independence, the the probability of rolling a sum of 5 (highlighted cells above) is \\(\\frac{4}{36}\\).\nWe could also simulate the outcome\n\nlibrary(reshape2)\nnumber_of_rolls &lt;- 100000\nsum_of_rolls &lt;- data.frame(index = 1:number_of_rolls, Sum = NA)\nfor (i in 1:number_of_rolls){\n  dice_roll_trial &lt;- sample(1:6, size = 2, replace = TRUE)\n  sum_of_rolls$Sum[i] &lt;- sum(dice_roll_trial)\n}\nsum_of_rolls_df &lt;- dcast(sum_of_rolls, Sum ~ \"Probability\", length )\n\nUsing Sum as value column: use value.var to override.\n\nsum_of_rolls_df$Probability &lt;- sum_of_rolls_df$Probability/number_of_rolls\nggplot(sum_of_rolls_df, aes(x=Sum, y=Probability)) +\n  geom_col(fill=\"orange\", color=\"black\") +\n  labs(y=\"Probability\")+\n    scale_x_continuous(breaks = c(2:12))\n\n\n\n\n\n\n\n\nNotice here we find the probability of rolling a sum of 5 is 0.11204 which is very close to \\(\\frac{4}{36}\\).\nTo find the probability using math, we have to note that the dice rolls are independent. For example, even though we only want a 4 on the second dice if we roll a 1 on the first dice, the roll of the first die does not influence the roll of the second. We should also note the desired outcomes are mutually exclusive. So we can find the probability of each happening and then add them. It’s easy to see how probability can get complicated!",
    "crumbs": [
      "Chapters",
      "Probability"
    ]
  },
  {
    "objectID": "content/chapters/Probability.html#conditional-probability",
    "href": "content/chapters/Probability.html#conditional-probability",
    "title": "Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nUnlike our coin example, sometimes a first event occurring does influence the probability of a second event.\n\n\n\nXKCD Conditional Risk: The annual death rate among people who know that statistics is one is six.\n\n\nIn a similar vein, although the risk of shark attack is low, it increases dramatically if you swim in the ocean.\nUnlike our previous examples, we now have 2 events (lets call them A and B), and the probability of both occurring is equal to\n\\[\nP[A \\ and \\ B] = P[A] \\ P[B|A]\n\\]\nwhich can be read as “the probability of A and B occurring is equal to the probability of A multiplied by the probability of B given A occurs”. Note if A and B are independent, this reduces to the multiplication rule.\nWe can extend this by noting\n\\[\nP[A \\ and \\ B] = P[A] \\ P[B|A] \\\\\nP[A \\ and \\ B] = P[B] \\ P[A|B] \\\\\nP[A] \\ P[B|A] = P[B] \\ P[A|B] \\\\\nP[A|B] = \\frac{P[B|A]*P[A]}{P[B]}\n\\]\nThis rule is known as Bayes’ Theorem. We will return to this when we discuss Bayesian analysis, but we can use it here for demonstration.\nFor our lightning example, we could use some (pretend) numbers to understand the risk and Bayes’ Theorem. First, let A be the probability of being outside in a lightning storm. B is then the probability of getting struck by lightning, , and P[B|A] is the probabiity of getting struck by lightning given that you are outside in a lightning storm (hint: it’s much higher than the P[B]).\nHere’s anoher similar (in concept) example. Medical trials are designed to test the effectiveness of drugs or treatments. In these trials, drug efficacy is considered by comparing outcomes in people who receive the drug or treatment compared to those who receive a placebo (such as a sugar pill). Note this only works if participants do not know which group (drug vs placebo) they are in (why?). In a given trial, people who receive the drug recover 60% of the time (or avoid some other adverse outcome). This may seem good, but it’s only relevant when compared to the placebo group. What if people receiving the placebo recovered 80% of the time? Also, if we know the probability of recovering without the drug, we can consider the total probability of recovery. For now, let’s assume that 20% of people who receive the placebo recover.\nWe could use a tree diagram to consider possible options:\n\nlibrary(DiagrammeR)\n\nbayes_probability_tree &lt;- function(prior, true_positive, true_negative, label1 = \"Prior\", \n                                   label2 = \"Complimentary Prior\", label3 = \"True Positive\",\n                                   label4 = \"False Negative\", label5 = \"False Positive\",\n                                   label6 = \"True Negative\") {\n  \n  if (!all(c(prior, true_positive, true_negative) &gt; 0) && !all(c(prior, true_positive, true_negative) &lt; 1)) {\n    stop(\"probabilities must be greater than 0 and less than 1.\",\n         call. = FALSE)\n  }\n  c_prior &lt;- 1 - prior\n  c_tp &lt;- 1 - true_positive\n  c_tn &lt;- 1 - true_negative\n  \n  round4 &lt;- purrr::partial(round, digits = 5)\n  \n  b1 &lt;- round4(prior * true_positive)\n  b2 &lt;- round4(prior * c_tp)\n  b3 &lt;- round4(c_prior * c_tn)\n  b4 &lt;- round4(c_prior * true_negative)\n  \n  bp &lt;-  round4(b1/(b1 + b3))\n  \n  labs &lt;- c(\"X\", prior, c_prior, true_positive, c_tp, true_negative, c_tn, b1, b2, b4, b3)\n  \n  tree &lt;-\n    create_graph() %&gt;%\n    add_n_nodes(\n      n = 11,\n      type = \"path\",\n      label = labs,\n      node_aes = node_aes(\n        shape = \"circle\",\n        height = 1,\n        width = 1,\n        x = c(0, 3, 3, 6, 6, 6, 6, 8, 8, 8, 8),\n        y = c(0, 2, -2, 3, 1, -3, -1, 3, 1, -3, -1))) %&gt;% \n    add_edge(\n      from = 1,\n      to = 2,\n      edge_aes = edge_aes(\n        label = label1\n      )\n    ) %&gt;% \n    add_edge(\n      from = 1, \n      to = 3,\n      edge_aes = edge_aes(\n        label = label2\n      )\n    ) %&gt;% \n    add_edge(\n      from = 2,\n      to = 4,\n      edge_aes = edge_aes(\n        label = label3\n      )\n    ) %&gt;% \n    add_edge(\n      from = 2,\n      to = 5,\n      edge_aes = edge_aes(\n        label = label4\n      )\n    ) %&gt;% \n    add_edge(\n      from = 3,\n      to = 7,\n      edge_aes = edge_aes(\n        label = label5\n      )\n    ) %&gt;% \n    add_edge(\n      from = 3,\n      to = 6,\n      edge_aes = edge_aes(\n        label = label6\n      )\n    ) %&gt;% \n    add_edge(\n      from = 4,\n      to = 8,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 5,\n      to = 9,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 7,\n      to = 11,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 6,\n      to = 10,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) \n  message(glue::glue(\"The probability of having {label1} after testing {label3} is {bp}\"))\n  print(render_graph(tree))\n  invisible(tree)\n}\n\n#first example\nbayes_probability_tree(prior = 0.5, true_positive = 0.8, true_negative = 0.8, label1 = \"medicine\", label2 = \"placebo\",\n                       label3 = \"cured\", label4 = \"not cured\",\n                       label5 = \"cured\", label6 = \"not cured\")\n\nThe probability of having medicine after testing cured is 0.8\n\n\nThis tree let’s us consider multiple things. We can see the probability of being cured is .5, but 80% of those come from the group receiving medicine (again, the P[being cured|given medicine]). WE could also derive this using Bayes Theorem.\n$$ P[being  cured|medicine] = \\ P[being  cured|medicine] = \\ P[being  cured|medicine] = .8\n$$\nOne more example. Instead of medical trials, let’s focus on medical screenings. These are used to identify patients who have a condition, but there are no perfect tests. A test may give a false positive, meaning it says a condition exists when it does not. A test can also give a false negative, meaning it finds a condition does not exist when it really does. Both of these present issues for patients and explain why series of tests are often used before more invasive procedures are employed.\nFor example, assume a procedure is used to assess skin cancer. This cancer occurs at a frequency of .00021 in the general population. The test is fairly accurate; if a patient has cancer, the screening will correctly identify if 95% of the time. However, the probability of a false positive is .01. Given these numbers, how worried should a person be about a positive test?\nAlthough the test seems to be good, note the prevalence of a false positive is far higher than the prevalence of cancer! This means most positives will likely be false. To quantify this, let A be the probability of cancer and B be the probability of a positive screening. So,\n\\[\nP[A|B] = \\frac{.95 \\ * .00021}{.95 \\ * \\ .0021+.01*.9779} \\\\\nP[A|B] = .169\n\\]\nIn other words, only 17% of people with positive screenings actually have cancer.\nTo show this in a probability tree:\n\nbayes_probability_tree(prior = 0.0021, true_positive = 0.95, true_negative = 0.99, label1 = \"cancer\", \n                       label2 = \"not cancer\",\n                       label3 = \"positive\", \n                       label4 = \"negative\",\n                       label5 = \"positive\", \n                       label6 = \"negative\")\n\nThe probability of having cancer after testing positive is 0.16625",
    "crumbs": [
      "Chapters",
      "Probability"
    ]
  },
  {
    "objectID": "content/chapters/Probability.html#related-ideas",
    "href": "content/chapters/Probability.html#related-ideas",
    "title": "Probability",
    "section": "Related Ideas",
    "text": "Related Ideas\nFalse results are integral to the ideas of test specificity and sensitivity Lalkhen and McCluskey (2008). A specific test will yield few false negatives, while a sensitive test will yield few false positives. Put another way (from Lalken & McCluskey (2008): “A test with 100% sensitivity correctly identifies all patients with the disease”, and ” a test with 100% specificity correctly identifies all patients without the disease”. True and false results also impact predictive values.\n\n\n\n\n\n\n\n\n\nCondition\n\n\n\n\n\n\nTest Outcome\nPresent\nAbsent\n\n\nPositive\nTrue Positive\nFalse positive\n\n\nNegative\nFalse negative\nTrue Negative\n\n\n\nSensitivity=\nTrue Positive/ Condition present\nSpecificity =\nTrue negative/\nCondition negative\n\n\n\nThese ideas can also be related to power. We will return to this visualization in future chapters.\n\n\n\nA 3D visualisaion of PPV, NPV, Sensitivity and Specificity. Luigi Albert Maria, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons",
    "crumbs": [
      "Chapters",
      "Probability"
    ]
  },
  {
    "objectID": "content/chapters/Probability.html#next-steps",
    "href": "content/chapters/Probability.html#next-steps",
    "title": "Probability",
    "section": "Next steps",
    "text": "Next steps\nNow that we’ve discussed probability, we can move into the wild world of p-values and discuss how they relate to estimation!",
    "crumbs": [
      "Chapters",
      "Probability"
    ]
  },
  {
    "objectID": "content/chapters/summarizing_data.html",
    "href": "content/chapters/summarizing_data.html",
    "title": "Summarizing data",
    "section": "",
    "text": "Figure 1: XKCD: Data Trap. It's important to make sure your analysis destroys as much information as it produces. https://xkcd.com/2582/, CC BY-NC 2.5 https://creativecommons.org/licenses/by-nc/2.5/.\nOnce we have some data, the next step is often to summarize it. In fact, we’ve already done that in some ways. Some statistics like the mean may be considered a summary of the data. This may be useful because we prefer large datasets (remember good sampling!), but making sense of a list of numbers can be really hard! Summaries help us describe, and eventually compare, datasets, which we are using to infer something about a population.\nThink about it this way. We want to know if several species of iris (Iris versicolor, setosa and virginica) have similarly-shaped flowers. Since we can’t measure every flower on every plant from these species, we sample several sites and come up with the following data (using R’s built-in iris dataset, a dataset we will often use).\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\nOverwhelming, isn’t it? And this isn’t a huge dataset! There are only 150 rows, yet some datasets have tens of thousands! It’s really hard (or impossible) to just look at these numbers and infer anything about the population. Summary statistics help us get a better mental image of the distribution of the sample data.",
    "crumbs": [
      "Chapters",
      "Summarizing data"
    ]
  },
  {
    "objectID": "content/chapters/summarizing_data.html#types-of-data",
    "href": "content/chapters/summarizing_data.html#types-of-data",
    "title": "Summarizing data",
    "section": "Types of data",
    "text": "Types of data\nWe can summarize data using visual (i.e., graphs) or numerical (e.g., summary statistics like the mean) approaches. The specific way we summarize the data also depends on the type of data. Note, the trait we are collecting data on may also be called a variable (since it varies across the population and thus sample).\nLet’s just look at the first few rows of the iris dataset.\n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\n\n\nWhat’s the data showing? Click on the grey triangle\n\nWe’ll use many datasets in class to illustrate points. I don’t expect you to become an expert on any of them, but I will provide some background along the way. For example, this isn’t a botany class, but in case you are interested, here’s some flower morphology.\n\n\n\n\n\n\nFigure 3: Flower morphology. Pearson Scott Foresman, Public domain, via Wikimedia Commons\n\n\n\n\nThis dataset includes a few different types of variables.\n\nCategorical variables\nVariables can be categorical (e.g., eye color, or species in the iris dataset). If categorical variables have no clear hierarchical relationship (again, like eye color and species- one isn’t better than the other), then they are nominal variables. If the categories imply a rank or order (e.g., freshmen, sophomore, junior, senior; egg, larvae, pupae, adult) then they are ordinal variables).\n\n\nNumeric variables\nIf data values are based on numbers instead of categories, they are numeric variables. These can be divided into those are count-based (no fractions) - we call these discrete data- and those that can take on any values in a given range - like height or sepal length in the iris dataset- we call these continuous variables.",
    "crumbs": [
      "Chapters",
      "Summarizing data"
    ]
  },
  {
    "objectID": "content/chapters/summarizing_data.html#graphical-summaries",
    "href": "content/chapters/summarizing_data.html#graphical-summaries",
    "title": "Summarizing data",
    "section": "Graphical summaries",
    "text": "Graphical summaries\nVisual interpretations or displays of your data are an excellent way to make patterns, trends, and distributions easier to see (like the comic above shows). In this section we’ll go over a number of graphs. Consider this is a resource. I don’t expect you to know how to make each of these on your own immediately. We will actually introduce the software we are using to make these in later sections. Instead, you can return here later when you are actually making a graph for ideas (and code!). For your first read, focus on the images (not the code!)\nWhile the type of graph you should use will depend on the data (and you may have several options!) all graphs should have\n\nA descriptive title\n\nMove beyond Y vs. X. State any patterns you see in the title to help the viewer know what they are looking for! Honest interpretation of data is always paramount, but in producing a graph you will already be making visualization decisions.\n\nLabeled axes (measure and unit)\n\nWhat did you measure, and using what (e.g. Sepal length (cm)).\n\nData points\n\nYou have to actually graph something!\n\n\nOther parts should only be included when needed, like\n\nA legend\n\nOnly needed for graphs with multiple datasets where color, shape, or some other visual cue indicates something to the viewer that would be unclear without added information.\n\nTrendlines\n\nCan be used to show the general/overall relationship between variables. If you use these, make sure to use the right ones! Don’t fit a straight line to a curved relationship!\n\n\n\nSingle variable\n\nNumerical data\n\nHistograms\nOccasionally you only want to show the distribution for a single numerical variable (or how the data themselves are distributed). For example, we could want to display sepal lengths for all the Iris virginica we sampled. We could do this using a histogram.\n\nlabel_size &lt;- 2\ntitle_size &lt;-2.5\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"], \n     main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))), \n     xlab = \"Sepal Length (cm)\", \n     cex.lab=label_size, cex.axis=label_size, cex.main=title_size, \n     cex.sub=label_size, col = \"blue\")\n\n\n\n\n\n\n\nFigure 4: Example of approximately normal data\n\n\n\n\n\nThe above plot is produced using functions available in all R installs. Many plots now use ggplot2, a package you have to install (don’t worry, we’ll get there!). However, since you may come back to this later, I’ll also show how this graph using ggplot2, and we’ll use that approach for most of the other graphs in this course.\n\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 5: Example of approximately normal data\n\n\n\n\n\nHistograms put the data in bins (usually automatically set by software, but you can update!) and then show the number of samples that fall into each bin. This allows a quick estimate (look at the y, or vertical, axis) of how many samples were taken. The above images also allows us to begin to consider the bounds/range of the data (~4.5-8 cm), which gives information on the minimum and maximum values. We can also see lengths around 6-7 cm are most common.\n\n\nWhy do these graphs look slightly different? (Click the grey triangle to see the answer)\n\nMost programs, including R, have autobreak functions that separate the data into bins for histograms. Notice ggplot2 uses a different algorithm to bin the data. That also impacts what you see! Users, however, can override these, so it’s worth noting that differences in bin size can influence what distributions look like.\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],       main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),       xlab = \"Sepal Length (cm)\",       cex.lab=label_size, cex.axis=label_size, cex.main=title_size,       cex.sub=label_size, col = \"blue\") \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=3, main = \"Sepal length histogram, 3 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")  \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=10, main = \"Sepal length histogram, 10 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Auto breaks with ggplot2\n\n\n\n\n\n\n\n\n\n\n\n(b) 3 breaks\n\n\n\n\n\n\n\n\n\n\n\n(c) 10 breaks\n\n\n\n\n\n\n\nFigure 6: The number of bins changes how histograms look .\n\n\n\nor, in ggplot2,\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\", bins = 4) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \", 3 breaks\")),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\", bins = 11) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \", 10 breaks\")),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Auto breaks with ggplot2\n\n\n\n\n\n\n\n\n\n\n\n(b) 3 breaks\n\n\n\n\n\n\n\n\n\n\n\n(c) 10 breaks\n\n\n\n\n\n\n\nFigure 7: The number of bins changes how histograms look (now in ggplot2).\n\n\n\nA similar issue exists for qualitative data in regards to the categories that are combined/used.\n\nThis distribution of this data is (very) approximately normal. We will define normality more later (equations!), but for now note the distribution is roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate…\nComparing the above graph to other distributions may be an easier approach to understanding normality. Consider these graphs.\n\nset.seed(19)\ncardinals &lt;- round(rbeta(10000,10,2)*50+runif(10000,5,10),3)\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 8: Example of left-skewed data (ggplot2). Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\nset.seed(19)\nparrots&lt;- round(c(rnorm(1000,400,10)),3)\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram( fill=\"green\", color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 9: Example of normal data. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\nset.seed(19)\nblue_jays &lt;- round(rbeta(10000,2,8)*100+runif(10000,60,80),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 10: Example of right-skewed data. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\nThe cardinal (Figure 8) data has a longer left tail and is not symmetric. We call this left- or negatively-skewed data (since it’s going lower on the x-axis). Compare that to the blue jay (Figure 10) data; it has a longer right-tail and is positively- or right-skewed. Again, note this is all relative to symmetric data like you see with the parrots (Figure 9), which is normally-distributed data.\nAll symmetric data is not normal, however. Look at the data on robin and woodpecker weights.\n\nset.seed(19)\nrochester &lt;- round(c(runif(1000,75,85)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 11: Example of uniform data. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\nset.seed(19)\nwoodpeckers &lt;- round(c(rnorm(100,60,4),rnorm(100,80,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 12: Example of bimodal data. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\nBoth these are roughly symmetric but clearly different from normally-distributed data (we will return to the woodpecker data!). The robin data (@fig-robins) is what we call uniformly distributed. There are really no tails, as it appears you are just as likely to see any number within the bounds as any other. Kurtosis is the statistical term for what proportion of the data points are in the tails. High kurtosis distributions have heavy tails with multiple outliers. The uniform distribution is an example of a low kurtosis distribution (it has no tails!).\nThis figure may also help.\n\n\n\n\n\n\nFigure 13: English: Plot of several symmetric unimodal probability densities with unit variance. From highest to lowest peak: red, kurtosis 3, Laplace (D)ouble exponential distribution; orange, kurtosis 2, hyperbolic (S)ecant distribution; green, kurtosis 1.2, (L)ogistic distribution; black, kurtosis 0, (N)ormal distribution; cyan, kurtosis −0.593762…, raised (C)osine distribution; blue, kurtosis −1, (W)igner semicircle distribution; magenta, kurtosis −1.2, (U)niform distribution. Public domain.\n\n\n\nIf we consider the normal distribution (shown in black) to have 0 kurtosis, the uniform (pink) has less, and the double-exponential (red) has more Figure 13.\nFinally, the woodpecker data (Figure 12) is what we call bimodal. It is symmetric in this case (not always true!), but it has a two clear peaks instead of a single central or skewed high point in the distribution.\nThese distributions helps us think about what we would expect to find in future samples (remember, we are assuming we have good samples!). To think about future sampling, we can change our y-axis from what we saw (frequency) to a probability density.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\nFigure 14: Probability density distribution\n\n\n\n\n\nThese probability density distributions can be calculated directly from data (as seen above), but we can also generate these shapes using equations and values from the data. The benefits of using a distribution derived from an equation is that it is consistent and easy to describe (standardized). This is why many common tests we will learn rely upon the data (or some derivative of it) following a known distribution. For example, many parametric tests will rely upon the data (or means of the data, or errors…we’ll get there) following a normal distribution. We can see our parrot data (which came from a normal distribution!) is very close to a “perfect” normal distribution as defined by an equation.\n\nparrots_df &lt;- data.frame(parrots)\ncolors &lt;- c(\"PDF from data\" = \"black\", \"normal curve\" = \"red\")\nggplot(parrots_df, \n       aes(x=parrots)) +\n  geom_histogram(aes(y = ..density..),fill=\"green\", color=\"black\") +\n  geom_density(aes(color=\"PDF from data\"))+\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Density\",\n       color=\"Source\")+\nstat_function(fun = dnorm, args = list(mean = mean(parrots_df$parrots), sd = sd(parrots_df$parrots)), aes(color=\"normal curve\"))+\n      scale_color_manual(values = colors)\n\n\n\n\n\n\n\nFigure 15: Comparing the distribution of the data to a perfect normal distribution. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\n\nBonus question: Why isn’t it perfect? (Click the grey triangle to see the answer!)\n\nThis is an easy example of sampling error!\n\n\n\nBox plots (aka, box and whisker plots)\nAnother way to visualize the distribution of numerical data for a single group is using box-and-whisker plots.\n\nggplot(iris[iris$Species == \"virginica\",],\n            aes(x=Species,y=Sepal.Length)) + geom_boxplot(size = 3) +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"\",\n       y= \"Sepal Length (cm)\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\n\n\n\nFigure 16: Example of approximately normal data\n\n\n\n\n\nThese plots show the values of the quartiles of the data. In this way they start combining numerical summaries (more to come!) and visual summaries. More to come, but for now imagine you had a 99 data points. If you arrange the data points from smallest to largest, the median of the data would be the middle (50th data point). If you took the bottom half of the data (first data to median), the first quartile would be the middle point (or, in this case, the average of the 25th and 26th data points). Similarly, the third quartile is the middle of the top half of the data set (or, if not one number, average of 75th and 76th data point). Note the median is also the 2nd quartile of the data!\nThe box in the box-and-whisker plot shows the first, second, and third quartiles, also known as the inter-quartile range (IQR). The whiskers extend to the minimum and maximum values of the dataset or, up to values within a set range. In ggplot, whiskers by default can only be as long as 150% of the IQR. This means extreme outliers are shown as individual dots. Typically, the most extreme values (minimum and maximum) plus the first, second, and third quartiles are together called the five number summary.\n\n“Easy” examples of five number summaries\n\nAssume we have data that goes from 1 to 99. The five number summary should be\n\nx &lt;- seq(1:1:99) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    25.5    50.0    50.0    74.5    99.0 \n\n\nNote the 1st and 3rd quartiles are averaged!\nSimilarly, consider the numbers 1-5\n\nx &lt;- seq(1:1:5) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       2       3       3       4       5 \n\n\n\n\n\n\nCategorical data\nFor categorical data, a bar chart fills a very similar role. Note, however, we don’t bin the data., and there is inherent order for some examples (nominal data). For example, we could examine the colors of our I. virginica. To do this, we’ll need to add some data to our iris data (notice this produces no output…)…\n\nset.seed(19)\ncolors &lt;- c(\"blue\", \"orange\", \"purple\")\niris$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\n\nand then summarize it…\n\nlibrary(Rmisc)\nI_viriginica_colors &lt;- summarySE(iris[iris$Species == \"virginica\",], measurevar = \"Sepal.Length\",\n                                 groupvars = \"Color\", na.rm = T)\n\nbefore we graph it.\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")))\n\n\n\n\n\n\n\nFigure 17: Distribution of flower colors\n\n\n\n\n\nOr better\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        col = colors)\n\n\n\n\n\n\n\nFigure 18: Distribution of flower colors (plot)\n\n\n\n\n\nUsing ggplot2\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\n\n\n\nFigure 19: Distribution of flower colors (ggplot2)\n\n\n\n\n\nNote the legend may be superflous here (but consider accessiblity - should we add another distinguishing feature?):\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure 20: Let colors match traits if possible, but note everyone can’t see colors and sometimes they are not printed.\n\n\n\n\n\n\n\n**Barchart issues**\n\nNote all of the bar graphs above share a similar problem. People tend to like bars, but they are actually just using a lot of ink! We could get the same information about sepal lengths focusing on just the “top” of the bar:\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_freqpoly(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nFigure 21: Note you only really know the tops of the bar!\n\n\n\n\n\nWe can also just display the data!\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Species, y=Sepal.Length)) +\n  geom_point(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\n\n\n\nFigure 22: Displaying the data may be the easiest option for small-ish datasets.\n\n\n\n\n\n\n\n\n\nMultiple variables\nOften we collect multiple pieces of information instead of just one. This can occur for multiple reasons. We may want to consider differences in some variable/trait among groups. This means we have either numerical or categorical data from various groups, but note that groups themselves are now a piece of data! We can think of these analyses as impact of group (a category) on traits (numerical or categorical). We will eventually call these a t-test or ANOVA (when the trait we measure is categorical) ota \\(\\chi^2\\) test (when the trait is categorical). Either way, this is a case where we are collecting a single piece of data from multiple groups. Alternatively, we may collect data on multiple traits from a single group to see how they impact each other. We will eventually analyze this type of data using regression or correlation. Regardless of type, we can also graph this data.\n\nNumerical variables from multiple groups\nWhen we gather numerical data from various groups and wish to compare, we can extend our use bar charts and box-whisker plots by using shapes, colors, or other features to symbolize the groups. For example, we can illustrate the mean (coming up in numerical summaries) or other summary statistics using bar plots..\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_bar(stat = \"summary\", fun = \"mean\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n{#fig-bar_charts_all species width=672}\n\n\n\n\nor the distribution using stacked histograms…\n\nggplot(iris, aes(x=Sepal.Length)) +     geom_histogram(aes(fill=Species))+    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\",        x= \"Species\")\n\n\n\n{#fig-stacked_histograms_all species width=672}\n\n\n\n\nor box-and-whisker plots.\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_boxplot(aes(fill=Species))+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\", x= \"Species\")\n\n\n\n{#fig-box_whisker_all species width=672}\n\n\n\n\nWe can also still just display the data for each group…\n\nggplot(iris, aes(y=Sepal.Length, x=Species, color=Species)) +\n  geom_jitter() +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n{#fig-point_all species width=672}\n\n\n\n\nWe also need to ensure the different groups are visible when distributions overlap. Sometimes stacked histograms (and similar graphs) make it hard to actually visualize each individual group. One option is to instead facet these graphs. Faceting means we produce different graphs for each group, treatment, etc, but they (typically) share axes. This makes it easier to compare the groups.\n\n ggplot(iris, aes(x=Sepal.Length)) + \n   geom_histogram(aes(fill=Species))+ \n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")+\n   facet_wrap(~Species, ncol = 1)\n\n\n\n{#fig-faceted_histograms_all species width=672}\n\n\n\n\nAnother option is to show the cumulative frequency distribution for each group.\n\nggplot(iris, aes(Sepal.Length, colour = Species)) + stat_ecdf()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Cumulative frequency\")\n\n\n\n\n\n\n\nFigure 23: Cumulative frequency distributions can be useful in noting exactly where distributions diverge\n\n\n\n\n\n\n\nCategorical data from multiple groups\nFor our example, let’s return to our focus on the color of flowers for various species of iris. One option for this is to consider bar plots. These can be stacked…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure 24: Bar plots are stacked by default and count the number of rows found in each category\n\n\n\n\n\nor not…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = position_dodge(width=0.5))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure 25: Bar plots can also be grouped by adding the position_dodge argument\n\n\n\n\n\nOther options include divergent plots, but those are best for 2 groups of data. They also require the data to be summarized and somewhat transformed. For example, we could have blue or not blue flowers.\n\nlibrary(plyr)\niris$blue &lt;- revalue(iris$Color, c(\"blue\"=\"blue\", \"purple\"=\"not blue\", \"orange\"=\"not blue\"))\n\nThen we have to summarize the data.\n\niris_summary &lt;- data.frame(table(iris$blue, iris$Species))\nnames(iris_summary) &lt;- c(\"Blue\", \"Species\", \"Frequency\")\n\nand make not blue negative\n\niris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] &lt;- iris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] * -1\n\nthen plot it.\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\n\n\n\nFigure 26: Divergent plots show how 2 categories differ among groups\n\n\n\n\n\nwhich we could flip by reversing all x/y arguments..\n\nggplot(iris_summary,aes(y=Species, x=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       y= \"Species\",\n       x= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\n\n\n\nFigure 27: Reorienting graphs may help viewers better visualize differnces\n\n\n\n\n\nor using an additional argument (remember, a lot of this is for later reference!)\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\")) +\n  coord_flip()\n\n\n\n\n\n\n\nFigure 28: Note we get the same results by simply adding the argument coord_flip\n\n\n\n\n\n\n\ngeom_bar vs geom_col\n\ngeom_bar and geom_col are very similar commands, but geom_bar assumes its needs to do something to the data (like count it) by default, whereas geom_col assumes the data are summarized/ready to plot as is. The extra argument stat=identity above can usually make geom_bar behave like geom_col.\n\nIn the above cases, each group was measured the same number of times. However, if this isn’t true, visualizations may confound sampling size with summaries. In those cases, focusing on proportion (explained below!) of outcomes may be more useful (and will give you the exact same visualization if all groups were measured the same number of times!). This is sometimes called a mosaic plot; another way to make them (not shown here) is using the package ggmosaic.\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = \"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Proportion\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\n\n\n\nFigure 29: For proportion-based visualizations, stacked bar plots may be easier to read than grouped. We just add the position=fill argument to make these.\n\n\n\n\n\nNote we could also facet this data if we had other variables. For example, assume sampled another set of populations to the west..\n\niris_new &lt;- iris\ncolors &lt;- c(\"pink\", \"orange\", \"yellow\")\niris_new$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\niris_both &lt;- rbind(iris,iris_new)\niris_both$Population &lt;- factor(c(rep(\"East\",nrow(iris)), rep(\"West\", nrow(iris_new))))\n\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\n\n\n\nFigure 30: Faceting can make patterns easier to compare.\n\n\n\n\n\nNote we can combined these ideas!\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\n\n\n\nFigure 31: We can add facets and proportions.\n\n\n\n\n\nFinally, we can end this section noting a pie chart is just a transformed bar chart.\n\niris_both$Share &lt;- \"\"\nggplot(iris_both,aes(x=Share)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Distribution of flower colors differ among populations of \",italic(\"I. species \"))),\n       y=\"\", \n       x=\"\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_grid(Population~Species) +\n coord_polar(theta=\"y\") \n\n\n\n\n\n\n\nFigure 32: We can add facets and proportions.\n\n\n\n\n\n\n\nRelationships among data from a single group\nInstead of collecting data on a single trait from multiple groups, we may collect data on multiple traits from a single group. For example, we could want to see if petal length is related to sepal width in I.virginica. This relationship could be visually summarized using a scatter plot.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length, y=Petal.Length)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\n\n\n\nFigure 33: Scatter plots show relationships among numerical variables.\n\n\n\n\n\nObviously we can (and will) combine many of the above approaches. For example, we may want to see if relationships among two numerical variables differ among groups (an ANCOVA!).\n\nggplot(iris,\n              aes(x=Sepal.Length, y=Petal.Length, color=Species)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\n\n\n\nFigure 34: We can add facets and proportions\n\n\n\n\n\nWe’ll get to these later in class, but I just want to note their existence here. Finally, if you are reading this for the first time, don’t worry about the tests (just like the code!). We will explain how all these tests are related when we get there!\nFinally, note data of this type may include time or dates. We’ll use a different dataset to illustrate this.\n\nairquality$Date &lt;-as.Date(paste(airquality$Month, airquality$Day,\"1973\", sep=\"/\"), format =\"%m/%d/%Y\")\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\n\n\n\nFigure 35: Scatter plots can also include temporal data\n\n\n\n\n\nWe can also add lines…\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  geom_line()+\n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\n\n\n\nFigure 36: Scatter plots can also include lines\n\n\n\n\n\nWe can even include multiple data sets!\n\nggplot(airquality, aes(x =Date,y =Temp)) + geom_point(aes(col =\"Temp\")) + geom_line(col=\"orange\") + geom_point(aes(y=Wind+50, col = \"Wind speed\")) + scale_y_continuous(sec.axis = sec_axis(~.-50, name = \"Wind (mph)\")) + geom_line(aes(y=Wind+50))+\n     labs(title=\"Environmental measurements over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\n\n\n\nFigure 37: Scatter plots can also include multiple lines\n\n\n\n\n\n\n\nThere’s more to do and think about!\nThis just scratches the surface of potential ways to visualize data. For example, heatmaps can be used to show location specific data and we can build interactive or animated visualizations. However, the basic principles we’ve examined here should get you started.\nThe different approaches covered here also indicate there a lots way to display data! Whichever approach you use, you should ensure that you represent the data honestly and clearly. Sometimes that means you just display data (points)! You should also always consider possible ways the data/visualization could be misinterpreted and avoid them. Common mistakes include the decision about which baseline should be included. For example, should charts always include 0 on the y-axis? Not including 0 can may small differences appear large. However, including it can make important changes seem insignificant! Consider\n\nsmall_difference &lt;- data.frame(Treatment = c(\"a\",\"b\"), mean=c(37,40))\nlibrary(ggpubr)\nbp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, fill=Treatment))+\n  geom_bar(stat=\"identity\")\nsp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, color=Treatment))+\n  geom_point()\ncompare &lt;- ggarrange(bp, sp, labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1,common.legend = TRUE, legend=\"bottom\")\nannotate_figure(compare,\n                top = text_grob(\"Including a zero point can make a big difference!\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\nFigure 38: The decision of where to start the y-axis can have major impacts on interpretation. A is bar charts for the data, with 0 included on the y-axis. B is the same dataset using scatter plots and y-axis set (by default) to not include 0\n\n\n\n\n\nIf this is changes in temperature, option B may be more useful (this could be a normal temperature (37 C) compared to a fever of 104 (40 C). However, if its a difference in a metabolic rate, it may have minor impacts (and thus we choose option A)!\nSimilarly, imagine we collected this data\n\ngood_fit_x &lt;- runif(100, 1, 50) \ngood_fit_y &lt;- rnorm(100,25,2) \ngood_data &lt;- data.frame(source = \"good\", x=good_fit_x, y=good_fit_y) \nbad_fit_x &lt;- runif(10, 20, 30) \nbad_fit_y &lt;- rnorm(10,95,1) \nbad_data &lt;- data.frame(source = \"outlier\", x=bad_fit_x, y=bad_fit_y) \nall_data &lt;- rbind (good_data, bad_data)\n\npoints &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  labs(title=\"Raw data\")\n\npoints_plus_curve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  geom_smooth(se = F) + \n    labs(title=\"Curve fit to data but points shown\")\n\ncurve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_smooth(se = F) +\n    labs(title=\"Only curve\")\ncompare &lt;- ggarrange(points, points_plus_curve, curve, labels = c(\"A\", \"B\", \"C\"),\n          ncol = 2, nrow = 2, common.legend = TRUE, legend=\"bottom\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nannotate_figure(compare,\n                top = text_grob(\"Same data, three visualizations\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\nFigure 39: Same data graphed 3 ways. A is raw data, B is raw data with smooth (averaged) curve added, and C is curve only (which also rescales by default.\n\n\n\n\n\nWhereas the raw data (panel A) may suggest some outliers that are concerning, by panel C we have “smoothed” the data and made an interesting pattern. In general, thought must be applied to individual situations regarding visualization style and nuance. Adding information on spread in the data will also help (coming up!).",
    "crumbs": [
      "Chapters",
      "Summarizing data"
    ]
  },
  {
    "objectID": "content/chapters/summarizing_data.html#numerical-summaries",
    "href": "content/chapters/summarizing_data.html#numerical-summaries",
    "title": "Summarizing data",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\nWhile visual summaries give us a clearer picture of the data, numerical summaries can help distill a large dataset into several components that can then be analyzed or compared. A key point is we are rarely trying to say if 2 groups are exactly the same or if a trait value is exactly equal to something. Given sampling error, we know its unlikely we would get exactly the same values, and, more importantly, its really rare for 2 groups to be exactly the same. Instead, we are often comparing characteristics of the population data among group or to set values.\n\nCentral tendency\nOne common characteristic of a population is central tendency. Central tendency considers what are common values in a dataset by focusing on the center of the distribution. Mean, or the average or \\(\\mu\\) , is one measure of central tendency. Due to sampling error, we don’t know \\(\\mu\\), but we can estimate it. In general, we use Greek letters to denote the population values and standard(Latin) letters typically denote our estimate (sometimes with added symbols). For example, if we have n data points, our estimate of the mean \\(\\mu\\) is known as \\(\\overline{Y}\\) (read as “y-bar”) is\n\\[\n\\overline{Y} = \\frac{\\sum_{i=1}^{n} n_{i}}{n} \\sim \\mu\n\\]\nwhere \\(\\sim\\) means “approximately”. Other measures of central tendency include the mode (most common data point) or median (middle data point if all data were placed in ascending order (remember box plots!)).\nWhy do we need more than one measure of central tendency? Consider our cardinal data:\n\n# function to calculate mode\nfun.mode&lt;-function(x){as.numeric(names(sort(-table(x)))[1])}\n\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(cardinals), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(cardinals), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(cardinals), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n\n\n\n\n\n\nFigure 40: Skew impacts value of and relationships among various measures of central tendency\n\n\n\n\n\nNote the data is left-skewed. so the mean is pulled towards these outliers. The median may offer a better summary of the actual center. We see similar outcomes with right-skewed data.\n\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(blue_jays), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(blue_jays), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(blue_jays), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n\n\n\n\n\n\nFigure 41: Skew impacts value of and relationships among various measures of central tendency. . Note this is not actual data, only simulated for use in example.\n\n\n\n\n\nBut with symmetric data, we see the measures of central tendency align more\n\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(parrots), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(parrots), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(parrots), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n\n\n\n\n\n\nFigure 42: For symmetric data, measures of central tendency are more aligned. . Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\n\nWhy is the mode not always on the highest bar?\n\nNote the mode is heavily/totally impacted by data precision and thus can lead to unusual matches with histograms. In our above example, cardinals were measured to 10-3 grams. However, the data was binned to levels of 10-2 grams. Due to this mismatch, the most common measurement of the raw data was 52.401, which occurred 6 times. However, more data points still fell in another bin!\n\nA special case where central tendency may not be the best way to describe a distribution is known as bimodal data. In this case, the distribution shows two, not one, clear peak. Remember the woodpecker Figure 12 data?\n\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram(aes(y=..density..), color=\"black\") +\n  geom_density()+\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Proportion\")+\n    theme_bw()+\n  geom_vline(aes(xintercept=mean(woodpeckers), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(woodpeckers), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(woodpeckers), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n\n\n\n\n\n\nFigure 43: Example of bimodal data with various measures. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\nNote the mode is (again) off, but the mean and median also represent uncommon individuals!\n\n\nSpread\nAlong with the central tendency, another set of numerical summaries focus on the spread of the data. In some ways these focus on how much of the data is in the tail (or how heavy the tail is). To illustrate this, consider the Figure 5 data.\n\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n\n\n\n\n\n\nFigure 44: Remember this example of approximately normal data?\n\n\n\n\n\nWe can instead plot the raw data\n\niris$sample &lt;- 1:nrow(iris)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point() +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")\n\n\n\n\n\n\n\nFigure 45: Note x-axis is just sample order!\n\n\n\n\n\nNow let’s add the mean\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point(color='blue') +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n  annotate(\"text\", label = \"mean\", x = 135, y = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") \n\n\n\n\n\n\n\nFigure 46: Mean shown in blue!\n\n\n\n\n\nNote the points differ in how far they are from the mean! For example, we could find another species with a very similar mean but different spread of the data.\n\niris_new &lt;- data.frame(Sepal.Length = runif(50,min=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])-.25, max=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.25), Species = \"uniforma\", sample=101:150)\niris_hypothetical &lt;- merge(iris, iris_new, all = T)\nggplot(iris_hypothetical[iris_hypothetical$Species %in% c(\"virginica\", \"uniforma\"),],\n              aes(y=Sepal.Length, x=sample, color=Species))+\n  geom_point() +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" and \", italic(\"uniforma \"), \"arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n    geom_hline(aes(yintercept=mean(iris_hypothetical[iris_hypothetical$Species == \"uniforma\", \"Sepal.Length\"])), color = \"red\")+\n  annotate(\"text\", label = \"I. virginica mean\", x = 135, y = mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") +\n  annotate(\"text\", label = \"I. uniforma mean\", x = 135, y = mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])-.13, color = \"blue\")+\n  scale_color_manual(values=c(\"blue\", \"red\"))\n\n\n\n\n\n\n\nFigure 47: Similar mean, very different distribution!\n\n\n\n\n\nThis spread could be quantified in multiple ways. Here we focus on the variance, which is defined as\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (Y_{i}-\\overline{Y})^2}{n-1} \\sim \\sigma^2\n\\]\nAgain, the population parameter is \\(\\sigma^2\\), and the estimate is \\(s^2\\). This is effectively the average distance of each point from the mean squared!\n\nsegment_data &lt;- data.frame( x = 101:150, xend = 101:150, y=iris[iris$Species == \"virginica\", \"Sepal.Length\"], yend = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"]) )\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point(color='blue') +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n  annotate(\"text\", label = \"mean\", x = 135, y = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") +\n  annotate(\"text\", label = \"square each blue line \\n and find average!\", x = 145, y = 7.5 , color = \"blue\") + geom_segment(data = segment_data, aes(x = x, y = y, xend = xend, yend = yend), color= \"blue\", size = 1.1, linetype=\"dotted\") \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\nFigure 48: Mean shown in blue!\n\n\n\n\n\nWhy \\(n-1\\) on the bottom, you might ask? Related reasons focus on degrees of freedom (we’ll get there) and bias. Our estimate of \\(s^2\\) is based on our sample mean. Since the sample mean can, at best, be the population mean, our variance estimate may be biased (too small). Dividing by \\(n-1\\) can be shown to correcthat. Alternatively, we are estimating one parameter from our data (again, \\(\\mu\\)), so we need to remove one degree of freedom from our calculation. However, some programs still \\(n\\) on the bottom. Note this will only really matter when \\(n\\) is small. In short, as another professor once told me, if the difference is based on whether you use \\(n\\) or \\(n-1\\) in your variance calculation, you likely have other problems.\nNote variance has odd (squared) units. If we take the square root of the variance, we get a value called the standard deviation.\n\\[\nstandard\\;deviation = sd= \\sqrt{variance}\n\\]\nThis metric is now in the same units as the mean (\\(\\mu\\)), so we can plot them easily on the same graph! This will become important later, especially when we discuss normal distributions.\n\n\nCoefficient of variation\nThe coefficient of variation, \\(CV\\), is found using the formula\n\\[\nCV = \\frac{s}{Y} * 100\\%\n\\]\nThis scales the variance (spread) of the data by the mean. The \\(CV\\) is unitless and can be used to compare various distributions.\n\n\nOdds and Ends: Quartiles, percentiles, other splits, maximum and minimum\nAs noted above in the discussion of five-number summaries, we can also find the assorted quartiles, minimum, and maximum of a dataset. This can be especially helpful when the mean isn’t a useful measure of central tendency (since variance and \\(CV\\) rely on the estimate of the mean!). For examples, see Figure 8. The original five number summary is\n\nsummary(cardinals)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  23.33   46.12   50.11   49.22   53.19   59.50 \n\n\nNote that if we shifted the bottom 10% of the values even further left (increasing the skew), the median stays the same, as does the first quartile (and thus the IQR), even though the mean and minimum move.\n\ncardinals_new &lt;- cardinals\ncardinals_new[cardinals_new &lt; quantile(cardinals_new, probs= .1)] &lt;- pmax(cardinals_new[cardinals_new &lt; quantile(cardinals_new, probs= .1)]-30,0)\n\nsummary(cardinals_new)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00   46.12   50.11   46.22   53.19   59.50 \n\noriginal_cardinal &lt;- ggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(cardinals), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(cardinals), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(cardinals), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\nnew_cardinal &lt;- ggplot(data.frame(cardinals_new), \n       aes(x=cardinals_new)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(cardinals_new), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(cardinals_new), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(cardinals_new), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\ncompare &lt;- ggarrange(original_cardinal, new_cardinal, labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1,common.legend = TRUE, legend=\"bottom\")\nannotate_figure(compare,\n                top = text_grob(\"Impacts of shifting data on 5-number summary\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\n\n\n\nFigure 49: Shifted cardinal data. Note this is not actual data, only simulated for use in example.\n\n\n\n\n\n\n\nProportions for categorical data\nFinally, if we have categorical instead of numerical data, we can find the proportion of data in each category. We mentioned this approach when producing mosaic plots. To find a proportion, you count the number of samples that fall in a given group and divided that by the total number sampled. Alternatively, you can assign a score of 0 for values that are not in the focal group and a score of 1 to samples that are - the average of these scores will give you the proportion.\nFor example, earlier we plotted how flower color differed among species and location.\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\n\n\n\n\nLet’s see where this came from. We can count the number of each color in each species in each population:\n\n\n\n  \n\n\n\nThen divide them by the number sampled for each species in each population:\n\nflower_prop_df &lt;- data.frame(prop.table(flower_table, margin = c(\"Population\", \"Species\")))\nnames(flower_prop_df)[4] &lt;- \"Proportion\"\nflower_prop_df$Population_species &lt;- paste(flower_prop_df$Population,flower_prop_df$Species)\nflower_prop_df &lt;- flower_prop_df[order(flower_prop_df$Population_species),]\nrow.names(flower_prop_df) &lt;- NULL\npaged_table(flower_prop_df[,1:4])",
    "crumbs": [
      "Chapters",
      "Summarizing data"
    ]
  },
  {
    "objectID": "content/chapters/summarizing_data.html#next-steps",
    "href": "content/chapters/summarizing_data.html#next-steps",
    "title": "Summarizing data",
    "section": "Next steps",
    "text": "Next steps\nNow that we can summarize data, we can begin to connect summaries to statistics (and learn/remember some probability along the way!).",
    "crumbs": [
      "Chapters",
      "Summarizing data"
    ]
  },
  {
    "objectID": "content/end_matter/acknowledgements.html",
    "href": "content/end_matter/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Many thanks to Bill Rice and Steve Gaines at UCSB for encouraging me to continue my interests in statistics.\nMy department at Baruch also supported me when I proposed the Biostatistics (ENV/BIO 2100) course in 2017 and taught for the first time in 2018.\nBaruch College’s Center for Teaching and Learning, as a channel for a statewide funding effort focuse on developed OER (open-educational resources) at CUNY and SUNY campuses, have supported the continued development of the class.\nThe class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!\n\nThis repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland.",
    "crumbs": [
      "End matter",
      "Acknowledgements"
    ]
  },
  {
    "objectID": "content/extensions/maps.html",
    "href": "content/extensions/maps.html",
    "title": "Maps in R",
    "section": "",
    "text": "Making maps is something many scientists need to do. Understanding the spatial relationship among sampling sites, populations, or cities can inform our understanding of analysis or results. While R is not primarily a geographic information system, it has the ability to produce maps through multiple libraries (the focus of this section). It can also be used to perform spatial analysis.",
    "crumbs": [
      "Extensions",
      "Maps"
    ]
  },
  {
    "objectID": "content/extensions/maps.html#making-maps",
    "href": "content/extensions/maps.html#making-maps",
    "title": "Maps in R",
    "section": "Making maps",
    "text": "Making maps\nProducing maps typically involves loading a background/base map of an area and then plotting sites or specific data points on it. For this to work, you have to make sure the different maps are using the same coordinate system and map projection. Put simply, coordinates (e.g., latitude and longitude) are used to specify a spot on the earth. Various coordinate systems exist, so you need to make sure the base map is using the same coordinates you are using to specify location. Part of different coordinate systems is related to the fact that dislaying a spherical earth on a flat screen/piece of paper is hard.\nIn order for it to end a “complete picture”, most projections distort various pieces of th earth.\nMap data can be produced using vector or raster data. Vectors mean the software is using directions to draw points, lines, or polygons that represent space. Raster means the software is actually stitching together cells or images to represent space.\n\nVector approaches\nFor example, rnaturalearth supplies vector data from NaturalEarth for use in R. You can ask for country level data. Note that the data contains info on how to “draw” each country, but can also hold other data.\n\nbase_map &lt;- ne_countries(type = 'countries', scale = 'small')\npaged_table(data.frame(base_map))\n\n\n  \n\n\n\nthis can be plotted immediately\n\nplot(base_map$geometry)\n\n\n\n\n\n\n\n\nOther commands only focus on coastlines\n\n coast &lt;- ne_coastline()\n  plot(coast$geometry)\n\n\n\n\n\n\n\n\nYou can also turn this object into a dataframe (fortify) and use it in ggplot2\n\nlibrary(ggplot2)\n\nggplot(base_map) +\n  geom_sf()+\n  xlab(\"Longitude\")+\n  ylab(\"Latitude\") \n\n\n\n\n\n\n\n\nOnce you have these layers, you can start adding your own sites\n\nsites &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/SurveySiteCoordinates.csv\", strip.white = T, stringsAsFactors = T)\n\nWarning in read.table(file = file, header = header, sep = sep, quote = quote, :\nincomplete final line found by readTableHeader on\n'https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/SurveySiteCoordinates.csv'\n\nggplot(base_map) +\n  geom_sf()+\n  xlab(\"Longitude\")+\n  ylab(\"Latitude\")  +\n  geom_point(data = sites, \n             aes_string(x=\"Longitude\",y=\"Latitude\", group = NA), size = 10)\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n\n\n\n\n\n\n\n\n\nRaster approaches\nSo far we have worked with vector data, which uses points, lines, and polygons to represent spatial data. Another common data type used in spatial analyses is raster data. Rasters are simply gridded maps, with values attributed to each cell. These are somewhat analagous to images, where each pixel in an image has certain attribute (color). The advantage of this type of data is that we can store large amounts of information for spatial analyses. We are going to illustrate how these work with some toy data first.\n\n# Load the raster package\n# Set the dimensions of the raster (rows and columns)\nnrows &lt;- 10\nncols &lt;- 10\n# Create a raster with random values\nraster_data &lt;- raster(matrix(round(runif(n = nrows * ncols, min = 0, max = 100), 0), nrow = nrows))\n# Plot the raster\nplot(raster_data)\n\n\n\n\n\n\n\n\nAs we can see, the resulting image is a grid with 10 rows and 10 columns. Each cell (sometimes called pixel or grain) has some numerical value between 0 and 100. Associated with each value is a color, with a color ramp to the right that shows how color relates to range of values. Right now our cell values are arbirarty, but they could be any information that you would want to map spatially. For example, imagine this raster was a map of a town and the value of each cell was a measure of population density at that location. We would want to know more about the attributes of the raster before doing any analyses. Lets briefly take a look at the attributes\n\nraster_data\n\nclass      : RasterLayer \ndimensions : 10, 10, 100  (nrow, ncol, ncell)\nresolution : 0.1, 0.1  (x, y)\nextent     : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : 0, 99  (min, max)\n\n\nThere are several attributes given to us. They are:\n\nDimensions: The size (number of cells) of the raster\nResolution: The size of each cell. Given in units of the axis, often square meters or arc minutes\nExtent: The geographic limits of the raster\nCRS: Coordinate reference system used by raster. This is how the map is projected\nValues: The range of values among raster cells\n\nSome of these attributes are neccesary to know for things like data processing, but they are also relevent for general study design. For example, resolution will likely influence your analyses. If the value of each cell was a measure of population density, there will be different patterns across scales. A 5km x 5km cell will capture population density at a finer scale than a 10km x 10km cell. Therefore it is important to consider how the scale of your data impacts the questions you are trying to ask. Luckily, there are ways we can manipulate raster data for our analyses.\nTake our previous raster that we made. Say the patterns we were interested in do not occur over finer spatial scales, and we want to resample our data so it is at a coarser resolution. Instead of getting a new map of population densities with larger cell sizes, we can simply resample our previous raster by aggregating multiple smaller cells together.\n\n# Aggregate the raster to a 5x5 raster by taking the mean value of each 2x2 cell block\naggregated_raster &lt;- aggregate(raster_data, fact = 2, fun = mean)\n# Plot the aggregated raster\nplot(aggregated_raster)\n\n\n\n\n\n\n\n\nWe could also do the reverse, where we resample our raster to a finer resolution. Our original raster was at a resolution of 10x10. We can use bilinear interpolation to increase the resolution to 20x20. This method estimates the value of these new pixels based on weighted averages of surrounding cells.\n\n#Make raster with parameters that we want to resample to\ntemplate_raster &lt;- raster(matrix(round(runif(100, min = 0, max = 100), 0), nrow = 20, ncol = 20))\nfiner_raster &lt;- resample(raster_data, template_raster, method = \"bilinear\")\n# Plot the raster\nplot(finer_raster)\n\n\n\n\n\n\n\n\nLets look at all three of our rasters sampled at different resolutions to visualize how these patterns change.\n\nplot(aggregated_raster)\n\n\n\n\n\n\n\nplot(raster_data)\n\n\n\n\n\n\n\nplot(finer_raster)\n\n\n\n\n\n\n\n\nNow lets illustrate how biologist work with rasters using some real world data. Two common sources of spatial data used by ecologists are species occurences and climate rasters. Species occurences are lat/lon coordinates of where an individual of a species has been observed or collected. This type of data can be found in online databases such as the Global Biodiversity Information Facility (GBIF; https://www.gbif.org/). Climate rasters are maps of variables relating to precipitation and temperature. The 19 bioclimatic variables from Worldclim (https://www.worldclim.org/data/bioclim.html) are commonly used by researchers. We are going to show how rasters of climate can be used to gain information about a species.\nWe can download this data straight from these sources into R using the rgbif and raster packages. First we will obtain occurence data. We can do any species. Here we will choose the moose (Alces alces)\n\nspecies_name &lt;- \"Alces alces\" \n# Search for occurrences of the species using GBIF\nocc_search &lt;- occ_search(scientificName = species_name, return = \"data\")\n\nWarning in pchk(return, \"occ_search\"): `return` param in `occ_search` function is defunct as of rgbif v3.0.0, and is ignored\nSee `?rgbif` for more information.\n\n# Check the occurrence data\nhead(occ_search$data)\n\n# A tibble: 6 × 125\n  key        scientificName   decimalLatitude decimalLongitude issues datasetKey\n  &lt;chr&gt;      &lt;chr&gt;                      &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 4507996075 Alces alces (Li…            53.2            -113. cdc,c… 50c9509d-…\n2 4507977218 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n3 4507703289 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n4 4507728240 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n5 4507977234 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n6 4507755396 Alces alces (Li…            38.8            -107. cdc,c… 50c9509d-…\n# ℹ 119 more variables: publishingOrgKey &lt;chr&gt;, installationKey &lt;chr&gt;,\n#   hostingOrganizationKey &lt;chr&gt;, publishingCountry &lt;chr&gt;, protocol &lt;chr&gt;,\n#   lastCrawled &lt;chr&gt;, lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, …\n\n\nWe see that there is a lot of associated data for each occurence on GBIF. While this can be useful, we are only interested in lat/lon coordinates here.\nNow we will download our climate rasters. We have to download all 19 bioclim variables, but we will only look at bio1, mean annual temperature. These rasters contain lots of data and can be slow to process, so we will download rasters at the coarsest possible resolution to save RAM.\n\n# Download a world elevation raster (DEM) from WorldClim\nclim_data &lt;- getData(name = \"worldclim\", var = \"bio\", res = 10, path = \"data\" )\n\nWarning in getData(name = \"worldclim\", var = \"bio\", res = 10, path = \"data\"): getData will be removed in a future version of raster\n. Please use the geodata package instead\n\ntmean &lt;- clim_data$bio1 #Seperate raster layer of interest\n# Plot the raster\nplot(tmean)\n\n\n\n\n\n\n\n\nOk so now we have a raster of annual mean temperature and coordinates of moose occurences. Lets see how occurences are distributed across our raster.\n\noccurrences &lt;- occ_search$data\n# Filter out rows with NA values in latitude or longitude columns\noccurrences &lt;- occurrences[complete.cases(occurrences[, c(\"decimalLongitude\", \"decimalLatitude\")]), ]\ncoordinates(occurrences) &lt;- c(\"decimalLongitude\", \"decimalLatitude\")\n# Plot occurrence points on the raster\nplot(tmean)\npoints(occurrences, col = \"red\", pch = 20)\n\n\n\n\n\n\n\n\nQualitatively, we can see that moose are distributed in areas with cooler mean annual temperatures. This is because the colors on the map where it occurs are yellow - red, which is at the bottom of the color ramp on the right (Note that temperatures here are reported in degrees celcius * 10). To quantify this relationship, we can sample the raster values at each occurence point\n\n# Extract raster values at occurrence points\nraster_values &lt;- extract(tmean, occurrences)\n#Calculate mean\nmean(raster_values/10)\n\n[1] 3.641884\n\nmedian(raster_values/10)\n\n[1] 3.7\n\n# Create a histogram of means\nhist(raster_values/10, breaks = 20, col = \"skyblue\", border = \"black\", xlab = \"Annual Mean Temp (°C)\", ylab = \"Frequency\", main = \"Frequency of Mean Annual Temperatures for A. alces\")\n\n\n\n\n\n\n\n\nWe find that distribution of mean annual temperatures experienced by moose are centered around 3.5 °C, with a mean value of 3.4002.\nHere we have shown how raster data can be used in combination with other spatial data to answer sceintific questions. Rasters are incredibly powerful for researchers because they both hold lots of information and are often widely available to the public. Studying complex spatial patterns and processes is neccesary for climate modeling, resource management, public health, agriculture, and many other scientific disciplines that provide a basis for informed decision making.\n\n\nGoogle api\nNote using google maps now requires an api. This can be created @ , but should not be shared with others. To use yours here, save it in a file called\n\nsource(\"content/extensions/private_info.R\")\n\n\nregister_google(key = key)\nmap &lt;- get_map(location =c(lon = mean(sites$Longitude), lat = mean(sites$Latitude)),\n               zoom = 12, maptype = \"satellite\")\n\nℹ &lt;https://maps.googleapis.com/maps/api/staticmap?center=40.614645,-73.838277&zoom=12&size=640x640&scale=2&maptype=satellite&language=en-EN&key=xxx&gt;\n\n#toner is another option\nggmap(map)+ \n  # xlab(expression(paste(\"Longitude \", ( degree~W)))) +\n  # ylab(expression(paste(\"Latitude \", ( degree~N)))) +\n  xlab(expression(paste(\"Longitude\"))) +\n  ylab(expression(paste(\"Latitude\"))) +\n  geom_point(data = sites, \n             aes(x=Longitude, y=Latitude, group = NA, \n                 color = Location), \n             shape = 21, size = 5, stroke = 1.5) +\n  #scale_x_continous (labels=abs) to get rid of negatives\n  # scale_x_continuous(labels=abs) +\n  scale_color_manual(values = c(\"white\", \"yellow\")) +\n  annotate(\"text\", label=\"Yellow Bar Hassock\", x=-73.85, y=40.59, size=10, \n           #          color =  hue_pal()(2)[2]) +\n           color = \"yellow\") +\n  annotate(\"text\", label=\"Black Bar Marsh\", x=-73.82, y=40.64, size=10, \n           #           color =  hue_pal()(2)[1]),\n           color = \"white\") \n\n\n\n\n\n\n\n\nSo far we have worked with vector data, which uses points, lines, and polygons to represent spatial data. Another common data type used in spatial analyses is raster data. Rasters are simply gridded maps, with values attributed to each cell. These are somewhat analagous to images, where each pixel in an image has certain attribute (color). The advantage of this type of data is that we can store large amounts of information for spatial analyses. We are going to illustrate how these work with some toy data first.\n\n# Load the raster package\nlibrary(raster)\n# Set the dimensions of the raster (rows and columns)\nnrows &lt;- 10\nncols &lt;- 10\n# Create a raster with random values\nraster_data &lt;- raster(matrix(round(runif(n = nrows * ncols, min = 0, max = 100), 0), nrow = nrows))\n# Plot the raster\nplot(raster_data)\n\n\n\n\n\n\n\n\nAs we can see, the resulting image is a grid with 10 rows and 10 columns. Each cell (sometimes called pixel or grain) has some numerical value between 0 and 100. Associated with each value is a color, with a color ramp to the right that shows how color relates to range of values. Right now our cell values are arbirarty, but they could be any information that you would want to map spatially. For example, imagine this raster was a map of a town and the value of each cell was a measure of population density at that location. We would want to know more about the attributes of the raster before doing any analyses. Lets briefly take a look at the attributes\n\nraster_data\n\nclass      : RasterLayer \ndimensions : 10, 10, 100  (nrow, ncol, ncell)\nresolution : 0.1, 0.1  (x, y)\nextent     : 0, 1, 0, 1  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : 1, 99  (min, max)\n\n\nThere are several attributes given to us. They are:\n\nDimensions: The size (number of cells) of the raster\nResolution: The size of each cell. Given in units of the axis, often square meters or arc minutes\nExtent: The geographic limits of the raster\nCRS: Coordinate reference system used by raster. This is how the map is projected\nValues: The range of values among raster cells\n\nSome of these attributes are neccesary to know for things like data processing, but they are also relevent for general study design. For example, resolution will likely influence your analyses. If the value of each cell was a measure of population density, there will be different patterns across scales. A 5km x 5km cell will capture population density at a finer scale than a 10km x 10km cell. Therefore it is important to consider how the scale of your data impacts the questions you are trying to ask. Luckily, there are ways we can manipulate raster data for our analyses.\nTake our previous raster that we made. Say the patterns we were interested in do not occur over finer spatial scales, and we want to resample our data so it is at a coarser resolution. Instead of getting a new map of population densities with larger cell sizes, we can simply resample our previous raster by aggregating multiple smaller cells together.\n\n# Aggregate the raster to a 5x5 raster by taking the mean value of each 2x2 cell block\naggregated_raster &lt;- aggregate(raster_data, fact = 2, fun = mean)\n# Plot the aggregated raster\nplot(aggregated_raster)\n\n\n\n\n\n\n\n\nWe could also do the reverse, where we resample our raster to a finer resolution. Our original raster was at a resolution of 10x10. We can use bilinear interpolation to increase the resolution to 20x20. This method estimates the value of these new pixels based on weighted averages of surrounding cells.\n\n#Make raster with parameters that we want to resample to\ntemplate_raster &lt;- raster(matrix(round(runif(100, min = 0, max = 100), 0), nrow = 20, ncol = 20))\nfiner_raster &lt;- resample(raster_data, template_raster, method = \"bilinear\")\n# Plot the raster\nplot(finer_raster)\n\n\n\n\n\n\n\n\nLets look at all three of our rasters sampled at different resolutions to visualize how these patterns change.\n\nplot(aggregated_raster)\n\n\n\n\n\n\n\nplot(raster_data)\n\n\n\n\n\n\n\nplot(finer_raster)\n\n\n\n\n\n\n\n\nNow lets illustrate how biologist work with rasters using some real world data. Two common sources of spatial data used by ecologists are species occurences and climate rasters. Species occurences are lat/lon coordinates of where an individual of a species has been observed or collected. This type of data can be found in online databases such as the Global Biodiversity Information Facility (GBIF; https://www.gbif.org/). Climate rasters are maps of variables relating to precipitation and temperature. The 19 bioclimatic variables from Worldclim (https://www.worldclim.org/data/bioclim.html) are commonly used by researchers. We are going to show how rasters of climate can be used to gain information about a species.\n\n# Load necessary libraries\nlibrary(rgbif)\n\nWe can download this data straight from these sources into R using the rgbif and raster packages. First we will obtain occurence data. We can do any species. Here we will choose the moose (Alces alces)\n\nspecies_name &lt;- \"Alces alces\" \n# Search for occurrences of the species using GBIF\nocc_search &lt;- occ_search(scientificName = species_name, return = \"data\")\n\nWarning in pchk(return, \"occ_search\"): `return` param in `occ_search` function is defunct as of rgbif v3.0.0, and is ignored\nSee `?rgbif` for more information.\n\n# Check the occurrence data\nhead(occ_search$data)\n\n# A tibble: 6 × 125\n  key        scientificName   decimalLatitude decimalLongitude issues datasetKey\n  &lt;chr&gt;      &lt;chr&gt;                      &lt;dbl&gt;            &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;     \n1 4507996075 Alces alces (Li…            53.2            -113. cdc,c… 50c9509d-…\n2 4507977218 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n3 4507703289 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n4 4507728240 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n5 4507977234 Alces alces (Li…            61.2            -150. cdc,c… 50c9509d-…\n6 4507755396 Alces alces (Li…            38.8            -107. cdc,c… 50c9509d-…\n# ℹ 119 more variables: publishingOrgKey &lt;chr&gt;, installationKey &lt;chr&gt;,\n#   hostingOrganizationKey &lt;chr&gt;, publishingCountry &lt;chr&gt;, protocol &lt;chr&gt;,\n#   lastCrawled &lt;chr&gt;, lastParsed &lt;chr&gt;, crawlId &lt;int&gt;, basisOfRecord &lt;chr&gt;,\n#   occurrenceStatus &lt;chr&gt;, taxonKey &lt;int&gt;, kingdomKey &lt;int&gt;, phylumKey &lt;int&gt;,\n#   classKey &lt;int&gt;, orderKey &lt;int&gt;, familyKey &lt;int&gt;, genusKey &lt;int&gt;,\n#   speciesKey &lt;int&gt;, acceptedTaxonKey &lt;int&gt;, acceptedScientificName &lt;chr&gt;,\n#   kingdom &lt;chr&gt;, phylum &lt;chr&gt;, order &lt;chr&gt;, family &lt;chr&gt;, genus &lt;chr&gt;, …\n\n\nWe see that there is a lot of associated data for each occurence on GBIF. While this can be useful, we are only interested in lat/lon coordinates here.\nNow we will download our climate rasters. We have to download all 19 bioclim variables, but we will only look at bio1, mean annual temperature. These rasters contain lots of data and can be slow to process, so we will download rasters at the coarsest possible resolution to save RAM.\n\n# Download a world elevation raster (DEM) from WorldClim\nclim_data &lt;- getData(name = \"worldclim\", var = \"bio\", res = 10)\n\nWarning in getData(name = \"worldclim\", var = \"bio\", res = 10): getData will be removed in a future version of raster\n. Please use the geodata package instead\n\ntmean &lt;- clim_data$bio1 #Seperate raster layer of interest\n# Plot the raster\nplot(tmean)\n\n\n\n\n\n\n\n\nOk so now we have a raster of annual mean temperature and coordinates of moose occurences. Lets see how occurences are distributed across our raster.\n\noccurrences &lt;- occ_search$data\n# Filter out rows with NA values in latitude or longitude columns\noccurrences &lt;- occurrences[complete.cases(occurrences[, c(\"decimalLongitude\", \"decimalLatitude\")]), ]\ncoordinates(occurrences) &lt;- c(\"decimalLongitude\", \"decimalLatitude\")\n# Plot occurrence points on the raster\nplot(tmean)\npoints(occurrences, col = \"red\", pch = 20)\n\n\n\n\n\n\n\n\nQualitatively, we can see that moose are distributed in areas with cooler mean annual temperatures. This is because the colors on the map where it occurs are yellow - red, which is at the bottom of the color ramp on the right (Note that temperatures here are reported in degrees celcius * 10). To quantify this relationship, we can sample the raster values at each occurence point\n\n# Extract raster values at occurrence points\nraster_values &lt;- extract(tmean, occurrences)\n#Calculate mean\nmean(raster_values/10)\n\n[1] 3.641884\n\nmedian(raster_values/10)\n\n[1] 3.7\n\n# Create a histogram of means\nhist(raster_values/10, breaks = 20, col = \"skyblue\", border = \"black\", xlab = \"Annual Mean Temp (°C)\", ylab = \"Frequency\", main = \"Frequency of Mean Annual Temperatures for A. alces\")\n\n\n\n\n\n\n\n\nWe find that distribution of mean annual temperatures experienced by moose are centered around 3.5 °C, with a mean value of 3.4002.\nHere we have shown how raster data can be used in combination with other spatial data to answer sceintific questions. Rasters are incredibly powerful for researchers because they both hold lots of information and are often widely available to the public. Studying complex spatial patterns and processes is neccesary for climate modeling, resource management, public health, agriculture, and many other scientific disciplines that provide a basis for informed decision making.",
    "crumbs": [
      "Extensions",
      "Maps"
    ]
  },
  {
    "objectID": "content/extensions/maps.html#next-steps",
    "href": "content/extensions/maps.html#next-steps",
    "title": "Maps in R",
    "section": "Next steps",
    "text": "Next steps\nR can also be used to interact with more map-focused software like QGIS.",
    "crumbs": [
      "Extensions",
      "Maps"
    ]
  },
  {
    "objectID": "content/practice_problems/10_Linear_model_extensions.html",
    "href": "content/practice_problems/10_Linear_model_extensions.html",
    "title": "Linear model extensions",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nIn a study considering how the presence of sea stars changed snail growth patterns, ~25 snails were grown in containers containing 0,1, or 2 seastars.\nSince non-consumptive effects are often threshold based, these treatments levels should be considered as groups (not as a continuous variable!). The data is available at\n\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/snail_modified_for_class.csv\nFL is the final length of measured snails, and the treatment (coded 1-3) correspond to [1=Control (no predators). 2=1 predator treatment,3=2 predator treatment).\nWhat method would you use to analyze this data and why? Carry out your test, stating your null hypothesis, test assumptions, p-value, and interpretation.\nDescribe any necessary steps and provide graphics and values as needed. If needed, can you determine which treatments differ from each other?\n\n(From OZDasl) The data give the ambient temperature and the number of primary O-rings damaged for 23 of the 24 space shuttle launches before the launch of the space shuttle Challenger on January 20, 1986. (Challenger was the 25th shuttle. One engine was lost at sea and could not be examined.) Each space shuttle contains 6 primary O-rings.\n\nNote these are counts. We can analyze this data using a Poisson distribution or binomial. Make sure you understand why each one is possible, which one is better, and carry out the analysis. Data is available @\nhttp://www.statsci.org/data/general/challenger.txt\n\nReturning to the whelk length-mass relationship from class, try fitting an exponential curve to the data. As a hint, try\n\n\nnls(Mass ~ exp(b0 + b1 * Shell.Length), whelk, \n                   start = list(b0 =1, b1=0), na.action = na.omit)\n\nCompare this model to those that assume a linear and power relationship. Data is available @\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/whelk.csv\n\nGoing back to the TEAM dataset, remember we found that elevation had no impact on carbon storage. But that was a linear fit. Use a gam (generalized additive model) to see if elevation can be related to carbon storage in an additive model. Note we can use the gamm (generalized additive mixed model) function in the mgcv package to denote mixed effects. For example (from help file)\n\n\nb2 &lt;- gamm(y~s(x0)+s(x1)+s(x2),family=poisson,\n           data=dat,random=list(fac=~1))\n\nTeam data is available @\nhttps://github.com/jsgosnell/CUNY-BioStats/blob/master/datasets/team_data_no_spaces.csv",
    "crumbs": [
      "Practice problems",
      "Linear model extensions"
    ]
  },
  {
    "objectID": "content/practice_problems/12_Intro_to_Bayesian.html",
    "href": "content/practice_problems/12_Intro_to_Bayesian.html",
    "title": "All about the Bayes",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nMake sure you can describe the main differences between Frequentist, Likelihood, and Bayesian approaches.\nReview the video we watched in class to make sure you understand the Bayesian connection. You can also read a related post @ https://brilliant.org/wiki/monty-hall-problem/.\n\n\nhttps://www.youtube.com/watch?v=mhlc7peGlGg\n\n\nI’ve shared a script in R that lets you test the Monty Hall idea (like in the video!). It’s the chivers_monty_hall_script from the code_examples foldercode_examples\non github. For this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/chivers_monty_hall_script.R”) , then test out the idea here using the following functions which calculate outcomes under each strategy.\n\n\nmonty(strat=“stay”, print_games=F)\nmonty(strat=“switch”, print_games=F)\nmonty(strat=“random”, print_games=F)\n\n\nSetup the Monty Hall problem as probabilities and convince yourself how it works. You may want to remember to think about prior and new information (likelihoods).\nRun the frog analysis (14/18 frogs are right-pawed) assuming an “uninformed” prior (is this really possible?) and priors that predict frogs are likely to be left- or right-handed (look under Bayesian analysis in script for functions such as triplot and qbeta). Vary both the relationship among the shape variables and the magnitude (weighting) to understand how the prior impacts your posterior.\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques and a Bayesian approach. For the Bayesian approach, compare approaches that give the null more and less weight.\n\nData at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)\n\nYou can source the bootstrapjsg function using\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/bootstrapjsg.R\")\n\n\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\n\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/fertilizer.csv\nUse the data to test the hypothesis that there is no difference in mean plant heights for the two groups A) Using frequentist methods B) Using Bayesian approaches.\n8.Develop a Bayesian model to determine if sepal width (from the iris dataset in R) differs among populations.\n\ncompare models that parameterize each population as different vs one that only examines difference between I. setosa and other species.\n\nmaking a new dummy variable is one way to do this!"
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html",
    "title": "Estimation and ggplot2",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#overview",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#overview",
    "title": "Estimation and ggplot2",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Estimation lecture and the use of ggplots (lots of ggplot2 example code in the Summarizing data lecture\n\nggplot2 basics\nggplot2 is a great plotting package that allows a lot of control over your output. Let’s do some examples using the sleep dataset that we left off with last week. Load the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nggplot2 works in layers so you can or subtract as needed. Provided code is verbose here so you can see what its doing. First, install and call the package.\n\nlibrary(ggplot2)\n\nTo make a plot, first set a base layer using the ggplot function.\n\ndreaming_sleep_relationship &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming))\n\nHere we are naming a dataframe to use (first argument), then noting which columns to use for the x and y axis (under the aes argument, stands for aesthetics).\nNote when we do this we get a blank graph (if we name the ggplot output, we have to call it to see it!)\n\ndreaming_sleep_relationship\n\n\n\n\n\n\n\n\nNext we add data layers using geom_ commands. Let’s start with a scatter plot, which we make using the geom_point command.\n\ndreaming_sleep_relationship_scatter &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming)) + \n  geom_point()\n\nAgain, nothing is shown, but not the object is saved! We can call it\n\ndreaming_sleep_relationship_scatter\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nWe can also just call it directly, but when/if we do this the object is not saved in the environment.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point()\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nIf nothing extra is given, the geom_commands inherit everything from the ggplot command. So here we get a scatter plot of the relationship between TotalSleep and Dreaming. Note the axis labels are the column titles, which may not be what we want in the end in regards to readability.\nHowever, now you have a basic plot. You can also use other arguments in geom_layer commands to add to it. For example, let’s color these by primate\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Primate))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNow we’ve added information on primates. Since that require us to get more data from the dataset, we had to add another aes argument. Note this is different from this (which causes an error1)\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"Primate\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nError in `geom_point()`:\n! Problem while converting geom to grob.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! Unknown colour name: Primate\n\n\nand this\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"blue\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nThe first causes an error as primate isn’t a color. The second makes all points blue! Also note the 2nd method loses the legend as color now conveys no information.\nIn general, you have to put things you want to plot in the aes argument area and anything outside of that changes the entire plot. For example, we can change the size of all points using\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(size = 4)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nThis is also a good time to talk about renaming factor labels. You may want to change Primate levels to Yes and No for your graph. Lots of ways to do this, but the revalue function in the plyr package is nice (and we’ll use this suite of packages often, same person developed ggplot2, plyr, and reshape)\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\n\nNotice what I did above. I made a new column from an existing one using a name I might want on a legend. Now I can use it in a graph.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nI can also just change the legend title directly or change legend text, but often workign with the dataframe is easier for me.\nIf we wanted the levels of Primate in a different order, we can use the relevel function in the plyr package to set one as the “first” level (and then do this sequentially to get them in the right order if needed). You can also change level orders using the factor or ordered functions for multiple levels at once.\n\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\" )\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nFinally, we can use the theme or related functions (like xlab, ylab, ggtitle) to change how the graph looks. Note, all the code here is verbose so you can change as needed, but you rarely need all this.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nYou can also directly change legend title and colours with the scale_ commands\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nIn general scale_[whatever you had aes commands]_manual lets you set colors or codes. To see color codes go to this chart\nYou can also facet a graph by another column. For example, I can split the graph I already made by Taxa\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\")) +\n  facet_wrap(~Taxa, ncol = 1)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nNotice doing this and having legend may be redundant, so I can remove the legend\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\")) +\n  facet_wrap(~Taxa, ncol = 1) +\n  guides(colour=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\nI also added a theme section to change the facet label. All this shows how you are focused on adding or layering levels in ggplot2.\nYou can save the most recent plot directly to your working directory using\n\nggsave(\"Fig1.jpg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nThis is useful when we need to send just an image to someone (or add it to a document). You can also just save using rstudio functionality.\nggplot2 is a great example of needing to undertand basic functionality without having to remember everything. The intro class lecture and accompanying code should help you get started. A few other points that often come up are noted below.\n\n\nHistograms\nFor histograms, you only need one axis (frequency is calculated automatically)\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nNote we can just copy our theme info from above and modify as needed (or ggplot2 will largely skip un-needed info). You can also save and name a theme so you don’t have to do all this everytime.\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nFinally, remember you can subset the dataframes you feed to the ggplot functions (or any other function for that matter). For example, let’s just do a histogram of just primate sleep.\n\nggplot(sleep[sleep$Taxa == \"Primate\",], aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\n\n\n\nNot interesting, but you get the idea.\n\n\nBarcharts and confidence intervals\nEstimating is a key part of statistics and should include the value you are estimating and an estimate of uncertainty. Graphs typically show this using confidence intervals, which rely on samples of means following a normal distribution that we can describe. If we assume the estimate (not the data!) is normally distributed, we can assume things about uncertainty. Namely, we can build a 95% confidence interval around our estimate (meaning the true mean is in the range 95 out of 100 times we create a sample).\nNow’s let do these in R. Confidence intervals are often tied to barcharts. Although these are common in practice, they are not easy by default in R as statisticians don’t love them. That’s because they use a lot of wasted color. I’ll show this in a moments. However, since they are common I’ll show you how to build them.\nLet’s go back to the sleep dataset and consider the average total sleep time speed for each exposure level. First, lets change exposure to factors and label them\n\nstr(sleep) #just a reminder\n\n'data.frame':   62 obs. of  13 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n $ Taxa       : Factor w/ 2 levels \"Primate\",\"Non-primate\": 2 2 2 2 2 2 2 2 2 1 ...\n\nsleep$Exposure &lt;- factor(sleep$Exposure)\n\nCheck levels\n\nlevels(sleep$Exposure)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nand relabel if you want (just for example here)\n\nlevels(sleep$Exposure)&lt;- c(\"Least\",\"Less\", \"Average\", \"More\", \"Most\") \n\nNext, we need to get the average and standard deviation for each group (remember this is tied to the normal distribution!). If we wanted to this by hand, we could do something like thi (let’s just focus on least for an example, and note we have to remove NA data)\n\nmean(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T)\n\n[1] 12.94615\n\n\nThis is our estimate. The standard deviation of this estimate is\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(sleep[sleep$Exposure == \"Least\" & is.na(sleep$TotalSleep) == F, \"TotalSleep\"]))\n\n[1] 0.7833111\n\n\nwhich is equivalent to\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(na.omit(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"])))\n\n[1] 0.7833111\n\n\nWe also call this the standard error of the mean.\nFortunately, we can also do this using a function from the Rmisc package in R, as ggplot2 doesn’t have it built in (maybe because bar charts are a bad idea?).\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nsleep_by_exposure &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Exposure\", na.rm = T)\n\nInspect the table\n\nsleep_by_exposure\n\n  Exposure  N TotalSleep       sd        se       ci\n1    Least 26   12.94615 3.994119 0.7833111 1.613259\n2     Less 13   11.11538 3.957029 1.0974823 2.391209\n3  Average  4    8.57500 1.808084 0.9040419 2.877065\n4     More  5   10.72000 1.663430 0.7439086 2.065421\n5     Most 10    4.19000 1.776670 0.5618323 1.270953\n\n\nNow we can use this summarized data to make a graph that shows uncertainty (95% confidence intervals)\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nNow to show why barplots waste ink. Note we can show the same information with\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\n\n\n\n\nAll the exta color is nice, but its not really adding anything!",
    "crumbs": [
      "Practice problems",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#lets-practice",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#lets-practice",
    "title": "Estimation and ggplot2",
    "section": "Let’s practice!",
    "text": "Let’s practice!\nLet’s return to the mammal sleep dataset that we left off with last week (Make sure you did the first assignment!).\nLoad the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nLast time you used the built-in plot functions to do some plots. Let’s replace those with ggplot2 and do some more.\n\n1\nFirst plot how TotalSleep is explained by BrainWt (remember the issues with the data). Use ggplot2 to plot the relationship.\n\n\n2\nNext color code each plot point by whether or not its a primate. In order to do this you can use the Primate column or (following class code) make a new column called Taxa to represent the information (hint:search for “ revalue”). Make sure axes are well-labeled.\n\n\n3\nLet’s work with histograms.\n\nWhat type of variation do we see in total time spent sleeping? Create a histogram to explore this issue.\nFacet the graph you created based on whether or not the animal is a primate (Primate column).\nNow only graph the data for primates.\n\n\n\n4\nDevelop a properly-labeled bar graph with error bars to explore how total sleep changes with\n\nPrimate (relabeled as yes/no as Primate/Non-Primate; note there are multiple ways to do this!) – use a 95% confidence interval for the bar\nPredation risk (as a factor!) – use 1 standard error for the bar. Note the difference!",
    "crumbs": [
      "Practice problems",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#estimates-and-certainty-concepts",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#estimates-and-certainty-concepts",
    "title": "Estimation and ggplot2",
    "section": "Estimates and Certainty Concepts",
    "text": "Estimates and Certainty Concepts\n\n5\nWhat does a 95% confidence interval mean?\n\n\n6\nTo make sure you understand the ideas of sampling, confidence intervals, and the central limit theorem, review the visualizations produced by UBC:\n\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CLT.htm\n\n\n\n7\nFor this question you’ll need the central_limit_theorem.R script from the code_examples folder. Download it to your computer and open it. Alternatively, go ahead and make a copy of the CUNY-Biostats repository. You won’t have write access but can keep one up-to-date on your machine/cloud (pull occassionally!).\nOnce you get the script, open it in Rstudio (it will be in another tab!). Make sure you have the VGAM library installed (if you open the script n Rstudio, it will likely prompt you at the top). Then use the Source button (next to the Run command we’ve been using for lines or segments). Source runs the entire code at once (similar to knitting an Rmd file) without showing any console output, but graphs and objects are still produced!\nYou can also do this from the web (included here). When you knit the file, output will appear in your final file. However, its nice to know what Source does in general.\n\nlibrary(VGAM)\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nThis script follows the UBC tutorial to show you how well the CLT (central limit theorem) works (and how it functions). This will be useful in coming to understand when you can trust tests based on the normality of means. The script produces output (graphs) that allow you to examine 6 distributions that differ in shape (skewness and kurtosis) and how those traits interact with sample size to influence the normality of means.\nSource it (or look for the graphs produced in your knitted file) and and then review the plots and consider how sample size interacts with the shape of underlying distributions to influence how quickly sample means approach normality. The noted distributions are:\n\nNormal(Z) (0,1) {no Kurtosis / no skewness / no truncation}\nDouble exponential (0,2) {high Kurtosis / no skewness / no truncation}\nUniform(0,1) {moderate Kurtosis / no skewness / double truncation}\nExponential(1,1) {high asymmetric Kurtosis / high skewness / single truncation}\nChi-square(df=4) {low Kurtosis / moderate skewness / single truncation}\nBinomial distribution (p=.7) {discrete distribution]",
    "crumbs": [
      "Practice problems",
      "Estimates and ggplot2"
    ]
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html",
    "title": "Tests for continuous data from one sample",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html#overview",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html#overview",
    "title": "Tests for continuous data from one sample",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Tests for continuous data from one sample lecture.",
    "crumbs": [
      "Practice problems",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html#examples",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html#examples",
    "title": "Tests for continuous data from one sample",
    "section": "Examples",
    "text": "Examples\nFrom lecture! Consider if average height of males training at the Australian Institute of Sport is different than average of human population.\nThese are all one sample tests, but they differ in what we know. If we know the variance of our population, we use a z test (function in BSDA package).\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T)\nlibrary(BSDA)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'BSDA'\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nz.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6, sigma.x=7)\n\n\n    One-sample z-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nz = 14.292, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 184.1474 186.8643\nsample estimates:\nmean of x \n 185.5059 \n\n\nIf we don’t, we use a t-test\n\nt.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059 \n\n\nThese both assume the means of the data are normal! If we want to relax that assumption, we can use the Wilcoxon test (also known as Mann-Whitney test, signed binary transform, or other terms!). This assumes the distribution of means is symmetric.\n\nwilcox.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nV = 5052, p-value = 5.714e-16\nalternative hypothesis: true location is not equal to 175.6\n\n\nor the sign-test/media test.\n\nSIGN.test(sport[sport$Sex == \"male\", \"Ht\"], md = 175.6)\n\n\n    One-sample Sign-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\ns = 90, p-value = 8.882e-16\nalternative hypothesis: true median is not equal to 175.6\n95 percent confidence interval:\n 183.9000 187.4684\nsample estimates:\nmedian of x \n     185.55 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.9406  183.9 187.3000\nInterpolated CI       0.9500  183.9 187.4684\nUpper Achieved CI     0.9629  183.9 187.7000\n\n\nNote this is just transforming data to 1/0 and doing a binomial test!\n\nabove_175.6 &lt;- nrow(sport[sport$Sex == \"male\" & sport$Ht &gt; 175.6,])\nbinom.test(above_175.6, nrow(sport[sport$Sex == \"male\",]))\n\n\n    Exact binomial test\n\ndata:  above_175.6 and nrow(sport[sport$Sex == \"male\", ])\nnumber of successes = 90, number of trials = 102, p-value = 6.125e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.8035103 0.9377091\nsample estimates:\nprobability of success \n             0.8823529 \n\n\nWe can also bootstrap the data.\n\nnumber_of_simulations &lt;- 1000\nlibrary(ggplot2)\nboostrap_data&lt;- sport[sport$Sex == \"male\", \"Ht\"]\nboostrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\niris_bootstrap &lt;-sample(boostrap_data, length(boostrap_data), replace = T)\nboostrap_outcomes$mean[i] &lt;- mean(iris_bootstrap)\nboostrap_outcomes$sd[i] &lt;- sd(iris_bootstrap)\n}\nggplot(boostrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nand find associated quantile-based 95% confidence intervals:\n\nquantile(boostrap_outcomes$mean, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n183.9614 187.0975 \n\n\nor using functions in the boot library\n\nlibrary(boot)\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\nresults &lt;- boot(data=boostrap_data, statistic = function(x, inds) mean(x[inds]),\n   R=number_of_simulations)\nggplot(data.frame(results$t), aes(x=results.t)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nquantile( results$t, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n184.0353 186.9051 \n\nboot.ci(results)       \n\nWarning in boot.ci(results): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic         \n95%   (184.0, 187.0 )   (184.1, 187.0 )  \n\nLevel     Percentile            BCa          \n95%   (184.0, 186.9 )   (184.1, 187.1 )  \nCalculations and Intervals on Original Scale\n\n\nAnother option (recommended) is the boot.t.test function in the MKinfer package.\n\nlibrary(MKinfer)\nboot.t.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Bootstrap One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nbootstrap p-value &lt; 2.2e-16 \nbootstrap mean of x (SE) = 185.5084 (0.7766755) \n95 percent bootstrap percentile confidence interval:\n 184.0313 187.0158\n\nResults without bootstrap:\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059",
    "crumbs": [
      "Practice problems",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html#lets-practice",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html#lets-practice",
    "title": "Tests for continuous data from one sample",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nRecognizing and assessing normality\n\n1\nUsing the qqplot_example.R code, examine the following distributions and, for the continuous distributions (marked with a “*”), observe how a normal probability plot (qqplot) can be used to visually test for approximate normality.\n\n*Normal (u= 0; σ2= 1, 10, 100)\n*Student’s t (df = 1, 10, 30, & 100)\n*Chi-square (df= 1, 2, 5, 30, 50)\nBernoulli (P=0.1, 0.5, & 0.9)\nBinomial (P=0.05; N= 2, 5, 25, & 50); (P=0.25; N= 2, 5, 25, & 50); (P=0.50; N= 2, 5, 25, & 50); (P=0.75; N= 2, 5, 25, & 50); (P=0.95; N= 2, 5, 25, & 50)\nPoisson ( u= 2, 5, 10, 30, & 50)\n\nFor this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R”)\n\n\n2\nReview the central_limit_theorem.R code (remember\n\nlibrary(VGAM)\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\n\n\nAttaching package: 'VGAM'\n\n\nThe following objects are masked from 'package:boot':\n\n    logit, simplex\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\n\nif you need to convince/remind yourself how common normality of means is for even non-normal data.\n\n\n\nWorking with data (note some sample sizes may be too small for these to all be good ideas!)\nMake sure you are comfortable with null and alternative hypotheses for all examples. You should also feel comfortable graphing the data.\n\n3\nSeven observers were shown, for a brief period, a grill with 161 flies impaled and were asked to estimate the number. The results are given by Cochran (1954). Based on five estimates, they were 183.2, 149.0, 154.0, 167.2, 187.2, 158.0, and 143.0. Test the null hypothesis that the mean of the estimates is 161 flies.\n\nAssuming variance = 275\nEstimating the variance from the data\nUsing rank transform analysis\nUsing binary transform analysis\n\nNote there are several ways to load the data! You can make a list (since the list is short):\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0 )\n\nor make a dataframe in a spreadsheet software (eg, Excel, Google Sheets) and then upload using a read.csv command. We did this in your introduction to R!\n\n\n4\nYields of 10 strawberry plants in a uniformity trial are given by Baker and Baker (1953) as 239, 176, 235, 217, 234, 216, 318, 190, 181, and 225 g. Test the hypothesis that µ = 205 * Assuming variance = 1500 * Estimating the variance from the data * Using rank transform analysis * Using binary transform analysis\n\n\n5\nEvolutionary geneticists predicts the family sex ratio will be 80% female in broods of eagles that successfully fledge &gt;3 young. Nests that fledge 3 or more chicks are very rare but a sample of 30 chicks are obtained from such nests and they yield 25 females and 5 males. Test the hypotheses that that: * a) the sex ratio is 50% females * b) the sex ratio is 80% females.\n\n\n6\nStudies of flying snakes have led researchers to posit the mean undulation rate is 1.4 Hz. You wish to test this hypothesis using the small sample of undulation rates shown below. Create a small dataset of the paradise tree snake undulation rates and choose and justify a test you can use to assess the data.\nUndulation rates (in Hz): 0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6\n\n\n7\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques. Data at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)",
    "crumbs": [
      "Practice problems",
      "Tests for continuous data from one sample"
    ]
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html",
    "href": "content/practice_problems/6_Compare_means.html",
    "title": "Compare means among groups",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#overview",
    "href": "content/practice_problems/6_Compare_means.html#overview",
    "title": "Compare means among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture.",
    "crumbs": [
      "Practice problems",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#examples",
    "href": "content/practice_problems/6_Compare_means.html#examples",
    "title": "Compare means among groups",
    "section": "Examples",
    "text": "Examples\nWe will run ANOVA’s using the lm function to connect them to other test. First, build the model\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nThen use the object it created to test assumptions\n\npar(mfrow = c(2,2))\nplot(iris_anova)\n\n\n\n\n\n\n\n\nIf assumptions are met, check the p-value using the summary or Anova function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_anova, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the overall test is significant, carry out post hoc tests (Tukey shown here for all pairs, as most common)\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nIf assumptions are not met, we can use the Kruskal Wallis non-parametric test and associated post hoc tests.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\nor a bootstrap alternative\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\nFor 2 groups, the boot.t.test function in the MKinfer package is also an option.",
    "crumbs": [
      "Practice problems",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#just-for-practice",
    "href": "content/practice_problems/6_Compare_means.html#just-for-practice",
    "title": "Compare means among groups",
    "section": "Just for practice",
    "text": "Just for practice\n\n1\nUse the iris dataset in R to determine if petal length differs among species. Do this problems using ANOVA, Kruskal-Wallis, and bootstrapping methods. Make sure you can plot the data and carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n\n2\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv.\nAnalyze this data using the t.test function and the lm function to convince yourself that t-tests are special cases of ANOVAs, which are special cases of linear models!",
    "crumbs": [
      "Practice problems",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "href": "content/practice_problems/6_Compare_means.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "title": "Compare means among groups",
    "section": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.",
    "text": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n3\nData on sugar cane yield for multiple fields is available using\nread.table(“https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv”, header = T, stringsAsFactors = T)\nMore info on the data can be found at http://www.statsci.org/data/oz/cane.html. Is there evidence that location (DistrictPosition column) impacts yield (Tonn.Hect column)? If so, which areas are driving this distance?\n\n\n4\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on gender? If so, which gender has the higher FEV score? How much variance does gender explain?\n\n\n5\nThe following data are human blood clotting times (in minutes) of individuals given one of two different drugs.\n\n\n\nDrug B\nDrug G\n\n\n\n\n8.8\n9.9\n\n\n8.4\n9.0\n\n\n7.9\n11.1\n\n\n8.7\n9.6\n\n\n9.1\n8.7\n\n\n9.6\n10.4\n\n\n\n9.5\n\n\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\nUsing rank transform analysis\nUsing a permutation test\nUsing a bootstrap test\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\nUsing rank transform analysis\nUsing a permutation test\nUsing a bootstrap test\n\n\n\n6\n(Example from Handbook on Biological Statistics) Odd (stunted, short, new) feathers were compared in color to typical feathers in Northern Flickers (Colaptes auratus) (Wiebe and Bortolotti 2002) . Data is at\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\nTest the hypothesis that odd and typical feathers did not differ using\n\na Student’s t test and/or lm\na rank test\nbootstrapping\n\nNote we will return to this question next week!",
    "crumbs": [
      "Practice problems",
      "Compare means among groups"
    ]
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Practice problems",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#overview",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#overview",
    "title": "Relationships among numerical variables",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Relationships among numerical variabless lecuture.",
    "crumbs": [
      "Practice problems",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#example",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#example",
    "title": "Relationships among numerical variables",
    "section": "Example",
    "text": "Example\nFollowing the iris dataset from class\n\nlibrary(ggplot2)\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(size = 3) +\n  ylab(\"Sepal Length\")+ggtitle(\"Sepal length increases with petal length\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+\n  xlab(\"Petal length (cm)\") +\n  ylab(\"Sepal length (cm)\")\n\n\n\n\n\n\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\npar(mfrow = c(2,2))\nplot(iris_regression)\n\n\n\n\n\n\n\nlibrary(car)\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\ncor.test(~ Sepal.Length + Petal.Length, data = iris,\n         method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\n\nbootstrap_iris &lt;- Boot(iris_regression)\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate     2.5 %    97.5 %\n(Intercept)  4.3066034 4.1400653 4.4433386\nPetal.Length 0.4089223 0.3728116 0.4506309",
    "crumbs": [
      "Practice problems",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#practice",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#practice",
    "title": "Relationships among numerical variables",
    "section": "Practice",
    "text": "Practice\n\n1\n\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at\n\nhttp://www.statsci.org/data/oz/ms212.txt\nWith more info at\nhttp://www.statsci.org/data/oz/ms212.html.\nIs there evidence that age, height, or weight impact change in pulse rate for students who ran (Ran column = 1)? For each of these, how much variation in pulse rate do they explain?\n\n\n2\n\n(from OZDASL repository, http://www.statsci.org/data/general/stature.html; reference for more information)\n\nWhen anthropologists analyze human skeletal remains, an important piece of information is living stature. Since skeletons are commonly based on statistical methods that utilize measurements on small bones. The following data was presented in a paper in the American Journal of Physical Anthropology to validate one such method. Data is available @\nhttp://www.statsci.org/data/general/stature.txt\nas a tab-delimted file (need to use read.table!) Is there evidence that metacarpal bone length is a good predictor of stature? If so, how much variation does it account for in the response variable?\n\n\n3\n\nData on medals won by various countries in the 1992 and 1994 Olympics is available in a tab-delimited file at\n\nhttp://www.statsci.org/data/oz/medals.txt\nMore information on the data can be found at:\nhttp://www.statsci.org/data/oz/medals.html\nIs there any relationship between a country’s population and the total number of medals they win?\n\n\n4\n\nContinuing with the Olympic data, is there a relationship between the latitude of a country and the number of medals won in summer or winter Olympics?\n\n\n\n5\n\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\n\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on age or height? If so, how do these factors impact FEV, and how much variance does each explain?\n\n\n6\n\nContinuing with the FEV data, produce plots that illustrate how height, age, and gender each impact FEV.",
    "crumbs": [
      "Practice problems",
      "Relationships among numerical variables"
    ]
  },
  {
    "objectID": "content/primer_materials/tools_overview.html",
    "href": "content/primer_materials/tools_overview.html",
    "title": "Downloading tools and using github",
    "section": "",
    "text": "In class we will use R, Rstudio (now Posit), and git (via github). We will use R in class to “do” statistics. R is a free, open-source program that is widely used in academia and industry (learning it is a CV or resume skill). It is command-line based, which may be different if you are used to point-and-click programs (graphical user interfaces), but that allows it to be easily saved and shared. We will also store R and related files in multiple places using a process called version control; specifically, we will use github to accomplish this.\nBelow are notes to help you download these and get started. Bryan (2017) and Bryan (n.d.) also supply excellent extended introduction and notes.\n\nRequired tools\n\nGet access to R!. You can make an account at posit Cloud (formerly Rstudio Cloud) (https://posit.cloud/). You can also install R (https://cran.r-project.org/) and Rstudio (https://www.rstudio.com/) on your machine, but I strongly recommend starting with Posit cloud. Rstudio cloud is free for up to 25 hours/month, you don’t have to maintain it, and it gives gives a standard install (same on all machines, so your intro/ our training may be smoother). You can also do both. If you need help, videos are at :\n\nMaking a posit Cloud account (formerly Rstudio Cloud, to be updated but similar process)- this is the recommended approach!\nDownloading R\nDownloading Rstudio\n\nJoin the github classroom we’ll be using for our sessions\n\nlook for email from Blackboard! \nWhen you visit the page it will ask you to connect or create a github repository. You can use any name (be anonymous or not) that you want. This is a free process.\n\n\n\n\nCloning a repository\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio cloud(to be updated for Positcloud, but still basically the same).\nAfter you join the github classroom, you’ll make a clone of the assignment repository. You can do this on Positcloud or an installed version of Rstudio. I recommend starting with posit Cloud and focus on that process here. First, open Posticloud in one tab/window on your browser (and log in). Next, open github on another tab/window.\nThen, find your copy of the repository on github. You can follow the github classroom link again, or log into github and then visit https://github.com/settings/repositories. Find the repository connected to the assignment. You can go to go to https://github.com/settings/repositories to look for it (you’ll need to sign in to github). For github classroom assignments, the repository will be called assignment_name_YOURGITHUBUSERNAME. Click on it to open the repository page.\n\n\n\nFind your repository @ https://github.com/settings/repositories. Then select it (use the top link!)\n\n\nThis will take you to your repository page. This is a also a chance to note you may want to sync the fork - this catches your copy up to any changes I have made in the assignments or associated files.\n\n\n\nYou can sync up any changes to the original assignment repository by clicking the sync fork button. Note all repositories will not have this option.\n\n\n\n\nWhat’s the difference between clone and fork? Click on the grey triangle\n\nA clone of repository is directly linked up to the original repository. Changes made in one will be pushed or pulled to the others. A fork is different in that it can’t directly communicate. Instead, changes can be synced up using pull requests. github also makes it easy to sync them using the button shown above. Github classroom forks the assignments for each of you, then you makes clones of the forks to work on posit Cloud or your machines.\n\nFrom the repository page, you need to get the url to copy (or clone) the repository. To do this, click on the green Code button from the github page for your repository. Copy the web url (or click the copy icon, two overlapping squares).\n\n\n\nClick on Code to get repository url\n\n\nNow go to the PositCloud tab. Select New Project, New Project from Github repo. You’ll need to enter the url for your github repository (what you copied). Press enter and the project will deploy.\n\n\n\nClick on New Project to clone a repository.\n\n\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!\n\nIf you are using RStudio on your desktop (or via a server…anywhere that\nlooks like an RStudio screen)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio desktop\nTo start working on an assignment, open RStudio.\n\n\n\nSelect File &gt; New Project in Rstudio to start a project\n\n\nSelect file, new project, Version control. On the next screen select git. If this isn’t available, you may need to install git (free) on your system. You can download it at https://git-scm.com/download/.\nNext you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository.\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the Rstudio Repository URL space. You can select/edit what you want the repository to be called and where its stored (its just a folder on your computer). For example, I have a Repositories folder in my main hard drive where I save all of these. Then select Create project. Whatever you choose, the project will be saved in new folder in that location using the name you chose. Note you may need to enter your github username and password to create the repository.\nYou also may get an error/warning about personal access token! this happens at different points on different machines (thus why Rstudio cloud is nice). If you see this now, don’t worry. We’ll cover it (a known issue) in class.\nThe next screen will bring you to a “normal” RStudio screen. Now we can actually work in R and markdown.\n\n\n\nWorking in R and with markdown\nNow you can start working on the files in the repository in Rstudio. Whether you are in posit Cloud or Rstudio, the basic screen should look the same.\n\n\n\nImage of “normal” R screen.\n\n\nThe main screen has 4 quadrants by default (note the upper left may not be there at first!), each with multiple tabs. Color and appearance can be customized until Tools &gt; Options. For now, make sure the upper right quadrant is tabbed to Git. Note the area is empty.\nBefore you work, make sure you are in the right repository. In posit cloud, the project, or workspace, is shown at the the top of the screen (after Your Workspace). In Rstudio, you should see whatever you named the project in the upper right hand corner. If you don’t go to File &gt; Open Project and navigate to where you placed the repository.\nOnce you are in the right project, open the file you want to work on. From inside the project space, go to File, Open File and find it, or look in the Files window (lower right quadrant) to find and open the file.\n\n\n\nYou can select files in the Files tab (typically lower right quadrant).\n\n\nIn this example we will copy a file and then edit it to explain saving, commits, and pushing. For example, you can make a copy of the R_primer.R file (the first file we use in class, and the only .R file!). Select the checkbox next to the file, then click the More (gear) button &gt; Make a copy. Then save a copy with your initials.\n\nEditing, committing, and pushing changes\nWhen you did this, the new file now appears in the window under the git tab.\n\n\n\nWhen you change a file (by saving or creating it) it will appear in the git window.\n\n\nThis means you have changed (by updating, adding, or removing) a file but have not committed that change. A commit is different than a save. A save updates a file. A commit takes a snapshot that can be compared to earlier (or later) versions to show you exactly what changed. This is very useful for programs that use text commands (like R), since small errors can cause code to not run. This process is called version control, and it is recommended for use in modern statistics curriculum.\n\nAs more businesses, governments, and researchers make analysis-driven decisions, students of statistics and data analysis should be taught how to collaborate with others in managing data, code, and results that are part of a reproducible analysis pipeline. Version control, a system for organizing and tracking changes to files associated with a project (Tichy 1985; Chacon and Straub 2014), has long been recommended for inclusions in the modern statistics curriculum (Nolan and Temple Lang 2010). More recently, both the American Statistical Association (2014) and the National Academy of Sciences (2018) have emphasized that the modern statistics curriculum should teach students project documentation and collaboration.(Fiksel et al. 2019) (terms bolded by me).\n\nTo commit the file, select the checkbox next to the files, and select Commit.\n\n\n\nTo commit the file, select the checkbox next to the files, and select Commit.\n\n\nA pop-up window will appear. It shows what has changed in selected files in green (addition, all new here!) or red (removed, not shown here). You have to select boxes next to files(if not already done), enter commit message, and press commit. Try it now. Enter “My first commit!” and press Commit.\n\n\n\nPop-up commit window. You have to select boxes next to files(if not already done), enter commit message, and press commit.\n\n\n\nPotential error\nIf you get a screen that looks like this:\n\n\n\nThis screen means you need to tell your computer who to assign changes to\n\n\nIt just means we need to associate an identity with the commits. To do this, close (x) the git windows. Select the terminal tab:\n\n\n\nThe terminal tab lets you send commands to your computer\n\n\nThen paste this line into the terminal (tab to the right of the console tab), (note you need 2 – should be 2 dashes!)\ngit config –global user.email “you@example.com”\nreplace the email with your email (leave the quotes) and press enter.\nThen paste this line into the terminal,\ngit config –global user.name “Your Name”\nreplace the Your Name with your name (leave the quotes) and press enter.\nNow go back to the git window and try the commit again. It should work. You will only have to do this once (for desktop versions) and only occasionally for cloud-based RStudio instances.\nNow you’ve committed to the file to your Rstudio instance (on your own machine or server), which is itself a git repository. Remember, this is different than a save. A save overwites the current file, while a commit compares changes you have made and tracks them. To see this, you can go the Git tab, select Diff, and then History on the pop-you. From there, you can select the commit, select any file you committed, and actually see the changes. This allows you to go back to (or just see) earlier versions easily, which is often helpful in programming.\n\n\n\nPushing to github\nNow you need to push these changes to the cloud so I can see them (or, in the future, so you could share with collaborators or save a copy for yourself). Rstudio/posit Cloud warns you of this issue!\n\n\n\nNote you are warned “Your branch is ahead..” in multiple places\n\n\nTo fix this, press Push on the the pop-up window or git tab (the green arrow).\n\n\n\nPress the push arrow!\n\n\n\nPotential error (very likely!)\nAs of Fall 2021, Github no longer accepts usernames and passwords for authentication. However, posit Cloud may still ask for those since they once worked, so don’t be surprised if you enter your password correctly but your attempt to create a repository (or push commits to it) still fails with a message like this.\n\n\n\nIf you see this, it means you need to setup or reauthorize a github token\n\n\nGithub requires you to use a token to verify you have permission to make changes to repositories that you store there. To create and use a token, we will use two packages. To install them, first select Tools &gt; Install Packages.\n\n\n\nInstall packages using the Tools&gt;Install packages option\n\n\nThen install the usethis and gitcreds packages.\n\n\n\nPut usethis, gitcreds in Packages options (Rstudio will help you complete these); leave the install dependencies box checked\n\n\nEnter these package names in the pop-up window, leave install dependencies checked, and click install. We will discuss this more in class, but in short R works off functions to run commands. Functions are short names for longer sets of instructions someone has written. Functions are stored in packages (sometimes called libraries). There are many, many of these, so some don’t come pre-installed/available with R. If you need those you have to install them once (per machine or project in posit Cloud).\nNow go to the console area (lower left). This is one of the only things you’ll do directly there! We’ll talk about using scripts more.\n\n\n\nConsole is where we enter personal access token commands. Everything else is in scripts!\n\n\nNext enter these commands and press enter. If this file is open in R, you can select the green triangle button (play icon) to run the current chunk. Otherwise you can copy and paste it into R.\n\nlibrary(usethis)\nusethis::create_github_token()\n\nThis will launch a browser pointed to github. You may need to log in. Then it will have you name a PAT (personal access token). You can, for example, name it Rstudio. You can also set it to no expiration since you are only using it for this class (not a good idea in general for security reasons).\n\n\n\nName your personal access token and put no expiration. Leave all else as is and press generate token on bottom of window.\n\n\nScroll to the bottom of the page (leave everything else alone) and press generate token. A new screen will appear\n\n\n\nA token will appear. Save it somewhere!\n\n\nSave the token somewhere (you’ll never see it again once you close the window). Then go back to posit Cloud/Rstudio and run this code.\n\nlibrary(gitcreds)\ngitcreds_set()\n\nSelect 3, then paste in the token you just generated and press enter.\n\n\n\nEnter the token (not your github password) and press enter.\n\n\nThis process is letting your computer and github communicate and should only need to be done once for a desktop. For rstudio.cloud, you will need to regularly reenter the token, but you don’t have to recreate it. So save you PAT somewhere just in case. If/when you lose it, however, you can simply make a new one and reconnect the repositories.\nOnce you enter your git credentials, try to push your changes again (press the green arrow). It should work this time.\n\n\nPotential error\nOne error that might appear when you try to push looks like this:\n\n\n\nThis error means you need to pull before you can push!\n\n\nOn the bright side, this error means github and Posit Cloud/Rstudio are talking. However, it also means your github-based clone has changed since you last synced it. To prevent merge errors, use the git pull button first, then try to push again.\n\n\n\nUse the pull button to pull changes from the github-based clone.\n\n\nYou know push has worked when the warnings disappear!\n\n\n\nNo more warnings!\n\n\nYou can also go to your github repository (on the web) and see the commits there.\nAs you work, use commits to save snapshots of your work in a version control manner, and pushes to share them. If you get stuck, you can also push your file up so I can see it and help you fix it (much better than “My code isn’t working). Then you can actually see”how” I fixed it. The code will also be useful for assessments.\n\n\n\n\n\n\n\nReferences\n\nBryan, Jennifer. 2017. “Excuse Me, Do You Have a Moment to Talk about Version Control?” https://doi.org/10.7287/peerj.preprints.3159v2.\n\n\n———. n.d. Happy Git and GitHub for the useR. https://happygitwithr.com/.\n\n\nFiksel, Jacob, Leah R. Jager, Johannna S. Hardin, and Margaret A. Taub. 2019. “Using GitHub Classroom to Teach Statistics.” Journal of Statistics Education 27 (2): 110–19. https://doi.org/10.1080/10691898.2019.1617089.",
    "crumbs": [
      "Software primer",
      "Tools overview"
    ]
  },
  {
    "objectID": "content/solutions/11_Multivariate_methods_solutions.html",
    "href": "content/solutions/11_Multivariate_methods_solutions.html",
    "title": "Multivariate methods",
    "section": "",
    "text": "Remember you should\n\nadd code chunks by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I to answer the questions!\nknit your file to produce a markdown version that you can see!\nsave your work often\n\ncommit it via git!\npush updates to github\n\n\n\nA pharmaceutical company has a drug that may help an illness that causes fever (temperature in degrees Celsius), blood pressures, and “aches” (scored on an index). Data is collected for several patients. To determine if the drug actually helps, test for differences in multivariate means for the fever, pressure and aches column, against the grouping variable treatment.\n\n\nillness &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRlcjpU0XHfXF1WId1C5ZYX0YdY53KI9Nv91_tNCMj4z4iTjr-XMW1L_Ln8j3ahk5GUPZy4kGzSlA96/pub?gid=1322236994&single=true&output=csv\",\n                    stringsAsFactors = T)\n\nWe will test the multiple outcomes using a MANOVA. This tests the null hypothesis that there is no difference in the vector of mean parameters for the groups.\n\nm &lt;- manova(cbind(fever,pressure,aches)~treatment, illness)\nsummary(m)\n\n          Df  Pillai approx F num Df den Df    Pr(&gt;F)    \ntreatment  1 0.55466   14.115      3     34 3.857e-06 ***\nResiduals 36                                             \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe MANOVA shows a significant difference (Pillai’s trace = .55466, p &lt;.001), so we reject the null hypothesis. To follow this up we consider ANOVAs for each trait to determine which ones differ among groups\n\nsummary.aov(m)\n\n Response fever :\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntreatment    1 43.973  43.973   34.99 9.02e-07 ***\nResiduals   36 45.242   1.257                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response pressure :\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\ntreatment    1  440.9  440.93  2.6871 0.1099\nResiduals   36 5907.4  164.09               \n\n Response aches :\n            Df  Sum Sq Mean Sq F value Pr(&gt;F)\ntreatment    1   59.74  59.738  1.6285 0.2101\nResiduals   36 1320.58  36.683               \n\n\nThese indicate that only fever differs among groups.\n\nDarlingtonia californica is a partly carnivorous pitcher plant that grows in fens and along seeps and streams in the mountains of Oregon and California. Its pitchers are tubular l eaves with a round hood and a mouth at the base of the hood (see figure below). A “fishtail” appendage hangs from the mouth. Wasps and other prey are attracted to nectar secreted by extrafloral nectaries along the hood, mouth, and fishtail. Plants absorb nutrients excreted by a food web of bacteria, protozoa, mites, and fly larvae that break down the prey.\n\nMeasurements of 87 plants from four sites were made by Ellison and Farnsworth (2005, The cost of carnivory for Darlingtonia californica (Sarraceniaceae): evidence from relationships among leaf traits. Am. J. Botany 92: 1085-1093). Their measurements are available using\n\npitcher &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vQZf2mS4NmfBUUsn7lY2RTpuVjuWvRYN4MdLNt2XdS4WepolrxvWCKBI5diKBMWPLhdbEGwP-hfWOnz/pub?gid=1427497144&single=true&output=csv\",\n                    stringsAsFactors = T)\n\nI obtained them from the web page (http://harvardforest.fas.harvard.edu/personnel/web/aellison/publications/primer/primer.html) of A. M. Ellison for the book by Gotelli and Ellison (2004, A primer of ecological statistics. Sinauer, Sunderland, Mass.). To simplify, outliers have been removed. Most plant traits in the file are illustrated in the image below, and trait labels are fairly self-explanatory. Keel width measures the span of the pitcher tube. “Wing” traits refer to the lengths of the fishtail appendage.\n\n\n\n\nPhotograph of a Darlingtonia californica pitcher with morphological measurements indicated (lower diameter at ground level not shown). Note the translucent hood and the pronounced fishtail appendage attached to the proximal side of the mouth\n\n\n\n\nUse a MANOVA to consider differences in plant traits (do not follow-up with almost 20 ANOVA’s! Just consider why PCA might be useful with large datasets!\n\n\npitcher_outcomes &lt;- pitcher[,2:13]\npitcher_manova &lt;- manova(as.matrix(pitcher_outcomes)~site, pitcher)\nsummary(pitcher_manova)\n\n          Df Pillai approx F num Df den Df    Pr(&gt;F)    \nsite       3 1.6951   8.0108     36    222 &lt; 2.2e-16 ***\nResiduals 83                                            \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary.aov(pitcher_manova)\n\n Response height :\n            Df Sum Sq Mean Sq F value Pr(&gt;F)\nsite         3  35080   11693  1.1618 0.3293\nResiduals   83 835341   10064               \n\n Response mouth_diam :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3 1069.1  356.38  12.902 5.353e-07 ***\nResiduals   83 2292.7   27.62                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response tube_diam :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3 234.95  78.317  9.6701 1.526e-05 ***\nResiduals   83 672.21   8.099                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response keel_diam :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3 141.99  47.329  14.653 9.638e-08 ***\nResiduals   83 268.08   3.230                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response wing1_length :\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \nsite         3  12897  4298.9  11.289 2.76e-06 ***\nResiduals   83  31606   380.8                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response wing2_length :\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)   \nsite         3   7784 2594.56     5.5 0.001702 **\nResiduals   83  39154  471.74                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response wingsprea :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3  21676  7225.3  6.9585 0.0003108 ***\nResiduals   83  86182  1038.3                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response hoodarea :\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3  4015.2 1338.41  6.3842 0.0006031 ***\nResiduals   83 17400.4  209.64                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response wingarea :\n            Df  Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3  3115.8 1038.60  7.1171 0.0002592 ***\nResiduals   83 12112.2  145.93                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response tubearea :\n            Df Sum Sq Mean Sq F value  Pr(&gt;F)  \nsite         3   5507 1835.78  2.9363 0.03805 *\nResiduals   83  51892  625.21                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response hoodmass_g :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3 3.1075 1.03585  10.439 6.721e-06 ***\nResiduals   83 8.2362 0.09923                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n Response tubemass_g :\n            Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nsite         3 19.305  6.4349    6.39 0.0005991 ***\nResiduals   83 83.583  1.0070                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nUse principal component analysis to investigate variation among individual plants in their dimensions. Along the way, make sure you\n\nconstruct screeplots\ndetermine how many principal components to retain (and why)\nUse biplots and/or loadings to see if you can understand/interpret the first few principal components\n\n\nNoticed I scaled the data here since some groups have more/less variation and are measured in different units.\n\nsummary(pitcher_outcomes)\n\n     height        mouth_diam      tube_diam       keel_diam     \n Min.   :322.0   Min.   :13.60   Min.   :14.30   Min.   : 1.600  \n 1st Qu.:545.5   1st Qu.:27.30   1st Qu.:17.70   1st Qu.: 5.000  \n Median :625.0   Median :31.50   Median :19.80   Median : 6.100  \n Mean   :615.6   Mean   :30.88   Mean   :20.05   Mean   : 6.399  \n 3rd Qu.:671.0   3rd Qu.:34.50   3rd Qu.:21.00   3rd Qu.: 7.200  \n Max.   :845.0   Max.   :49.30   Max.   :30.00   Max.   :14.800  \n  wing1_length     wing2_length      wingsprea         hoodarea     \n Min.   : 10.00   Min.   : 16.00   Min.   : 22.00   Min.   : 13.81  \n 1st Qu.: 58.00   1st Qu.: 56.50   1st Qu.: 70.00   1st Qu.: 35.31  \n Median : 70.00   Median : 70.00   Median : 86.00   Median : 46.18  \n Mean   : 73.26   Mean   : 72.36   Mean   : 91.66   Mean   : 47.56  \n 3rd Qu.: 85.00   3rd Qu.: 83.50   3rd Qu.:112.50   3rd Qu.: 56.30  \n Max.   :148.00   Max.   :152.00   Max.   :199.00   Max.   :104.04  \n    wingarea        tubearea        hoodmass_g       tubemass_g   \n Min.   : 2.03   Min.   : 29.57   Min.   :0.2200   Min.   :0.680  \n 1st Qu.:14.36   1st Qu.: 69.40   1st Qu.:0.5600   1st Qu.:1.995  \n Median :19.89   Median : 89.15   Median :0.7600   Median :2.920  \n Mean   :23.21   Mean   : 87.43   Mean   :0.8101   Mean   :2.882  \n 3rd Qu.:27.59   3rd Qu.:103.00   3rd Qu.:1.0250   3rd Qu.:3.505  \n Max.   :77.09   Max.   :187.27   Max.   :1.9300   Max.   :5.890  \n\n\n\nlibrary(vegan)\npitcher_pca &lt;- rda(pitcher_outcomes, scale=T)\nsummary(pitcher_pca)\n\n\nCall:\nrda(X = pitcher_outcomes, scale = T) \n\nPartitioning of correlations:\n              Inertia Proportion\nTotal              12          1\nUnconstrained      12          1\n\nEigenvalues, and their contribution to the correlations \n\nImportance of components:\n                         PC1    PC2    PC3     PC4     PC5     PC6     PC7\nEigenvalue            6.0387 2.2926 1.5593 0.63927 0.44024 0.27999 0.25489\nProportion Explained  0.5032 0.1910 0.1299 0.05327 0.03669 0.02333 0.02124\nCumulative Proportion 0.5032 0.6943 0.8242 0.87748 0.91417 0.93750 0.95874\n                          PC8     PC9     PC10     PC11     PC12\nEigenvalue            0.17288 0.14335 0.092922 0.057404 0.028523\nProportion Explained  0.01441 0.01195 0.007744 0.004784 0.002377\nCumulative Proportion 0.97315 0.98510 0.992839 0.997623 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n* General scaling constant of scores:  5.667871 \n\n\nSpecies scores\n\n                 PC1      PC2      PC3      PC4      PC5      PC6\nheight       -1.1643 -0.95368  0.23353  0.28433 -0.40067  0.15695\nmouth_diam   -1.3498 -0.10307  0.53362 -0.29479  0.35038  0.30827\ntube_diam    -0.1513 -1.02639 -1.06379 -0.09076  0.48719 -0.43845\nkeel_diam     0.5582 -0.85222 -0.86751 -0.77983 -0.39166  0.33991\nwing1_length -1.3002  0.72306 -0.29384 -0.23501 -0.18980 -0.09135\nwing2_length -1.2168  0.68270 -0.57917 -0.02279 -0.35568 -0.17562\nwingsprea    -0.9352  0.67747 -0.88936  0.41005  0.11292  0.30465\nhoodarea     -1.4402 -0.30399 -0.01017 -0.07542  0.49798  0.26424\nwingarea     -1.3941  0.58219 -0.41932 -0.00920 -0.02980 -0.05794\ntubearea     -1.0507 -1.09046 -0.15821  0.51083 -0.12765  0.03247\nhoodmass_g   -1.3095  0.07561  0.51625 -0.65995  0.04898 -0.20154\ntubemass_g   -1.3311 -0.60281  0.52025  0.03302 -0.24827 -0.27434\n\n\nSite scores (weighted sums of species scores)\n\n             PC1      PC2      PC3       PC4        PC5       PC6\nsit1  -0.4463924  0.04766  0.79651 -1.054843 -0.0870049  0.335005\nsit2   1.0632800  0.47916  0.42089 -0.119629  0.3613301 -0.247938\nsit3   0.4386730  0.10924  0.13222 -0.184173 -0.0890179  0.075499\nsit4  -0.1661331  0.29206 -0.03427 -0.712293  0.4491643 -0.439535\nsit5   0.3304689 -0.63223  0.59247  0.079716 -0.5914151 -0.735484\nsit6  -0.3799725 -0.28525  0.39815 -0.429037 -0.2000534 -0.225961\nsit7  -0.3916880 -0.57755  0.31489 -1.060107  0.6798062 -0.519512\nsit8  -0.0872208  0.11243 -0.13918  0.472610 -0.3446415 -0.130392\nsit9   0.6816717 -0.06759 -0.17840 -0.236907 -0.0438359 -0.171646\nsit10 -0.3255634 -0.69190  1.06871 -0.482034  0.4828406  0.184721\nsit11  0.8034244  0.01429  0.35956 -0.876686  0.9733306  0.320842\nsit12 -0.7595912  0.43638 -0.10189 -0.912732  0.9836053  0.143740\nsit13 -1.0031435 -0.13357 -0.03894 -0.391550 -0.2840587  0.273339\nsit14 -0.2806476 -0.38673  0.74999 -1.082411  0.1679918  0.241718\nsit15  0.1381739 -0.39591  0.58624 -0.030995  1.1319188  0.778462\nsit16  0.6670847  0.22010  0.73802  0.082469  0.6924330  0.453134\nsit17 -0.2175254 -0.28696  0.55793  0.214797 -0.3622401  0.778094\nsit18  0.2111235  0.38335 -0.30553  0.212128  0.7100999  0.380937\nsit19  0.5075660 -0.17979 -0.05746  0.511997 -0.5220202 -0.850809\nsit20  0.0617287 -0.31374  0.23245  0.449793 -0.0306993 -0.077435\nsit21 -0.1762105 -0.17153  0.20731  0.236427 -0.2415121  0.636271\nsit22  0.3895824 -0.68817 -0.21368 -0.670757 -0.0133626 -0.448295\nsit23  0.7597897 -1.47935  0.32618  0.466748  1.2094533 -1.493809\nsit24  0.5820916  0.25051 -0.18916 -0.420591 -0.5091079  0.715202\nsit25  0.4175885 -0.89406  0.51579  0.604205 -0.4564758  0.259361\nsit26 -0.5162329 -0.03560  0.21041  0.758770 -0.9719342 -0.078193\nsit27 -0.6874618  0.16528 -0.23048 -0.145259 -0.6574611 -0.540882\nsit28  0.0844907 -0.83030  0.84730  0.025341 -0.7203106 -0.905834\nsit29 -0.3639010  0.08398  0.40438 -0.114736 -0.2829802 -1.022799\nsit30  0.2092140  0.33223  0.33383 -0.281520 -0.5847517 -0.287617\nsit31 -0.7094872 -0.33309 -0.17645  0.038312 -1.2697983 -0.555526\nsit32 -0.3247773  0.08040  0.31726 -0.452421 -0.3123298 -0.184047\nsit33  0.3397863  0.98893 -0.17209 -0.320579  0.5824703 -0.006482\nsit34 -0.5845362 -0.27480  0.66265 -0.362946  0.0002129 -0.376642\nsit35 -0.3572606  1.04672  0.05764 -0.298637 -0.6573240 -0.203199\nsit36 -0.2667667  0.50878  0.06541 -0.452741 -0.3111447 -0.686467\nsit37 -0.5677158  0.27752  0.06170 -0.728231 -0.4752313 -0.829873\nsit38  0.5229252  0.54024 -0.17909 -0.065267 -0.1945776  0.189681\nsit39 -0.0013364  0.80816 -0.13455 -0.018343 -0.0410862  0.391301\nsit40 -0.5388902 -1.13087  1.26171 -0.047454 -1.0441887 -0.668788\nsit41 -0.2467531  1.14060  0.66910 -0.573901  0.0146463  0.332846\nsit42  0.4549990  0.42063 -0.10218 -0.856017  0.6250215 -0.270708\nsit43 -0.1239053  0.40831  0.29145 -0.371215 -0.3167318  0.356128\nsit44 -0.1669593  0.75504  0.93458  0.624792  0.4268282  0.101325\nsit45  0.4288170 -0.27499 -0.17573 -2.222507 -1.7711028  2.378105\nsit46  0.3411268  0.32102  0.69979 -0.390182  0.1043059 -0.594431\nsit47  0.6208401  0.62623  1.25634  0.137758  0.4047325 -0.285599\nsit48  0.1931513  0.44505  0.64189 -0.001985 -0.3186258 -0.602631\nsit49 -0.1224239  0.25412  0.94560  0.191226  0.1844349  0.531529\nsit50 -0.2202620  0.19981  0.53275  0.010767 -0.3077867 -0.109635\nsit51  0.8917147  0.02203  0.06410 -0.439493  0.5206997 -0.369146\nsit52 -0.0500368 -0.35043  0.24503  0.062231  0.4307627  0.651150\nsit53 -0.1877315 -0.58397  0.59962  0.501188  0.5327591  1.182568\nsit54 -0.6434479  0.93835 -0.12122  0.419734 -0.7328652  0.051323\nsit55 -0.9655902  0.76333 -0.63653  1.590712 -0.2336204  0.966367\nsit56 -0.6095791 -0.19369  0.35361  0.609574  0.0675414 -0.955165\nsit57 -0.1637258 -0.54635  0.70509  1.868968  0.0093444  0.293474\nsit58  0.0811023  0.11102  0.27559  0.731463  0.6025209  1.179412\nsit59 -0.2263622 -0.29279 -1.06919  0.452795  1.7155293 -0.943129\nsit60 -0.3437170 -0.05901 -0.15968  0.355757  0.0777497 -0.696393\nsit61 -0.1269513  0.25833 -0.29434  0.768799  0.2236760  0.109182\nsit62 -0.1611561 -0.78416 -0.31557 -0.400971  0.6635208  0.607628\nsit63  1.1077018  1.12820  0.12538  0.199203  0.7324537  0.040404\nsit64 -0.0706639 -0.31781 -0.28904  0.864513 -0.6646166  0.272227\nsit65  0.1664669  0.26363 -0.70956  0.813948 -0.2342168  0.627288\nsit66  0.5394657  1.08518  0.32806  1.362784 -0.0030909  0.112026\nsit67 -0.3158841 -0.69456 -0.89648  0.118303  0.1763827 -0.045813\nsit68  0.7171084  0.46154 -0.54202  0.181813  0.1222254 -0.471115\nsit69  0.0004532  0.49471 -0.46819  0.323250  0.5553126  0.509247\nsit70 -0.2681351  0.44464 -0.47120  0.182249 -0.4531224 -0.044631\nsit71 -0.0843833  0.14298 -0.53371  0.135497  0.6208439  1.058486\nsit72 -1.1261616  0.32014  0.29980  0.657098 -0.0572245  0.325422\nsit73 -1.6046603  1.17904 -1.27249 -0.552834  0.3197890 -0.419779\nsit74 -2.0139236  0.23599 -0.89121 -0.173690  0.1562039 -0.675486\nsit75 -1.7543157 -1.48957 -0.72403  0.142786  1.5671974  0.413141\nsit76  0.6965810 -0.44968 -0.89687  0.225599 -0.7381074 -0.324791\nsit77  0.6040848 -0.75733 -1.01652  0.372706 -1.2037617 -0.408366\nsit78  0.9358270  0.29392 -0.43741  0.230137 -0.4547464 -0.598805\nsit79 -0.0025734 -2.03491 -0.65786 -0.113113 -0.3848851  1.109784\nsit80  0.2355288 -0.05073 -1.32836 -0.062861 -0.3406334  0.278353\nsit81  0.8757834 -0.18870 -1.63886 -0.442544 -0.1753669 -0.402537\nsit82  0.4224307  0.43504 -1.16942 -0.626329 -0.2335106 -0.121773\nsit83  0.6657932 -0.51662 -0.89376 -0.649431  0.7968785 -0.678728\nsit84  0.8054656 -0.22045 -0.88613  0.148910 -0.2246859  0.056510\nsit85  0.8557207 -0.89255 -0.13112  0.682129 -0.3729357  0.461634\nsit86  0.3009114 -0.31308 -0.38347  0.015390  0.5723651  0.609030\nsit87  0.6020202  0.47404  0.07596  0.694564 -0.1281819 -0.066068\n\n\n\nscreeplot(pitcher_pca)\n\n\n\n\n\n\n\npca_data &lt;- as.data.frame(t(as.data.frame(summary(pitcher_pca)$cont)))\npca_data$PC &lt;- 1: nrow(pca_data)\npca_data$Proportion_Explained &lt;-pca_data$\"Proportion Explained\"\npca_data$Cumulative &lt;-pca_data$\"Cumulative Proportion\"\nlibrary(ggplot2)\nggplot(pca_data, aes(x=PC,y=Proportion_Explained, group=1))+\n  geom_point(size=4)+\n  geom_line()+\n  labs(title=\"Scree plot: PCA on scaled data\") +\n  geom_vline(xintercept = which(pca_data$Cumulative &gt; .80)[1]) +\n  geom_text(aes(which(Cumulative &gt; .80)[1],.3,\n            label = paste(Cumulative[which(Cumulative &gt; .80)[1]]*100, \n                          \"% \\n of variation explained\"))) +\n  geom_hline(yintercept = 1/nrow(pca_data), linetype=\"dotted\")+\n  geom_text(aes(y= 1/nrow(pca_data), x=2, label = \"broken stick \\n line\"))\n\n\n\n\n\n\n\n\nMultiple methods suggest we should retain first 3 PC (they explain &gt;80% of variance, form elbow in scree plot, and would be selected using broken stick approach).\n\n summary(pitcher_pca)$species\n\n                    PC1         PC2         PC3          PC4         PC5\nheight       -1.1643428 -0.95367637  0.23352889  0.284330991 -0.40067325\nmouth_diam   -1.3497724 -0.10307217  0.53362181 -0.294794469  0.35038393\ntube_diam    -0.1513386 -1.02639333 -1.06379060 -0.090757278  0.48718590\nkeel_diam     0.5582436 -0.85222211 -0.86751464 -0.779825245 -0.39165963\nwing1_length -1.3001889  0.72306489 -0.29383753 -0.235012920 -0.18979581\nwing2_length -1.2168443  0.68270351 -0.57917053 -0.022790217 -0.35568359\nwingsprea    -0.9352076  0.67746718 -0.88936229  0.410054974  0.11292338\nhoodarea     -1.4401785 -0.30398796 -0.01016784 -0.075423616  0.49797720\nwingarea     -1.3940507  0.58219309 -0.41931938 -0.009200049 -0.02980016\ntubearea     -1.0507264 -1.09045742 -0.15821104  0.510832669 -0.12764686\nhoodmass_g   -1.3094841  0.07560727  0.51625102 -0.659950440  0.04897506\ntubemass_g   -1.3310526 -0.60280534  0.52025395  0.033022124 -0.24826759\n                     PC6\nheight        0.15695312\nmouth_diam    0.30826618\ntube_diam    -0.43844844\nkeel_diam     0.33991294\nwing1_length -0.09135393\nwing2_length -0.17561592\nwingsprea     0.30465108\nhoodarea      0.26424106\nwingarea     -0.05793657\ntubearea      0.03246665\nhoodmass_g   -0.20153729\ntubemass_g   -0.27433695\n\n\nWing (wingarea, wing1_length, wing2_length) and hoodarea appear to be driving PC1. PC is focus on tube measurements.\n\nbiplot(pitcher_pca, choices = c(1,2), type = c(\"text\", \"points\"), xlim = c(-5,10), scale=0,\n       main= \"Correlation biplot (scale = 0)\") # biplot of axis 1 vs 2\n\nWarning in plot.window(...): \"scale\" is not a graphical parameter\n\n\nWarning in plot.xy(xy, type, ...): \"scale\" is not a graphical parameter\n\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"scale\" is not a\ngraphical parameter\n\nWarning in axis(side = side, at = at, labels = labels, ...): \"scale\" is not a\ngraphical parameter\n\n\nWarning in box(...): \"scale\" is not a graphical parameter\n\n\nWarning in title(...): \"scale\" is not a graphical parameter\n\n\n\n\n\n\n\n\n\n\nUsing the same plant dataset, use linear discriminant analysis to classify the various sites\n\n\nlibrary(MASS)\npitcher_lda &lt;-pitcher[,1:13]\nda_ca &lt;- lda(site ~ ., pitcher_lda)\nsummary(da_ca)\n\n        Length Class  Mode     \nprior    4     -none- numeric  \ncounts   4     -none- numeric  \nmeans   48     -none- numeric  \nscaling 36     -none- numeric  \nlev      4     -none- character\nsvd      3     -none- numeric  \nN        1     -none- numeric  \ncall     3     -none- call     \nterms    3     terms  call     \nxlevels  0     -none- list     \n\nPredictions &lt;- predict(da_ca,pitcher_lda)\ntable(Predictions$class, pitcher_lda$site)\n\n     \n      DG HD LEH TJH\n  DG  23  0   0   2\n  HD   0 11   0   0\n  LEH  0  1  24   0\n  TJH  2  0   1  23\n\nldahist(data = Predictions$x[,1], g=pitcher_lda$site)\n\n\n\n\n\n\n\nldahist(data = Predictions$x[,2], g=pitcher_lda$site)\n\n\n\n\n\n\n\n\n\nUsing the same plant dataset, use cluster analysis to determine how many clusters are supported by the data.\n\n\nlibrary(cluster)    # clustering algorithms\nlibrary(factoextra)\nfviz_nbclust(pitcher_outcomes, kmeans, method = \"silhouette\")\n\n\n\n\n\n\n\n\nData only support 2 clusters (but we had 4 sites!). Note we don’t see clear break among sites in graph either.\n\nfinal &lt;- kmeans(pitcher_outcomes, 2, nstart = 25)\nprint(final)\n\nK-means clustering with 2 clusters of sizes 53, 34\n\nCluster means:\n    height mouth_diam tube_diam keel_diam wing1_length wing2_length wingsprea\n1 679.6226   33.65094  20.40755  6.207547     77.37736     76.37736  95.67925\n2 515.8824   26.55588  19.49412  6.697059     66.85294     66.08824  85.38235\n  hoodarea wingarea  tubearea hoodmass_g tubemass_g\n1 54.68491 26.71642 101.05679  0.9333962   3.464906\n2 36.46529 17.75353  66.17559  0.6179412   1.972647\n\nClustering vector:\n [1] 1 2 1 2 1 1 1 1 2 1 2 1 1 1 1 2 1 2 2 1 1 2 1 2 1 1 1 1 1 2 1 1 2 1 2 2 1 2\n[39] 2 1 2 2 1 1 1 2 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 2 2 1 1 1 1 1 1 2\n[77] 1 2 1 2 2 2 2 2 1 2 2\n\nWithin cluster sum of squares by cluster:\n[1] 395968.5 175725.5\n (between_SS / total_SS =  51.1 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\nfviz_cluster(final, data = pitcher_outcomes)\n\n\n\n\n\n\n\n#compare to other information\n\nlibrary(ggforce)\nlibrary(concaveman)\npitcher$cluster &lt;- factor(final$cluster)\npitcher$PC1 &lt;- as.data.frame(summary(pitcher_pca)$site)$PC1\npitcher$PC2 &lt;- as.data.frame(summary(pitcher_pca)$site)$PC2\nggplot(pitcher, aes(x=PC1, y=PC2, shape=site, color=cluster, group=cluster)) +\n  geom_point() +\n  geom_mark_hull(aes(fill=cluster))\n\n\n\n\n\n\n\n\n\nThe data for this exercise are rodent species abundance from 28 sites in California (Bolger et al. 1997, Response of rodents to habitat fragmentation in coastal Southern California, Ecological Applications 7: 552–563).\n\nThis data comes from the (website)[http://www.zoology.unimelb.edu.au/qkstats/data.htm) of Quinn and Keough (2002, Experimental Design and Data Analysis for Biologists, Cambridge Univ. Press, Cambridge, UK). Data is available via\n\nrodents &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vTLRwuI1cQ61RZOVJFwi0jhO85fonqR7oZHzy_9A5fVwxuZQ2A6iBnlLG2Z-33rwNnycqNUUh1_XuMU/pub?gid=1403553505&single=true&output=csv\", \n                    stringsAsFactors = T)\n\nThe 9 species are indicated by variable (column) names. Genus abbreviations are: Rt (Rattus), Rs (Reithrodontomys), Mus (Mus), Pm (Peromyscus), Pg (Perognathus), N (Neotoma) and M (Microtus). Rattus and Mus are invasive species, whereas the others are native.\n\nAnalyze the dat using correspondence analysis\n\ninterpret any results (loadings!)\n\n\n\nrodents_cca &lt;- cca(rodents[,-1])\nsummary(rodents_cca)\n\n\nCall:\ncca(X = rodents[, -1]) \n\nPartitioning of scaled Chi-square:\n              Inertia Proportion\nTotal           1.719          1\nUnconstrained   1.719          1\n\nEigenvalues, and their contribution to the scaled Chi-square \n\nImportance of components:\n                         CA1    CA2    CA3     CA4     CA5     CA6      CA7\nEigenvalue            0.7463 0.4591 0.2876 0.15278 0.03567 0.02458 0.011345\nProportion Explained  0.4341 0.2670 0.1673 0.08886 0.02074 0.01430 0.006599\nCumulative Proportion 0.4341 0.7011 0.8684 0.95721 0.97795 0.99225 0.998847\n                           CA8\nEigenvalue            0.001982\nProportion Explained  0.001153\nCumulative Proportion 1.000000\n\nScaling 2 for species and site scores\n* Species are scaled proportional to eigenvalues\n* Sites are unscaled: weighted dispersion equal on all dimensions\n\n\nSpecies scores\n\n                    CA1      CA2      CA3      CA4       CA5       CA6\nRt.rattus        2.6062  5.29874 -0.04857 -0.20529  0.030064 -0.003758\nMus.musculus     2.2895 -0.77463  0.09027  0.02397 -0.006747  0.002850\nPm.californicus -0.3071  0.05080 -0.13409  0.35500 -0.063215  0.011530\nPm.eremicus     -0.4133  0.02486  1.14724 -0.27566 -0.023139 -0.177492\nRs.megalotis    -0.3156 -0.04209 -0.06907 -0.13316  0.532798  0.211411\nN.fuscipes      -0.2733 -0.07662 -0.52447 -0.42972  0.118793 -0.153441\nN.lepida        -0.4467  0.02780  1.35632 -0.41923 -0.044516  0.771731\nPg.fallax       -0.2746 -0.10305 -0.94290 -1.12163 -0.429545  0.193050\nM.californicus  -0.3839 -0.01687  0.44567 -0.65496 -0.744677  0.261514\n\n\nSite scores (weighted averages of species scores)\n\n           CA1       CA2      CA3      CA4      CA5      CA6\nsit1   1.84681 -1.098735  0.13919  0.03544  0.65872 -0.40955\nsit2  -0.45410  0.028388  1.47538 -0.54050 -0.32520 -1.03226\nsit3  -0.13106 -0.087277 -0.63582  1.12198 -0.09235 -0.42415\nsit4  -0.27507 -0.091636 -1.13823 -0.98046 -1.75568  0.41337\nsit5  -0.37103  0.009339  0.20537  0.47983  0.81371 -1.12508\nsit6  -0.44178  0.027407  1.27694 -0.33839  0.14261  1.97439\nsit7   3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit8   3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit9   3.18338  1.920675  0.18225 -0.25239  0.09231  0.04264\nsit10  3.20909  2.722455  0.15299 -0.34334  0.15486  0.02634\nsit11  3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit12 -0.05491 -0.301609 -1.65187 -3.06119  1.29183 -0.03379\nsit13 -0.16717 -0.081410 -0.67420  0.91543  0.50579 -0.36864\nsit14  3.17373  1.620007  0.19322 -0.21829  0.06885  0.04875\nsit15  3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit16  3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit17  3.49195 11.542037 -0.16891 -1.34374  0.84291 -0.15289\nsit18 -0.34063  0.010235 -0.71108  0.96386  0.08532  0.61901\nsit19 -0.41150  0.110658 -0.46632  2.32364 -1.77238  0.46910\nsit20 -0.03833  1.215098 -0.29380  1.83557 -1.48304  0.16083\nsit21  3.35052  7.132246 -0.00796 -0.84354  0.49888 -0.06327\nsit22  3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit23 -0.37591 -0.163960 -1.80243 -3.24399  2.70293 -1.41928\nsit24  3.49195 11.542037 -0.16891 -1.34374  0.84291 -0.15289\nsit25  3.06766 -1.687336  0.31393  0.15686 -0.18917  0.11596\nsit26 -0.39476  0.004274 -1.05370  0.15706 -0.75548 -1.21836\nsit27 -0.40460  0.011545 -0.72691  0.53089  2.36564  1.04667\nsit28 -0.41957  0.082820 -0.20812  1.55161 -1.25349 -0.73110\n\nplot(rodents_cca)\n\n\n\n\n\n\n\n\nIt appears that invasive species (Rattus rattus and Muscus musculus) are driving the loadings.\n\nsummary(rodents_cca)$species\n\n                       CA1         CA2         CA3         CA4         CA5\nRt.rattus        2.6061989  5.29874422 -0.04857056 -0.20529314  0.03006368\nMus.musculus     2.2895378 -0.77462586  0.09027392  0.02396537 -0.00674700\nPm.californicus -0.3071181  0.05080108 -0.13409430  0.35500013 -0.06321493\nPm.eremicus     -0.4132524  0.02486477  1.14723516 -0.27565948 -0.02313896\nRs.megalotis    -0.3155994 -0.04208708 -0.06906776 -0.13316240  0.53279757\nN.fuscipes      -0.2732769 -0.07662170 -0.52446997 -0.42971810  0.11879332\nN.lepida        -0.4467095  0.02779902  1.35631782 -0.41923277 -0.04451588\nPg.fallax       -0.2746243 -0.10305312 -0.94289792 -1.12162708 -0.42954482\nM.californicus  -0.3838821 -0.01686660  0.44566658 -0.65495633 -0.74467657\n                         CA6\nRt.rattus       -0.003757729\nMus.musculus     0.002850040\nPm.californicus  0.011529890\nPm.eremicus     -0.177492479\nRs.megalotis     0.211411033\nN.fuscipes      -0.153441047\nN.lepida         0.771730556\nPg.fallax        0.193049692\nM.californicus   0.261513923\n\nsummary(rodents_cca)$sites\n\n              CA1          CA2          CA3         CA4         CA5         CA6\nsit1   1.84681376 -1.098735409  0.139189335  0.03544107  0.65872436 -0.40954944\nsit2  -0.45409654  0.028387729  1.475378220 -0.54050126 -0.32520013 -1.03226268\nsit3  -0.13106453 -0.087277026 -0.635820733  1.12197796 -0.09235328 -0.42414574\nsit4  -0.27506595 -0.091636366 -1.138230154 -0.98045754 -1.75567536  0.41337133\nsit5  -0.37103128  0.009338973  0.205367912  0.47983474  0.81370883 -1.12508461\nsit6  -0.44178475  0.027406546  1.276944215 -0.33838712  0.14260695  1.97439271\nsit7   3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit8   3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit9   3.18337708  1.920674958  0.182248070 -0.25239060  0.09230693  0.04263546\nsit10  3.20909115  2.722455092  0.152985239 -0.34333613  0.15485702  0.02634201\nsit11  3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit12 -0.05490512 -0.301609274 -1.651874915 -3.06118525  1.29183391 -0.03378661\nsit13 -0.16716877 -0.081410397 -0.674199522  0.91543170  0.50578546 -0.36864212\nsit14  3.17373431  1.620007407  0.193221631 -0.21828603  0.06885065  0.04874550\nsit15  3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit16  3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit17  3.49194583 11.542036575 -0.168905891 -1.34373689  0.84290798 -0.15288597\nsit18 -0.34062887  0.010234699 -0.711080679  0.96386393  0.08531798  0.61901315\nsit19 -0.41149579  0.110657901 -0.466317773  2.32363717 -1.77238336  0.46910209\nsit20 -0.03833064  1.215097902 -0.293798251  1.83557020 -1.48304462  0.16082859\nsit21  3.35051849  7.132245834 -0.007960326 -0.84353651  0.49888250 -0.06327198\nsit22  3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit23 -0.37590517 -0.163960086 -1.802433393 -3.24399470  2.70292869 -1.41927763\nsit24  3.49194583 11.542036575 -0.168905891 -1.34373689  0.84290798 -0.15288597\nsit25  3.06766380 -1.687335649  0.313930805  0.15686425 -0.18916846  0.11595600\nsit26 -0.39475743  0.004274291 -1.053697437  0.15706278 -0.75548148 -1.21835714\nsit27 -0.40459817  0.011545310 -0.726914344  0.53088842  2.36563584  1.04666752\nsit28 -0.41956768  0.082819918 -0.208124105  1.55161291 -1.25349435 -0.73110448",
    "crumbs": [
      "Solutions",
      "Multivariate methods"
    ]
  },
  {
    "objectID": "content/solutions/1_Getting_used_to_R_solutions.html",
    "href": "content/solutions/1_Getting_used_to_R_solutions.html",
    "title": "Getting used to R",
    "section": "",
    "text": "Overview\nThe focus of this overview is to get you used to tools we will be using in class. Before completing it you should have a basic understanding of using R. We will do an introduction in class (download help file). You should also be comfortable using Rstudio and github (see help file).\n\nRmd basics\nRmd files differ from R files in that they combine regular text with code chunks. This is a code chunk\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nCode chunks combine code with output. When combined with regular text/prose, this makes it easier to produce a range of documents. You set the output in the YAML header (the stuff between the 3 dashes you see at top of this document).\nAfter you write the file, you Knit it to turn the Rmd file into the selected output. Try it now. Note the first time you do this in a project you may be prompted to install a number of packages! If you are using a webservice you may also need to allow pop-ups in your browser. Don’t be surprised if a new window pops up (it should).\n\n\n\nThe knit button turns your .rmd file into other products\n\n\nThe Knit button saves the .Rmd file and renders a new version whose output depends on what you selected in the header. Here we have html_document, so if everything works a preview of a webpage like document should appear. The file also produces a github friendly .md file. This means you should only edit the Rmd file (leave the md and output files alone! They are automatically produced any changes you make there will be overwritten by your next knit).\nWhen you Knit a file, it runs in a totally new R instance. this means anything you only added in your instance (like working in the console) won’t be available. In other words, its the best way to see what a “new” user gets when they use your code.\nhowever, you don’t have to knit the file every time. if you just want to see output, note you can press the green button next to an R chunk.\n\n\n\nThe green arrows just runs the chunk in the console and shows the output\n\n\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nNow we’ll start changing the file to show you how rmarkdown works. First, amend the file by replacing the NAME and DATE spots in the header (top of the file between the — markers) with your name and the real date. Then Knit the file again. You should see your name in the new preview.\nRstudio has a Markdown Quick Reference guide (look under the help tab), but some general notes.\n\nPound/Hashtag signs denote headers\nyou can surround something double asterisks for bold or single asterisks for italics\nlists are denoted by numbers or asterisks at beginning of line (followed by space!)\n\nand can be indented for sublevels\n\nR code can be done inline, but is generally placed in stand-alone chunks\n\nthese will, by default, show the code and output\n\nlots of other options exist!\n\nThe main idea is Rmd files allow you to combine code, text, graphs, etc into multiple outputs that you can share (including with coding illiterate colleagues who just want output).\nTo practice working with Rmd files and R, work through the questions below. You can also get more help with this video\n\n\n\nPractice in R\n\n1\nLet x be defined by\n\nx &lt;- 5:15\n\nTry executing this chunk (in R studio, not the webview) by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter.\nThis will run the code in the Console. You may need to switch to Console (from Rmarkdown) in the lower right window area to see this. The executed code is also displayed in your processed file (hit Knit again to see this!).\nNote running this chunk has added an object named x to the Environment tab area (top right area of screen). But nothing was “returned” in the console. You prove this by typing x in the console. What does it return?\nDetermine what the “:” does! Complete the following sentence:\n\nx &lt;- 5:15\n\nThe : means “create a sequence counting by 1’s from a to b (in a:b)”.\n\n\n2\nNow try to guess the output of these commands\n\nlength(x)\nmax(x)\nx[x &lt; 5]\nx^2\nx[ x &lt; 8 & x &gt; 2]\n\nINSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. Then state what each of these does.\n\nlength(x)\n\n[1] 11\n\nmax(x)\n\n[1] 15\n\nx[x &lt; 5]\n\ninteger(0)\n\nx^2\n\n [1]  25  36  49  64  81 100 121 144 169 196 225\n\nx[ x &lt; 8 & x &gt; 2]\n\n[1] 5 6 7\n\n\nLength of x returns the number of elements in a vector. max returns the highest value. square brackets allows you to return (or work with) only portions of a vector. ^2 squares a value.\n\n\n3\nIs -1:2 the same as (-1):2 or -(1:2)? INSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Then state what each of these does.\n\n-1:2\n\n[1] -1  0  1  2\n\n(-1):2\n\n[1] -1  0  1  2\n\n-(1:2)\n\n[1] -1 -2\n\n\nThe first creates a sequence from -1 to 2 by ones (see question 1). The second does the same. The third creates a sequence from 1 to 2 then applies a negative to it.\n\n\n\nData input, plotting, and tests\nYou can read in a dataset from the internet following this protocol.\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nRun this chunk and note it has added an object named sleep to the environment.\nMake sure you see the object in the environment tab!\nInfo on the dataset is viewable @ http://www.statsci.org/data/general/sleep.html.\n\n4\nHow many rows does the sleep data set have (hint: ?dim)? What kind of data is stored in each variable?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\ndim(sleep)\n\n[1] 62 12\n\n\ndim returns the number of rows and columns (IN THAT ORDER) in a dataframe! So sleep has 62 rows. NOTE: If you look at the .Rmd code here, you can see how to put R output inline (instead of in chunks).\n\nstr(sleep)\n\n'data.frame':   62 obs. of  12 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nthe str function returns the size of the dataset and the class of each column. Note how we use the the $ notation to select columns.\n\n\n5\nChange the column named BodyWt to Body_weight”* in the sleep dataset.\nADD ANY R CHUNKS YOU USED TO COMPLETE THE TASK.\n\nnames(sleep)[names(sleep) %in% \"BodyWt\"] &lt;- \"Body_weight\"\n\n\n\n6\nProduce a plot of how TotalSleep differs between primates and other species. What is this plot showing?\nNote, as of early 2020 R no longer reads in strings as factors! This means the Primate column, which is full of “Yes”s and “No”s, reads in as words and R doesn’t know how to plot them. There are many ways to handle this. You can modify the read.csv command (add stringsAsFactors = T option), eg*\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nIf you do this, you’ll need to rechange anything you previously updated to the object (like renaming the BodyWt column).\nYou can also modify a single column for the actual object\n\nsleep$Primate &lt;- factor (sleep$Primate)\n\nor for a single command, eg (plot not actually shown!)\n\nplot(BodyWt ~ factor(Primate), data = sleep)\n\nNOTE YOU CAN ADD A PLOT TO THE DOCUMENT TOO! AMEND THE BELOW AS NEEDED.\n\nplot(cars)\n\n\n\n\n\n\n\n\nAnswer is\n\nplot(TotalSleep ~ Primate, sleep)\n\n\n\n\n\n\n\n\nor to clean it up (we’ll introduce ggplot2 in a few sessions to help with this)\n\nplot(TotalSleep ~ factor(Primate), sleep, main = \"Variance in sleep differs between primates and non-primates\", \n     xlab = \"Primate\", ylab = \"Total sleep (hours)\")\n\n\n\n\n\n\n\n\n\n\n7\nThe sleep dataset begs to have a linear model fit for it. Let’s consider. First plot how TotalSleep is explained by BrainWt. Are there any issues with the data? Exclude any outlier and fit a linear model to obtain the p-value for the model (hint: summary()). What does this imply?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\nFirst look for outliers (before fitting a model)\n\nplot(TotalSleep ~ BrainWt, sleep)\n\n\n\n\n\n\n\n\nWe have few measurements where BrainWt &gt;1000, so let’s exclude those for the model\n\nsleep_fit &lt;- lm(TotalSleep ~ BrainWt, sleep[sleep$BrainWt&lt;1000,])\nsummary(sleep_fit)\n\n\nCall:\nlm(formula = TotalSleep ~ BrainWt, data = sleep[sleep$BrainWt &lt; \n    1000, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.0342 -2.8719  0.1718  2.0426  7.8037 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.099991   0.632611  19.127  &lt; 2e-16 ***\nBrainWt     -0.014926   0.003833  -3.894 0.000278 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 53 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.2224,    Adjusted R-squared:  0.2078 \nF-statistic: 15.16 on 1 and 53 DF,  p-value: 0.0002782\n\n\nWe see a significant (p &lt;.05, don’t worry, we’ll see this later) relationship between BrainWt and TotalSleep, and it appears that TotalSleep decreases as BrainWt increases (note the negative estimate). We can visualize this using\n\nplot(TotalSleep ~ BrainWt, data = sleep[sleep$BrainWt &lt;  1000, ])\nabline(sleep_fit)\n\n\n\n\n\n\n\n\n\n\n\nEXTRA QUESTIONS\nnot required\n Dow Puffin Matthew Zalewski / CC BY (https://creativecommons.org/licenses/by/3.0)\n\n8\nSometimes data doesn’t have headers (column names),so you have to add them. Download a dataset on alcids (birds like puffins and auklets) from https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv.\nYou’ll need to modify the read.csv function by specifying header = False, then use the names function to name the columns [“year”, “a1_abund”, “NAO”, “a2_abund”, “a3_abund”, “a4_abund”, “a5_abund”, “a6_abund”]. Try it and check your input using the head command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\nalcids &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv\",header = F, stringsAsFactors = T)\nnames(alcids) &lt;- c(\"year\", \"a1_abund\", \"NAO\", \"a2_abund\", \"a3_abund\", \"a4_abund\", \"a5_abund\", \"a6_abund\")\nhead(alcids)\n\n  year a1_abund   NAO a2_abund a3_abund a4_abund a5_abund a6_abund\n1 1954       55 -2.52      100        1        0        8        0\n2 1955       44 -1.73      100        1        0       10        0\n3 1956       50  1.52      100        1        0        7        1\n4 1957      100 -1.02    18000        2       50        8        0\n5 1958        5 -0.37     1000        2       15       10        0\n6 1959      400 -1.54     1500        3      190        6        3\n\n\n\n\n9\nHere’s a sample dataset:\n\n\n\nDate\ngreenness\nRichness\nhabitat\n\n\n\n\n12-25-2009\n13766\n46\nforest\n\n\n01-01-2010\n50513\n60\nforest\n\n\n01-15-2010\n25084\n60\ngrassland\n\n\n\nEnter it into R (manually or via a .csv). (Hint: you have a piece of this in the code already). Check your input using the head() command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\nI did this by putting the data in a spreadsheet, saving it as a .csv file, and uploading it. You can see an example spreadsheet at https://docs.google.com/spreadsheets/d/1nOpd6QkJRG8tdn1b-Mmx8AVdwUIFAzzLw3SlJGb_LWA/edit?usp=sharing. From there you can download the file OR publish it to the web as a .csv (look under File &gt; Publish to web in the Google Sheets), and then read in the .csv file to R. Note I used stringAsFactors = T to have the habitat column read in as factors.\n\nexample_sheet &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRsRUBNxda2SEyfti8fAlGLbXjilR1SWYdmkOh1ZEIhadaqwkH6fP9aoWSPgIQEh0dd0isOxONTeAQc/pub?gid=0&single=true&output=csv\",\n                          stringsAsFactors = T)\n\nWarning in read.table(file = file, header = header, sep = sep, quote = quote, :\nincomplete final line found by readTableHeader on\n'https://docs.google.com/spreadsheets/d/e/2PACX-1vRsRUBNxda2SEyfti8fAlGLbXjilR1SWYdmkOh1ZEIhadaqwkH6fP9aoWSPgIQEh0dd0isOxONTeAQc/pub?gid=0&single=true&output=csv'\n\n# so you can see it\nhead(example_sheet)\n\n        Date greenness Richness   habitat\n1 12-25-2009     13766       46    forest\n2 01-01-2010     50513       60    forest\n3 01-15-2010     25084       60 grassland",
    "crumbs": [
      "Solutions",
      "Getting used to R"
    ]
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#overview",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#overview",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Hypothesis testing starting with binomial tests lecture.",
    "crumbs": [
      "Solutions",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#hypothesis-testing-and-the-binomial-distribution",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#hypothesis-testing-and-the-binomial-distribution",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Hypothesis Testing and the Binomial Distribution",
    "text": "Hypothesis Testing and the Binomial Distribution\n\nExample\nUsing the bat paper from class (Geipel et al. 2021), let’s consider how to analyze data showing all 10 bats chose the walking over the motionless model.\n\nbinom.test(10,10)\n\n\n    Exact binomial test\n\ndata:  10 and 10\nnumber of successes = 10, number of trials = 10, p-value = 0.001953\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6915029 1.0000000\nsample estimates:\nprobability of success \n                     1 \n\n\nWe use the binom.test function. We only need arguments for # of succeses and # of trials. By default it runs a 2-sided test against a null hypothesis value of p = .5. You can see how to update thee options by looking at the help file.\n\n?binom.test\n\nNote the confidence interval is assymetric since its estimated to be 1! We can see other options using the binom.confint function from the binom package.\n\nlibrary(binom)\nbinom.confint(10,10)\n\n          method  x  n      mean     lower    upper\n1  agresti-coull 10 10 1.0000000 0.6791127 1.043355\n2     asymptotic 10 10 1.0000000 1.0000000 1.000000\n3          bayes 10 10 0.9545455 0.8292269 1.000000\n4        cloglog 10 10 1.0000000 0.6915029 1.000000\n5          exact 10 10 1.0000000 0.6915029 1.000000\n6          logit 10 10 1.0000000 0.6915029 1.000000\n7         probit 10 10 1.0000000 0.6915029 1.000000\n8        profile 10 10 1.0000000 0.7303058 1.000000\n9            lrt 10 10 1.0000000 0.8252466 1.000000\n10     prop.test 10 10 1.0000000 0.6554628 1.000000\n11        wilson 10 10 1.0000000 0.7224672 1.000000\n\n\nAll of these correct for the fact that most intervals use a normal approximation, which as you remember from our earlier discussions is not good when sample sizes are small and/or the p parameter is extreme (close to 0 or 1).",
    "crumbs": [
      "Solutions",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#practice",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#practice",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Practice!",
    "text": "Practice!\nMake sure you are comfortable with null and alternative hypotheses for all examples.\n\n1\nAre people eared (do they prefer one ear or another)? Of 25 people observed while in conversation in a nightclub, 19 turned their right ear to the speaker and 6 turn their left ear to the speaker. How strong is the evidence for eared-ness given this data (adapted from Analysis of Biological Data)? * state a null and alternative hypothesis + Ho: proportion of right-eared people is equal to .5 + Ha: proportion of right-eared people is note equal to .5\n\ncalculate a test statistic (signal) for this data\n\n\n19/25 #sample proportion\n\n[1] 0.76\n\n\nThe signal from the data is the proportion of right-eared people 0.76\n\nMake you understand how to construct a null distribution\n\nusing sampling/simulation (code or written explanation)\n\n\n\nsampling_experiment = rbinom(10000, 25, .5)\nhist(sampling_experiment, breaks = 0:25, xlab = \"# of Right-eared people out of 25\", ylab = \"Probability of being drawn \\n from population of p = 0.5\", cex.main = 2, cex.axis = 1.5, cex.lab = 2)\n\n\n\n\n\n\n\n\n\nby using an appropriate distribution (code or written explanation)\n\n\nusing_distribution = dbinom(0:25,25,.5)\nusing_distribution\n\n [1] 2.980232e-08 7.450581e-07 8.940697e-06 6.854534e-05 3.769994e-04\n [6] 1.583397e-03 5.277991e-03 1.432598e-02 3.223345e-02 6.088540e-02\n[11] 9.741664e-02 1.328409e-01 1.549810e-01 1.549810e-01 1.328409e-01\n[16] 9.741664e-02 6.088540e-02 3.223345e-02 1.432598e-02 5.277991e-03\n[21] 1.583397e-03 3.769994e-04 6.854534e-05 8.940697e-06 7.450581e-07\n[26] 2.980232e-08\n\nsum(using_distribution)\n\n[1] 1\n\nNumber_righteared = c(0:25)\npdf = data.frame(Number_righteared, using_distribution)\nplot(0:25, using_distribution)\n\n\n\n\n\n\n\n\nEach of these show the expected distribution of signal under the null hypothesis. Note this implies multiple samples are taken. This is theory that underlies NHST (null hypothesis significance testing) and definition of p-value (coming up!).\n\nCalculate and compare p-values obtained using\n\nsimulation (calculation won’t be required on test, but make sure you understand!) (code or written explanation)\n\n\n\nlength(sampling_experiment[sampling_experiment &gt;= 19 | sampling_experiment &lt;= 6])/length(sampling_experiment)\n\n[1] 0.0148\n\n\n\nequations for binomial distribution (code or written explanation)\n\n\n(1-pbinom(18,25,.5)) * 2\n\n[1] 0.0146333\n\n\n\nR functions (required)(code)\n\n\nbinom.test(19,25, p=.5)\n\n\n    Exact binomial test\n\ndata:  19 and 25\nnumber of successes = 19, number of trials = 25, p-value = 0.01463\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.5487120 0.9064356\nsample estimates:\nprobability of success \n                  0.76 \n\n\nNote we can calculate a p-value using the simulated distribution, the actual distribution (which is exact in this case), and the test (which is usign the actual distribution!).\n\nCalculate a 95% confidence interval for the proportion of people who are right-eared\n\n\nlibrary(binom)\nbinom.confint(x=19, n=25, alpha=.05, method=\"all\") #use Agresti-coull \n\n          method  x  n mean     lower     upper\n1  agresti-coull 19 25 0.76 0.5624805 0.8882596\n2     asymptotic 19 25 0.76 0.5925865 0.9274135\n3          bayes 19 25 0.75 0.5854415 0.9037771\n4        cloglog 19 25 0.76 0.5420481 0.8842776\n5          exact 19 25 0.76 0.5487120 0.9064356\n6          logit 19 25 0.76 0.5584422 0.8880044\n7         probit 19 25 0.76 0.5666202 0.8934027\n8        profile 19 25 0.76 0.5724026 0.8967715\n9            lrt 19 25 0.76 0.5724301 0.8968455\n10     prop.test 19 25 0.76 0.5447916 0.8984194\n11        wilson 19 25 0.76 0.5657032 0.8850369\n\n#or\nbinom.confint(x=19, n=25, alpha=.05, method=\"agresti-coull\")\n\n         method  x  n mean     lower     upper\n1 agresti-coull 19 25 0.76 0.5624805 0.8882596\n\n\nOur 95% CI is .562 - .888. Note it does not include .5!\n\nHow do your 95% confidence interval and hypothesis test compare?\n\nThe p-value from all methods are &lt;.05, so I reject the null hypothesis that the proportion of right-eared people is equal to .5. The 95% 5% CI is .562 - .888. Note it does not include .5!\n\n\n2\nA professor lets his dog take every multiple-choice test to see how it compares to his students (I know someone who did this). Unfortunately, the professor believes undergraduates in the class tricked him by helping the dog do better on a test. It’s a 100 question test, and every questions has 4 answer choices. For the last test, the dog picked 33 questions correctly. How likely is this to happen, and is there evidence the students helped the dog?\nMAKE SURE TO THINK ABOUT YOUR TEST OPTIONS\n\n#use sided test as you only care if students helped the dog\nbinom.test(33,100, alternative=\"greater\", p=.25)\n\n\n    Exact binomial test\n\ndata:  33 and 100\nnumber of successes = 33, number of trials = 100, p-value = 0.0446\nalternative hypothesis: true probability of success is greater than 0.25\n95 percent confidence interval:\n 0.2523035 1.0000000\nsample estimates:\nprobability of success \n                  0.33 \n\n\nI chose to use a sided test since the professor wants to know if the students helped the dog.\nI found a p-value of .04, so I reject the null hypothesis that the proportion of correct answers is .25 (what I would expect by chance).",
    "crumbs": [
      "Solutions",
      "Hypothesis testing starting with binomial tests"
    ]
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html",
    "href": "content/solutions/5_Contingency_analysis_solutions.html",
    "title": "Compare proportions among groups",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html#overview",
    "href": "content/solutions/5_Contingency_analysis_solutions.html#overview",
    "title": "Compare proportions among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare proportions among groups lecture.",
    "crumbs": [
      "Solutions",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html#examples",
    "href": "content/solutions/5_Contingency_analysis_solutions.html#examples",
    "title": "Compare proportions among groups",
    "section": "Examples",
    "text": "Examples\nIssue is we often get data in spreadsheet format (expanded/long or wide/summarized, each shown below), but we need to get a vector or matrix for chisq.test and related functions.\n\nThe data\nFollowing the Everest example from class. Assume data is in a dataframe where each row is a group data point.\n\neverest &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\"),\n                      Oxygen = c(\"Used\", \"Used\", \"Not used\", \"Not used\"),\n                      Number = c(1045, 32, 88, 8))\n\nAssume data is in a dataframe where each row is an individual data point.\n\nlibrary(mirt)\neverest_expand &lt;- expand.table(everest)\n\n\n\ntests\nFirst, let’s ask if the same amount of people used or did not use oxygen. WE can use the table command to summarize. Note the chisq.test, by default, assumes each group is equally likely!\n\ntable(everest_expand$Oxygen)\n\n\nNot used     Used \n      96     1077 \n\nchisq.test(table(everest_expand$Oxygen)) \n\n\n    Chi-squared test for given probabilities\n\ndata:  table(everest_expand$Oxygen)\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nDong this with summarized data is actually harder\n\naggregate(Number~Oxygen, everest, sum)$Number\n\n[1]   96 1077\n\nchisq.test(aggregate(Number~Oxygen, everest, sum)$Number) \n\n\n    Chi-squared test for given probabilities\n\ndata:  aggregate(Number ~ Oxygen, everest, sum)$Number\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nBut this is better!\n\nbinom.test(table(everest_expand$Oxygen))\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we wanted to compare to past years where 10% of climbers did not use oxygen? Note table function splits into alphabetical order.\n\nbinom.test(table(everest_expand$Oxygen), p=.1)\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value = 0.04075\nalternative hypothesis: true probability of success is not equal to 0.1\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we want to determine if using oxygen impacts surival?\n\nchisq.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\nWarning in chisq.test(table(everest_expand$Oxygen, everest_expand$Survived)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nIssue (which we’ll address), but note same as\n\nchisq.test(table(everest_expand$Survived, everest_expand$Oxygen))\n\nWarning in chisq.test(table(everest_expand$Survived, everest_expand$Oxygen)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Survived, everest_expand$Oxygen)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 32, 88,  8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nKey is first argument must be all the info. This is different from (incorrect) approach like\n\nchisq.test(everest$Survived,everest$Oxygen)\n\nWarning in chisq.test(everest$Survived, everest$Oxygen): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  everest$Survived and everest$Oxygen\nX-squared = 0, df = 1, p-value = 1\n\n\nThis is comparing split among Survived and not to split (expected) using Oxygen!\nSo order has minimal input with 2 groups. Other test options necessitated by the warning\n\nfisher.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\np-value = 0.01284\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 1.144791 6.826869\nsample estimates:\nodds ratio \n  2.964765 \n\nlibrary(DescTools)\nGTest(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nG = 5.7466, X-squared df = 1, p-value = 0.01652\n\n\nWhat if we added another group? Like Enriched, Regular, None for oxygen.\n\neverest_enriched &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\", \"Y\", \"N\"),\n                      Oxygen = c(\"Regular\", \"Regular\", \"None\", \"None\", rep(\"Enriched\", 2)),\n                      Number = c(1045, 32, 88, 8, 15, 2))\neverest_enriched_expand &lt;- expand.table(everest_enriched)\n\nNow we compare\n\ntable(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\n\n   \n    Enriched None Regular\n  N        2    8      32\n  Y       15   88    1045\n\nchisq.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(table(everest_enriched_expand$Survived,\neverest_enriched_expand$Oxygen)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\nX-squared = 10.879, df = 2, p-value = 0.004343\n\n\nFisher again due to size\n\nfisher.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\np-value = 0.00586\nalternative hypothesis: two.sided\n\n\nNow we follow-up, and rows/columns matter. Note default is row and fdr method. I order results for ease of view\n\nlibrary(rcompanion)\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n  Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq p.adj.Chisq\n1      N : Y  0.00586      0.00586  0.0189      0.0189 0.00434     0.00434\n\n\nNot quite what we wanted. How about\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1430  0.1080      0.1620  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.2560\n1      1.0000\n\n\nand you can change methods\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\",\n                                                          method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1910  0.1080      0.2160  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.3420\n1      1.0000\n\n\nTo put in manually, we need a few extra things\n\neverest_table &lt;- as.table(matrix(c(2,8,32,15,88,1045), nrow = 2, byrow = T))\nrownames(everest_table) = c(\"N\", \"Y\")\ncolnames(everest_table) = c(\"Enriched\", \"None\", \"Regular\")\neverest_table\n\n  Enriched None Regular\nN        2    8      32\nY       15   88    1045",
    "crumbs": [
      "Solutions",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html#lets-practice",
    "href": "content/solutions/5_Contingency_analysis_solutions.html#lets-practice",
    "title": "Compare proportions among groups",
    "section": "Let’s practice",
    "text": "Let’s practice\n\nHeart attacks\n\n1\nLet’s look at some heart attack data. Read in the data using\n\nheart_attacks &lt;- read.table(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/heartatk4R.txt\",header=T, stringsAsFactors = T)\n\nEvery entry is a person that has suffered a heart attack. More information on the dataset can be found at\nhttp://statland.org/Software_Help/DataDesk/datafile.htm\nWe want to again test if heart attacks occur equally across genders.\n\ntable(heart_attacks$SEX)\n\n\n   F    M \n5065 7779 \n\nbinom.test(7779, 7779+5065)\n\n\n    Exact binomial test\n\ndata:  7779 and 7779 + 5065\nnumber of successes = 7779, number of trials = 12844, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.5971385 0.6141184\nsample estimates:\nprobability of success \n             0.6056524 \n\n\nIf I assume males compose 50% of the population, I can test the null hypothesis that 50% of heart attacks occur in males using a binom.test to conduct a binomial test. I used the table command to determine the number of heart attacks in males and females and then used binom.test. The alternative is less than or greater than 50% of hear attacks occur in males. With a p-value of &lt;.001, I reject the null hypothesis. Data suggest that males are more likely to have heart attacks. Note this is better than\n\nchisq.test(table(heart_attacks$SEX), p=c(.50, .50))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(heart_attacks$SEX)\nX-squared = 573.48, df = 1, p-value &lt; 2.2e-16\n\n\nwhich is an approximate test.\n\nWhat if we know that males actually make up 50.8% of the population?\n\n\ntable(heart_attacks$SEX)\n\n\n   F    M \n5065 7779 \n\nbinom.test(7779, 7779+5065, .508)\n\n\n    Exact binomial test\n\ndata:  7779 and 7779 + 5065\nnumber of successes = 7779, number of trials = 12844, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.508\n95 percent confidence interval:\n 0.5971385 0.6141184\nsample estimates:\nprobability of success \n             0.6056524 \n\n\nNote I can amend the test proportion as noted here. Results do not change.\n\n\n2\nStill using the heart attack data, is survival independent of gender?\n\n#note what this does\ntable(heart_attacks$SEX, heart_attacks$DIED)\n\n   \n       0    1\n  F 4298  767\n  M 7136  643\n\n#then feed it to chisq.test (notice order here does not matter for 2x2 table)\nchisq.test(table(heart_attacks$SEX, heart_attacks$DIED))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks$SEX, heart_attacks$DIED)\nX-squared = 147.76, df = 1, p-value &lt; 2.2e-16\n\nchisq.test(table(heart_attacks$DIED, heart_attacks$SEX))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks$DIED, heart_attacks$SEX)\nX-squared = 147.76, df = 1, p-value &lt; 2.2e-16\n\n\nI used a chi2 to consider if survival was independent of sex. Our null hypothesis is that survival does not differ based on sex. the alternative is that it does. I found a chi21=147.76, which corresponds to a p-value of &lt;.001, so i reject the null hypothesis.\n\n\n3\nFor people that have a heart attack before they turn 30, is survival independent of gender?\n\nchisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                 heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))\n\nWarning in chisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], :\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], heart_attacks[heart_attacks$AGE &lt;     30, \"DIED\"])\nX-squared = 3.2597e-30, df = 1, p-value = 1\n\n#note warning on approximation, so check it\nchisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                 heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))$expected\n\nWarning in chisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], :\nChi-squared approximation may be incorrect\n\n\n   \n       0   1\n  F  7.8 0.2\n  M 31.2 0.8\n\n#several &lt;1, so use fisher.test\nfisher.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                  heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], heart_attacks[heart_attacks$AGE &lt; 30, \"DIED\"])\np-value = 1\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.006425781         Inf\nsample estimates:\nodds ratio \n       Inf \n\n#so if you are young, no difference\n\nI amended the previous question’s code to only focus on individuals who were under the age of 30 when they suffered a heart. Otherwise the hypotheses remain the same. I attempted to use a chi2 test but was warned the approximation may be incorrect. Remember that no cells can have expected values of &lt;1 and &lt;20% should have expected values &lt;5. Upon checking 2 cells have expected values &lt;1, so I instead used Fisher’s Test.\nI found a p-value of 1, thus I fail to reject the null hypothesis.\n\n\n\nDolphins\n\n4\nData on dolphin behavior was collected off the coast of Iceland. Data is @\nhttp://www.statsci.org/data/general/dolpacti.txt\nSince this is a .txt file, not a .csv, you’ll need to use something like\n\ndolphin &lt;- read.table(\"http://www.statsci.org/data/general/dolpacti.txt\", sep=\"\", header = T, stringsAsFactors = T)\n\nMore info on data @\nhttp://www.statsci.org/data/general/dolpacti.html\nIs traveling independent of time of day? You’ll need to consider traveling vs not traveling due to different number of groups observed in each period. Carry out post-hoc tests if needed.\nI looked at the data and then just made a table manually\n\ndolphin\n\n   Activity    Period Groups\n1    Travel   Morning      6\n2      Feed   Morning     28\n3    Social   Morning     38\n4    Travel      Noon      6\n5      Feed      Noon      4\n6    Social      Noon      5\n7    Travel Afternoon     14\n8      Feed Afternoon      0\n9    Social Afternoon      9\n10   Travel   Evening     13\n11     Feed   Evening     56\n12   Social   Evening     10\n\ntravel_table &lt;- as.table(matrix(c(6, 28+ 38, 6, 9, 14, 9, 13, 66), nrow = 4, byrow = T))\n#Adding in row and column names will make everything easier to read at end.\ncolnames(travel_table) = c(\"travel\", \"not_travel\")\nrownames(travel_table) = c(\"morning\", \"noon\", \"afternoon\", \"night\")\n#now look at it\ntravel_table\n\n          travel not_travel\nmorning        6         66\nnoon           6          9\nafternoon     14          9\nnight         13         66\n\nchisq.test(travel_table)\n\nWarning in chisq.test(travel_table): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  travel_table\nX-squared = 33.665, df = 3, p-value = 2.331e-07\n\n#check outcome given warning\nchisq.test(travel_table)$expected\n\nWarning in chisq.test(travel_table): Chi-squared approximation may be incorrect\n\n\n             travel not_travel\nmorning   14.857143   57.14286\nnoon       3.095238   11.90476\nafternoon  4.746032   18.25397\nnight     16.301587   62.69841\n\nfisher.test(travel_table)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  travel_table\np-value = 9.192e-07\nalternative hypothesis: two.sided\n\nlibrary(rcompanion)\npairwiseNominalIndependence(travel_table, compare = \"row\", method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\n\n           Comparison p.Fisher p.adj.Fisher  p.Gtest p.adj.Gtest  p.Chisq\n1      morning : noon 4.96e-03     1.98e-02 3.94e-03    1.58e-02 4.74e-03\n2 morning : afternoon 7.88e-07     4.73e-06 4.01e-07    2.41e-06 3.65e-07\n3     morning : night 1.49e-01     2.98e-01 1.28e-01    2.56e-01 2.09e-01\n4    noon : afternoon 3.20e-01     3.20e-01 2.07e-01    2.56e-01 3.54e-01\n5        noon : night 7.22e-02     2.17e-01 5.16e-02    1.55e-01 8.35e-02\n6   afternoon : night 6.83e-05     3.42e-04 4.98e-05    2.49e-04 6.88e-05\n  p.adj.Chisq\n1    1.90e-02\n2    2.19e-06\n3    4.18e-01\n4    4.18e-01\n5    2.50e-01\n6    3.44e-04\n\n\nI tested the null hypothesis that traveling is independent of time of day (compared to the alternative hypothesis that it is not, and thus differs aross time periods) using chi2 test. However, a warning and subsequent check indicated too many cells had low expected values, so I instead used a Fisher’s test. A resulting p-value of &lt;.001 led me reject the null hypothesis. Since I was comparing more than two groups, I used a post-hoc test to see which periods were different and found that travel differed between morning and noon, morning and afternoon, and afternoon and night (using the p.adj.Fisher column).\n\n\n\nSmoking\n\n5\nUse data on smoking and exercise from\nhttp://www.r-tutor.com/elementary-statistics/goodness-fit/chi-squared-test-independence\nto determine if smoking is independent of exercise. You’ll need to input data manually. Carry out post-hoc tests if needed.\nI created a table from the data and tested it using a chi2 test to determine if smoking was independent of exercise (null hypothesis) or differed based on exercise levels (alternative). However, a warning led me to see the expected cell values were too small, so I instead used a Fisher’s test.\n\nsmoke &lt;- chisq.test(matrix(c(7, 1, 3, #spacing just for visual use\n                             87,18,84,\n                             12,3,4,\n                             9,1,7), nrow = 4, byrow = T))\n\nWarning in chisq.test(matrix(c(7, 1, 3, 87, 18, 84, 12, 3, 4, 9, 1, 7), :\nChi-squared approximation may be incorrect\n\nsmoke$expected #too small!\n\n          [,1]      [,2]      [,3]\n[1,]  5.360169  1.072034  4.567797\n[2,] 92.097458 18.419492 78.483051\n[3,]  9.258475  1.851695  7.889831\n[4,]  8.283898  1.656780  7.059322\n\nfisher.test(matrix(c(7, 1, 3, #spacing just for visuals\n                     87,18,84,\n                     12,3,4,\n                     9,1,7), nrow = 4, byrow = T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(7, 1, 3, 87, 18, 84, 12, 3, 4, 9, 1, 7), nrow = 4, byrow = T)\np-value = 0.4138\nalternative hypothesis: two.sided\n\n\nA p-value of .4138 meant I failed to reject the null hypothesis.",
    "crumbs": [
      "Solutions",
      "Compare proportions among groups"
    ]
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html",
    "href": "content/solutions/7_More_ANOVAs_solutions.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#overview",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#overview",
    "title": "More ANOVAs",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the More ANOVAs lecuture.",
    "crumbs": [
      "Solutions",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#examples",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#examples",
    "title": "More ANOVAs",
    "section": "Examples",
    "text": "Examples\n\nIf interaction is significant\nFollowing the memory example from class, read in and check data\n\nmemory &lt;- read.table(\"http://www.statsci.org/data/general/eysenck.txt\", header = T,\n                     stringsAsFactors = T)\nstr(memory)\n\n'data.frame':   100 obs. of  3 variables:\n $ Age    : Factor w/ 2 levels \"Older\",\"Younger\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Process: Factor w/ 5 levels \"Adjective\",\"Counting\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Words  : num  8 6 4 6 7 6 5 7 9 7 ...\n\n\nLet’s put younger level first\n\nlibrary(plyr)\nmemory$Age &lt;- relevel(memory$Age, \"Younger\")\n\nand graph\n\nlibrary(Rmisc)\nfunction_output &lt;- summarySE(memory, measurevar=\"Words\", groupvars =\n                               c(\"Age\", \"Process\"), na.rm = T)\nlibrary(ggplot2)\nggplot(function_output, aes(x=Age, y=Words,color=Process, \n                                   shape = Process)) +\n  geom_line(aes(group=Process, linetype = Process), size=2) +\n    geom_point(size = 5) +\n  ylab(\"Words remembered\")+ \n  xlab(\"Age\") + \n  ggtitle(\"Process type interacts with age to impact memory\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nThere appears to be some interactions. Let’ build a model\n\nmemory_interactions &lt;- lm(Words ~ Age * Process, memory)\n\nand check assumptions.\n\npar(mfrow=c(2,2))\nplot(memory_interactions)\n\n\n\n\n\n\n\n\nThese appear to be met, so look at output\n\nlibrary(car)\nAnova(memory_interactions, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 272.9281 &lt; 2.2e-16 ***\nAge           72.2  1   8.9963 0.0034984 ** \nProcess     1353.7  4  42.1690 &lt; 2.2e-16 ***\nAge:Process  190.3  4   5.9279 0.0002793 ***\nResiduals    722.3 90                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince interaction is significant, analyze subsets. For example,\n\nmemory_interactions_young &lt;- lm(Words ~ Process, memory[memory$Age == \"Younger\",])\nplot(memory_interactions_young)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(memory_interactions_young, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 343.442 &lt; 2.2e-16 ***\nProcess     1353.7  4  53.064 &lt; 2.2e-16 ***\nResiduals    287.0 45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant difference in words recalled based on process, but why? Investigate with post-hoc tests.\n\nlibrary(multcomp)\ncomp_young &lt;- glht(memory_interactions_young, linfct = mcp(Process = \"Tukey\"))\nsummary(comp_young)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Words ~ Process, data = memory[memory$Age == \"Younger\", \n    ])\n\nLinear Hypotheses:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \nCounting - Adjective == 0      -8.300      1.129  -7.349  &lt; 0.001 ***\nImagery - Adjective == 0        2.800      1.129   2.479  0.11365    \nIntentional - Adjective == 0    4.500      1.129   3.984  0.00216 ** \nRhyming - Adjective == 0       -7.200      1.129  -6.375  &lt; 0.001 ***\nImagery - Counting == 0        11.100      1.129   9.828  &lt; 0.001 ***\nIntentional - Counting == 0    12.800      1.129  11.333  &lt; 0.001 ***\nRhyming - Counting == 0         1.100      1.129   0.974  0.86545    \nIntentional - Imagery == 0      1.700      1.129   1.505  0.56457    \nRhyming - Imagery == 0        -10.000      1.129  -8.854  &lt; 0.001 ***\nRhyming - Intentional == 0    -11.700      1.129 -10.359  &lt; 0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nBlocking example\nFollowing feather color example from class:\n\n# more than 2? ####\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nstr(feather)\n\n'data.frame':   32 obs. of  3 variables:\n $ Bird       : Factor w/ 16 levels \"A\",\"B\",\"C\",\"D\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Feather    : Factor w/ 2 levels \"Odd\",\"Typical\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Color_index: num  -0.255 -0.213 -0.19 -0.185 -0.045 -0.025 -0.015 0.003 0.015 0.02 ...\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather = \"Special\", \n                      Color_index= feather[feather$Feather == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather &lt;- merge(feather, special, all = T)\n\n\nAnova(lm(Color_index ~ Feather + Bird, data=feather), type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.36392  1  59.9538 1.224e-08 ***\nFeather     1.67906  2 138.3093 7.208e-16 ***\nBird        0.34649 15   3.8055 0.0008969 ***\nResiduals   0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\ncompare &lt;- glht(lm(Color_index ~ Feather + Bird, data=feather), linfct = mcp(\"Feather\" = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather + Bird, data = feather)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nTypical - Odd == 0      0.13712    0.02755   4.978   &lt;1e-04 ***\nSpecial - Odd == 0      0.44712    0.02755  16.232   &lt;1e-04 ***\nSpecial - Typical == 0  0.31000    0.02755  11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n#note comparison doesn't work\nAnova(lm(Color_index ~ Feather * Bird, data=feather), type= \"III\")\n\nError in Anova.lm(lm(Color_index ~ Feather * Bird, data = feather), type = \"III\"): residual df = 0",
    "crumbs": [
      "Solutions",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#practice",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#practice",
    "title": "More ANOVAs",
    "section": "Practice",
    "text": "Practice\n\n1\nA survey was conducted to see if athletes and non-athletes deal with anger in the same way. Data is @\nangry &lt;- read.csv(“https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv”, stringsAsFactors = T)\nand more information is at\nhttp://onlinestatbook.com/case_studies/angry_moods.html.\nFocus on the following variables:\nSports 1 = athletes, 2 = non-athletes Gender 1 = males, 2 = females Expression (AE) index of general anger expression: (Anger-Out) + (Anger-In) - (Control-Out) - (Control-In) + 48\nIs there any evidence that gender or athlete status impact how anger is expressed?\n\nangry &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv\", stringsAsFactors = T)\nstr(angry)\n\n'data.frame':   78 obs. of  7 variables:\n $ Gender          : int  2 2 2 2 1 1 1 2 2 2 ...\n $ Sports          : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Anger.Out       : int  18 14 13 17 16 16 12 13 16 12 ...\n $ Anger.In        : int  13 17 14 24 17 22 12 16 16 16 ...\n $ Control.Out     : int  23 25 28 23 26 25 31 22 22 29 ...\n $ Control.In      : int  20 24 28 23 28 23 27 31 24 29 ...\n $ Anger_Expression: int  36 30 19 43 27 38 14 24 34 18 ...\n\nangry$Gender &lt;- as.factor(angry$Gender)\nlibrary(plyr)\nangry$Gender &lt;- revalue(angry$Gender, c(\"1\" = \"male\", \n                                        \"2\" = \"female\"))\nangry$Sports &lt;- as.factor(angry$Sports)\nangry$Sports &lt;- revalue(angry$Sports, c(\"1\" = \"athlete\",\n                                        \"2\" = \"non-athlete\"))\nlibrary(Rmisc)\nanger_summary &lt;- summarySE(angry, measurevar=\"Anger_Expression\", groupvars =\n                               c(\"Sports\", \"Gender\"), na.rm = T)\nlibrary(ggplot2)\nggplot(anger_summary, aes(x=Gender, y=Anger_Expression, color=Sports, \n                                   shape = Sports)) +\n  geom_point(size = 3) +\n  geom_line(aes(group=Sports, linetype =Sports), size=2) +\n  geom_errorbar(aes(ymin=Anger_Expression-ci, ymax=Anger_Expression+ci), size=1.5) +\n  ylab(\"Anger level\")+ \n  xlab(\"Gender\") + \n  scale_shape_discrete(guide=FALSE)+\n  scale_linetype_discrete(guide=FALSE)+\n  ggtitle(\"Anger level among groups\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\n\n\n\n\n\n\n\n\n\nI first read in and recoded some data for ease and plotting. I then produced a plot to consider the null hypotheses that\n\nthe sport an athlete plays does not influence anger level\nthe gender of an athlete does not influence anger level\nthe sport an athlete plays and their gender do not interact to influence anger level\n\n\nangry_gender &lt;- lm(Anger_Expression ~ Sports * Gender, angry)\nplot(angry_gender)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(angry_gender, type = \"III\")\n\nWarning in printHypothesis(L, rhs, names(b)): one or more coefficients in the hypothesis include\n     arithmetic operators in their names;\n  the printed representation of the hypothesis will be omitted\n\nWarning in printHypothesis(L, rhs, names(b)): one or more coefficients in the hypothesis include\n     arithmetic operators in their names;\n  the printed representation of the hypothesis will be omitted\n\n\nAnova Table (Type III tests)\n\nResponse: Anger_Expression\n               Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   11200.1  1 71.8690 1.617e-12 ***\nSports          480.1  1  3.0807   0.08336 .  \nGender           17.7  1  0.1135   0.73711    \nSports:Gender     5.2  1  0.0336   0.85505    \nResiduals     11532.2 74                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#remove interaction since not significant\nangry_gender &lt;- lm(Anger_Expression ~ Sports + Gender, angry)\nplot(angry_gender)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(angry_gender, type = \"III\") #only differs among those who play sports\n\nWarning in printHypothesis(L, rhs, names(b)): one or more coefficients in the hypothesis include\n     arithmetic operators in their names;\n  the printed representation of the hypothesis will be omitted\n\n\nAnova Table (Type III tests)\n\nResponse: Anger_Expression\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 17367.1  1 112.8964 &lt; 2.2e-16 ***\nSports       1357.2  1   8.8227  0.003995 ** \nGender         16.3  1   0.1061  0.745501    \nResiduals   11537.4 75                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI then analyzed the data using factorial ANOVA. The outcome is continuous and both explanatory variables are categorical. The design is also fully randomized. Resildual plots indicated all assumptions were met (there is no pattern in the residuals and they are normally distributed). Analysis shows an insignificant interaction (F1,74=.04, p=.855) between sport and gender, so I removed the interaction term. The reduced model showed anger levels differed among athletes and non-athletes but not by gender. There was no need for post-hoc tests (only 2 levels/groups for each categorial variable.)\n\n\n2\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at http://www.statsci.org/data/oz/ms212.txt With more info at http://www.statsci.org/data/oz/ms212.html. Is there evidence that frequency of exercise (Exercise column) and gender impact change in pulse rate for students who ran (Ran column = 1)?\n\npulse &lt;- read.table(\"http://www.statsci.org/data/oz/ms212.txt\", header = T, \n                    stringsAsFactors = T)\npulse$Exercise &lt;- factor(pulse$Exercise)\nlibrary(plyr)\npulse$Exercise &lt;- revalue(pulse$Exercise, c(\"1\" = \"high\", \n                                            \"2\" = \"moderate\", \n                                            \"3\" = \"low\"))\npulse$Gender &lt;- factor(pulse$Gender)\npulse$Gender &lt;- revalue (pulse$Gender, c(\"1\" = \"male\", \"2\" = \"female\"))\npulse$change &lt;- pulse$Pulse2 - pulse$Pulse1\nchange_summary &lt;- summarySE(pulse[pulse$Ran == 1, ], measurevar=\"change\", groupvars =\n                               c(\"Exercise\", \"Gender\"), na.rm = T)\n\nWarning in qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced\n\nggplot(change_summary, aes(x=Gender, shape = Exercise, color = Exercise,\n                           y=change)) +\n  geom_point(size = 3) +\n  geom_line(aes(group=Exercise, linetype =Exercise), size=2) +\n  geom_errorbar(aes(ymin=change-ci, ymax=change+ci), size=1.5) +\n  ylab(\"Change in pulse \\n (beats per minute)\") +\n  scale_color_discrete(name = \"Exercise level\")+\n  scale_shape_discrete(guide=FALSE)+\n  scale_linetype_discrete(guide=FALSE)+\n  ggtitle(\"Change in pulse does \\n not differ among groups\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\n\n\n\n\nI first read in and recoded some data for ease and plotting. I then produced a plot to consider the null hypotheses that\n\nexercise level does not influence change in pulse rate\ngender does not influence change in pulse rate\ngender and exercise level do not interact to influence change in pulse rate\n\n\nexercise &lt;- lm(change ~ Gender * Exercise, pulse[pulse$Ran == 1, ])\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Gender * Exercise, data = pulse[pulse$Ran == \n    1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-44.231 -11.300   1.769  10.083  48.444 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     45.000      8.746   5.145 7.44e-06 ***\nGenderfemale                    35.000     23.139   1.513   0.1383    \nExercisemoderate                 9.231     10.573   0.873   0.3879    \nExerciselow                     12.400     12.972   0.956   0.3449    \nGenderfemale:Exercisemoderate  -38.231     24.678  -1.549   0.1292    \nGenderfemale:Exerciselow       -46.844     26.043  -1.799   0.0796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.42 on 40 degrees of freedom\nMultiple R-squared:  0.0828,    Adjusted R-squared:  -0.03185 \nF-statistic: 0.7222 on 5 and 40 DF,  p-value: 0.6107\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n                 Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)     12150.0  1 26.4739 7.444e-06 ***\nGender           1050.0  1  2.2879    0.1383    \nExercise          496.3  2  0.5407    0.5865    \nGender:Exercise  1488.8  2  1.6220    0.2102    \nResiduals       18357.7 40                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#rerun without interaction\nexercise &lt;- lm(change ~ Gender + Exercise, pulse[pulse$Ran == 1, ])\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Gender + Exercise, data = pulse[pulse$Ran == \n    1, ])\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.99 -14.89   2.23  11.91  45.19 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        50.391      8.273   6.091 2.94e-07 ***\nGenderfemale       -2.738      6.770  -0.404    0.688    \nExercisemoderate    3.603      9.572   0.376    0.708    \nExerciselow         1.155     10.617   0.109    0.914    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.74 on 42 degrees of freedom\nMultiple R-squared:  0.008416,  Adjusted R-squared:  -0.06241 \nF-statistic: 0.1188 on 3 and 42 DF,  p-value: 0.9485\n\nAnova(exercise, type = \"III\") #no significance\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 17532.0  1 37.1019 2.937e-07 ***\nGender         77.3  1  0.1636    0.6879    \nExercise       97.1  2  0.1028    0.9025    \nResiduals   19846.5 42                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI then analyzed the data using factorial ANOVA. The outcome is continuous and both explanatory variables are categorical. The design is also fully randomized. Residual plots indicated all assumptions were met (there is no pattern in the residuals and they are normally distributed). Analysis shows an insignificant interaction (F2,40=1.2, p=.21) between exercise level and gender, so I removed the interaction term. The reduced model showed neither gender (F1,42=.16, p =.69) or exercise level (F2,42=.1, p=.90) influenced change in pulse rate, so I failed to reject the related null hypotheses.\n\n\n3\nData from Valdez et al 2023 is available @ https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv.\nImport it into to R and\n\ndetermine how the snail grazing and nitrogen levels impact number of flowering shoots(Shoot.density..m2)\nconstruct a plot to showcase your analysis\n\n\nvaldez_2023 &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv\", stringsAsFactors = T)\nshoot_model &lt;-lm( Shoot.density..m2~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\nplot(shoot_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(shoot_model, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Shoot.density..m2\n                           Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)                196608  1 271.0588 1.334e-09 ***\nSnail.Level                 36238  2  24.9804 5.277e-05 ***\nNitrogen.level               4267  1   5.8824    0.0320 *  \nSnail.Level:Nitrogen.level   3100  2   2.1373    0.1607    \nResiduals                    8704 12                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNo interaction, so I can remove or not.\n\nshoot_model_reduced &lt;- update(shoot_model, .~.- Snail.Level:Nitrogen.level)\nAnova(shoot_model_reduced)\n\nAnova Table (Type II tests)\n\nResponse: Shoot.density..m2\n               Sum Sq Df F value    Pr(&gt;F)    \nSnail.Level     45596  2  27.039 1.556e-05 ***\nNitrogen.level  11150  1  13.224  0.002696 ** \nResiduals       11804 14                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBoth have impacts.\n\nsnail_post_hoc &lt;- glht(shoot_model_reduced, linfct = mcp(Snail.Level = \"Tukey\"))\nsummary(snail_post_hoc)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Shoot.density..m2 ~ Snail.Level + Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nremoval - control snails == 0           50.67      16.76   3.022  0.02306 *  \nsnail addition - control snails == 0   -72.00      16.76  -4.295  0.00201 ** \nsnail addition - removal == 0         -122.67      16.76  -7.317  &lt; 0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nsignificant difference among all snails.\n\nshoot_summary &lt;- summarySE(valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], measurevar = \"Shoot.density..m2\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\"))\nshoot_summary\n\n     Snail.Level Nitrogen.level N Shoot.density..m2        sd        se\n1 control snails     Fertilized 3          256.0000 27.712813 16.000000\n2 control snails        without 3          202.6667  9.237604  5.333333\n3        removal     Fertilized 3          320.0000 16.000000  9.237604\n4        removal        without 3          240.0000 27.712813 16.000000\n5 snail addition     Fertilized 3          165.3333 36.950417 21.333333\n6 snail addition        without 3          149.3333 33.306656 19.229607\n        ci\n1 68.84244\n2 22.94748\n3 39.74620\n4 68.84244\n5 91.78992\n6 82.73832\n\nshoot_summary$Snail.Level &lt;- relevel(shoot_summary$Snail.Level, \"removal\")\nshoot_summary$Snail.Level &lt;- relevel(shoot_summary$Snail.Level, \"uncaged\")\n\n\nggplot(shoot_summary, aes(x=Snail.Level, \n                           y=Shoot.density..m2,\n                           fill=Nitrogen.level)) +\n  geom_col(color=\"black\", position=position_dodge()) +\n  geom_errorbar(aes(ymin=Shoot.density..m2, ymax=Shoot.density..m2+ci), position = position_dodge()) +\n  labs(title=\"Grazing impacts depend on nitrogen levels\",\n       x= \"Grazing level\",\n       y= expression(paste(\"# of shoots/\" ,m^{-2})))\n\n\n\n\n\n\n\n\n\n\n4\nFind an example of a factorial ANOVA from a paper that is related to your work. Make sure you understand the connections between the methods, results, and graphs. Briefly answer the following questions\n\nWhat was the dependent variable?\nWhat were the independent variables?\nWas the interaction significant?\n\nIf so, how did they interpret findings\nIf not, were the main effects significant?",
    "crumbs": [
      "Solutions",
      "More ANOVAs"
    ]
  },
  {
    "objectID": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html",
    "href": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "",
    "text": "Remember you should",
    "crumbs": [
      "Solutions",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html#example",
    "href": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html#example",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Example",
    "text": "Example\nFollowing the iris example from class\n\nset.seed(3)\niris_example_species &lt;-data.frame(\n  Species = c(rep(\"baruch\",25), rep(\"hunter\", 25), rep(\"york\", 25)),\n  Petal_Length = runif(75,2,4 ))\nset.seed(31)\niris_example_species$Sepal_interaction &lt;- \n  iris_example_species$Petal_Length * c(rep(-2, 25),rep(0,25), rep(5,25)) + \n  c(rep(2,25), rep(3,25), rep(4,25)) + rnorm(75)\n\nPlot the data\n\nlibrary(ggplot2)\nggplot(iris_example_species, aes(x= Petal_Length, y = Sepal_interaction, color = Species)) +\n  geom_point()+\n  ylab(\"Sepal Length\") +\n  xlab(\"Petal Length\") +\n  ggtitle(\"Impact of petal length and species on sepal length\") +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nAnalysis would indicate (assumption plots not shown here to allow focus on interpreting interactions)\n\nlibrary(car)\nAnova(lm( Sepal_interaction~ Petal_Length * Species, iris_example_species), \n      type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n                      Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)            7.076  1   8.0267  0.006038 ** \nPetal_Length          38.452  1  43.6177  6.88e-09 ***\nSpecies                3.353  2   1.9015  0.157092    \nPetal_Length:Species 227.334  2 128.9368 &lt; 2.2e-16 ***\nResiduals             60.828 69                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\ninteractions do exist. This means we can’t interpret the “general” relationship, so we need to look for each species using regression.\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"baruch\", ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.7194 -0.5504 -0.1860  0.4736  1.7067 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    2.9734     0.9767   3.044  0.00576 ** \nPetal_Length  -2.3663     0.3335  -7.097 3.14e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8738 on 23 degrees of freedom\nMultiple R-squared:  0.6865,    Adjusted R-squared:  0.6728 \nF-statistic: 50.36 on 1 and 23 DF,  p-value: 3.144e-07\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"baruch\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   7.076  1  9.2676  0.005758 ** \nPetal_Length 38.452  1 50.3604 3.144e-07 ***\nResiduals    17.561 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"hunter\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"hunter\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.89221 -0.58055  0.00876  0.47006  2.49756 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)    1.2564     1.1463   1.096    0.284\nPetal_Length   0.4962     0.3895   1.274    0.215\n\nResidual standard error: 0.9902 on 23 degrees of freedom\nMultiple R-squared:  0.06589,   Adjusted R-squared:  0.02528 \nF-statistic: 1.622 on 1 and 23 DF,  p-value: 0.2155\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"hunter\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value Pr(&gt;F)\n(Intercept)   1.1779  1  1.2014 0.2844\nPetal_Length  1.5907  1  1.6224 0.2155\nResiduals    22.5503 23               \n\nsummary(lm(Sepal_interaction ~ Petal_Length, \n           iris_example_species[iris_example_species$Species == \"york\",]))\n\n\nCall:\nlm(formula = Sepal_interaction ~ Petal_Length, data = iris_example_species[iris_example_species$Species == \n    \"york\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.45150 -0.69660  0.02717  0.83006  1.64698 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)    4.0617     0.9550   4.253    3e-04 ***\nPetal_Length   4.9642     0.3024  16.417  3.4e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9491 on 23 degrees of freedom\nMultiple R-squared:  0.9214,    Adjusted R-squared:  0.918 \nF-statistic: 269.5 on 1 and 23 DF,  p-value: 3.401e-14\n\nAnova(lm(Sepal_interaction ~ Petal_Length, \n         iris_example_species[iris_example_species$Species == \"york\",]), \n      type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal_interaction\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   16.292  1  18.087 0.0002998 ***\nPetal_Length 242.770  1 269.527 3.401e-14 ***\nResiduals     20.717 23                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere we see that there is a significant negative relationship (F1,23 = 50.36, p&lt;0.001) between sepal and petal length for I. baruch, a significant positive relationship (F1,23 = 269.53, p&lt;0.001) between sepal and petal length for I. york,and no relationship (F1,23 = 1.63, p&lt;-0.21) between sepal and petal length for I. hunter.",
    "crumbs": [
      "Solutions",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html#practice",
    "href": "content/solutions/9_Combining_numerical_and_categorical_predictors_solutions.html#practice",
    "title": "Combining (lots of) numerical and categorical predictors",
    "section": "Practice",
    "text": "Practice\n\n1\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nDoes the impact of age on FEV differ among genders? Consider how your answer to this differs from the previous assignment!\n\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T, \n                  stringsAsFactors = T)\nfev_age &lt;- lm(FEV ~ Age*Sex, fev)\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  18.654   1  69.087 5.506e-16 ***\nAge          72.190   1 267.356 &lt; 2.2e-16 ***\nSex           7.977   1  29.543 7.745e-08 ***\nAge:Sex      17.426   1  64.535 4.467e-15 ***\nResiduals   175.509 650                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age * Sex, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.64072 -0.34337 -0.04934  0.33206  1.86867 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.849467   0.102199   8.312 5.51e-16 ***\nAge          0.162729   0.009952  16.351  &lt; 2e-16 ***\nSexMale     -0.775867   0.142745  -5.435 7.74e-08 ***\nAge:SexMale  0.110749   0.013786   8.033 4.47e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5196 on 650 degrees of freedom\nMultiple R-squared:  0.6425,    Adjusted R-squared:  0.6408 \nF-statistic: 389.4 on 3 and 650 DF,  p-value: &lt; 2.2e-16\n\n\nWe can explore this question using an ANCOVA since the response is continuous and the explanatory variables combine a categorical and continuous variable. Analysis of residuals indicates the assumptions are met (no pattern, normal distribution). There is a significant interaction among age and gender on FEV (F1,650=64.535, p&lt;.001). We should explore impacts of age on each gender separately.\n\nfev_age &lt;- lm(FEV ~ Age, fev[fev$Sex == \"Male\",])\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n             Sum Sq  Df  F value Pr(&gt;F)    \n(Intercept)   0.147   1   0.4258 0.5145    \nAge         221.896   1 641.5722 &lt;2e-16 ***\nResiduals   115.518 334                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age, data = fev[fev$Sex == \"Male\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.64072 -0.37752 -0.05318  0.36893  1.86867 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.0736     0.1128   0.653    0.514    \nAge           0.2735     0.0108  25.329   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5881 on 334 degrees of freedom\nMultiple R-squared:  0.6576,    Adjusted R-squared:  0.6566 \nF-statistic: 641.6 on 1 and 334 DF,  p-value: &lt; 2.2e-16\n\n\nAge has a significant (F1,334 = 641, p &lt; 0.01) positive (.27 L yr-1) impact on FEV in males.\n\nfev_age &lt;- lm(FEV ~ Age, fev[fev$Sex == \"Female\",])\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 18.654   1  98.262 &lt; 2.2e-16 ***\nAge         72.190   1 380.258 &lt; 2.2e-16 ***\nResiduals   59.991 316                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age, data = fev[fev$Sex == \"Female\", ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.09240 -0.28991 -0.03762  0.28749  1.13451 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.849467   0.085695   9.913   &lt;2e-16 ***\nAge         0.162729   0.008345  19.500   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4357 on 316 degrees of freedom\nMultiple R-squared:  0.5461,    Adjusted R-squared:  0.5447 \nF-statistic: 380.3 on 1 and 316 DF,  p-value: &lt; 2.2e-16\n\n\nAge also has a significant (F1,316 = 380, p &lt; 0.01) positive (.16 L yr-1) impact on FEV in females. The interaction is likely due to the higher rate of increase of FEV with age in males.\n\nlibrary(ggplot2)\nggplot(fev, aes(x=Age, y=FEV, color = Sex, shape = Sex)) +\n  geom_point(size = 3) +\n  ylab(\"FEV (L)\") +\n  ggtitle(\"FEV increases faster \\n with age in males\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32)) +\n    geom_smooth(method = \"lm\", se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n2\nData on home gas consumption at various temperatures before and after new insulation was installed has been collected @\nhttp://www.statsci.org/data/general/insulgas.txt\nMore information on the data is available @\nhttp://www.statsci.org/data/general/insulgas.html\nIs there any relationship between these factors? How would you test this, and what type of plot would you produce to accompany your analysis?\n\nheat &lt;- read.table(\"http://www.statsci.org/data/general/insulgas.txt\", \n                   header = T, stringsAsFactors = T)\nhead(heat)\n\n  Insulate Temp Gas\n1   Before -0.8 7.2\n2   Before -0.7 6.9\n3   Before  0.4 6.4\n4   Before  2.5 6.0\n5   Before  2.9 5.8\n6   Before  3.2 5.8\n\nheat_model &lt;- lm(Gas ~ Insulate * Temp, heat)\nplot(heat_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nrequire(car)\nAnova(heat_model, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Gas\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)   90.636  1 1243.911 &lt; 2.2e-16 ***\nInsulate      12.502  1  171.583 4.709e-16 ***\nTemp           2.783  1   38.191 2.640e-07 ***\nInsulate:Temp  0.757  1   10.391  0.002521 ** \nResiduals      2.915 40                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nggplot(heat, aes_string(x=\"Temp\", y=\"Gas\", color = \"Insulate\")) +\n  geom_point(size = 3) +\n  ylab(expression(paste(\"Gas (1000 \",ft^3, \")\")))+\n  xlab(expression(paste(\"Temperature (\", degree~C, \")\")))+\n  geom_smooth(method = \"lm\", se = F) +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: `aes_string()` was deprecated in ggplot2 3.0.0.\nℹ Please use tidy evaluation idioms with `aes()`.\nℹ See also `vignette(\"ggplot2-in-packages\")` for more information.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nThere is a significant relationship between insulation type (before/after) and temperature on gas usage (F1,40=10.39, p&lt;.01). Graphical analysis indicates the old (before) insulation led to higher overall gas usage and gas usage increased faster with colder temperature compared to the new insulation. Statistical analysis bears this out\n\nheat_model_old &lt;- lm(Gas ~ Temp, heat[heat$Insulate == \"Before\",])\nplot(heat_model_old)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(heat_model_old)\n\n\nCall:\nlm(formula = Gas ~ Temp, data = heat[heat$Insulate == \"Before\", \n    ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62020 -0.19947  0.06068  0.16770  0.59778 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.85383    0.11842   57.88   &lt;2e-16 ***\nTemp        -0.39324    0.01959  -20.08   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2813 on 24 degrees of freedom\nMultiple R-squared:  0.9438,    Adjusted R-squared:  0.9415 \nF-statistic: 403.1 on 1 and 24 DF,  p-value: &lt; 2.2e-16\n\nAnova(heat_model_old, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Gas\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 265.115  1 3349.59 &lt; 2.2e-16 ***\nTemp         31.905  1  403.11 &lt; 2.2e-16 ***\nResiduals     1.900 24                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nheat_model_new&lt;- lm(Gas ~ Temp, heat[heat$Insulate == \"After\",])\nplot(heat_model_new)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(heat_model_new)\n\n\nCall:\nlm(formula = Gas ~ Temp, data = heat[heat$Insulate == \"After\", \n    ])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.61677 -0.03594  0.03300  0.10180  0.35901 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  4.59062    0.12145  37.799  &lt; 2e-16 ***\nTemp        -0.24963    0.03769  -6.623 5.86e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2519 on 16 degrees of freedom\nMultiple R-squared:  0.7327,    Adjusted R-squared:  0.716 \nF-statistic: 43.87 on 1 and 16 DF,  p-value: 5.857e-06\n\nAnova(heat_model_new, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Gas\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 90.636  1 1428.759 &lt; 2.2e-16 ***\nTemp         2.783  1   43.867 5.857e-06 ***\nResiduals    1.015 16                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant relationship between gas usage and temperature for old and new insulation homes. However, the old insulation led to using 400 ft3 more gas per week to heat the house with every degree drop in temperature, while the new insulation leads to a increase of only 250 ft3 more gas per week with each degree drop.\n\n\n3\nData on the height, diameter, and volume of cherry trees was collected for use in developing an optimal model to predict timber volume. Data is available @\nhttp://www.statsci.org/data/general/cherry.txt\nUse the data to justify an optimal model.\n\ncherry &lt;- read.table(\"http://www.statsci.org/data/general/cherry.txt\",\n                     header = T)\nhead(cherry)\n\n  Diam Height Volume\n1  8.3     70   10.3\n2  8.6     65   10.3\n3  8.8     63   10.2\n4 10.5     72   16.4\n5 10.7     81   18.8\n6 10.8     83   19.7\n\n#if only considering main effects (one option)\ncherry_full &lt;- lm(Volume ~ Diam + Height, cherry)\nplot(cherry_full)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(cherry_full, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Volume\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  679.0  1  45.0632  2.75e-07 ***\nDiam        4783.0  1 317.4129 &lt; 2.2e-16 ***\nHeight       102.4  1   6.7943   0.01449 *  \nResiduals    421.9 28                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#both are significant, so finished\n\n#could also consider interactions \ncherry_full &lt;- lm(Volume ~ Diam * Height, cherry)\nplot(cherry_full)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(cherry_full, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Volume\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  62.185  1  8.4765 0.0071307 ** \nDiam         68.147  1  9.2891 0.0051087 ** \nHeight      128.566  1 17.5248 0.0002699 ***\nDiam:Height 223.843  1 30.5119 7.484e-06 ***\nResiduals   198.079 27                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(cherry_full)\n\n\nCall:\nlm(formula = Volume ~ Diam * Height, data = cherry)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-6.5821 -1.0673  0.3026  1.5641  4.6649 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 69.39632   23.83575   2.911  0.00713 ** \nDiam        -5.85585    1.92134  -3.048  0.00511 ** \nHeight      -1.29708    0.30984  -4.186  0.00027 ***\nDiam:Height  0.13465    0.02438   5.524 7.48e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.709 on 27 degrees of freedom\nMultiple R-squared:  0.9756,    Adjusted R-squared:  0.9728 \nF-statistic: 359.3 on 3 and 27 DF,  p-value: &lt; 2.2e-16\n\n#all significant, so finished\n\nI used multiple regression to consider the impacts of both continuous and categorical explanatory variables on timber volume. I used a top-down approach focused on p-values (F tests) in this example. Both diameter and height (and their interaction) are significant, so the full model is justified by the data. It explains 97.5% of the variation in volume. AIC methods lead to a similar outcome\n\nlibrary(MASS)\nstepAIC(cherry_full)\n\nStart:  AIC=65.49\nVolume ~ Diam * Height\n\n              Df Sum of Sq    RSS    AIC\n&lt;none&gt;                     198.08 65.495\n- Diam:Height  1    223.84 421.92 86.936\n\n\n\nCall:\nlm(formula = Volume ~ Diam * Height, data = cherry)\n\nCoefficients:\n(Intercept)         Diam       Height  Diam:Height  \n    69.3963      -5.8558      -1.2971       0.1347  \n\n\n\n\n4\nOver the course of five years, a professor asked students in his stats class to carry out a simple experiment. Students were asked to measure their pulse rate, run for one minute, then measure their pulse rate again. The students also filled out a questionnaire. Data include:\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\nHeight\nHeight (cm)\n\n\nWeight\nWeight (kg)\n\n\nAge\nAge (years)\n\n\nGender\nSex (1 = male, 2 = female)\n\n\nSmokes\nRegular smoker? (1 = yes, 2 = no)\n\n\nAlcohol\nRegular drinker? (1 = yes, 2 = no)\n\n\nExercise\nFrequency of exercise (1 = high, 2 = moderate, 3 = low)\n\n\nChange\nPercent change in pulse (pulse after experiment/pulse before experiment)\n\n\nYear\nYear of class (93 - 98)\n\n\n\nUsing the available data (available at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vToN77M80enimQglwpFroooLzDtcQMh4qKbOuhbu-eVmU9buczh7nVV1BdI4T_ma-PfWUnQYmq-60RZ/pub?gid=942311716&single=true&output=csv )\ndetermine the optimal subset of explanatory variables that should be used to predict change pulse rate (Change) (focusing on main effects only, no interactions) and explain your choice of methods. Interpret your results. Make sure you can explain any changes you needed to make to the dataset or steps you used in your analysis.\n\npulse_class_copy &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vToN77M80enimQglwpFroooLzDtcQMh4qKbOuhbu-eVmU9buczh7nVV1BdI4T_ma-PfWUnQYmq-60RZ/pub?gid=942311716&single=true&output=csv\", stringsAsFactors = T)\npulse_class_copy$Gender &lt;- as.factor(pulse_class_copy$Gender)\npulse_class_copy$Smokes &lt;- as.factor (pulse_class_copy$Smokes)\npulse_class_copy$Alcohol &lt;- as.factor(pulse_class_copy$Alcohol)\n\npulse_full &lt;- lm(Change ~ ., pulse_class_copy )\npulse_final &lt;- step(pulse_full)\n\nStart:  AIC=-94.24\nChange ~ Height + Weight + Age + Gender + Smokes + Alcohol + \n    Exercise + Year\n\n           Df Sum of Sq    RSS     AIC\n- Year      1  0.002178 4.0113 -96.218\n- Gender    1  0.002825 4.0119 -96.211\n- Smokes    1  0.006969 4.0161 -96.163\n- Age       1  0.007498 4.0166 -96.157\n- Weight    1  0.018975 4.0281 -96.026\n- Exercise  1  0.063201 4.0723 -95.524\n&lt;none&gt;                  4.0091 -94.243\n- Height    1  0.248912 4.2580 -93.473\n- Alcohol   1  0.275592 4.2847 -93.185\n\nStep:  AIC=-96.22\nChange ~ Height + Weight + Age + Gender + Smokes + Alcohol + \n    Exercise\n\n           Df Sum of Sq    RSS     AIC\n- Gender    1  0.002745 4.0140 -98.187\n- Smokes    1  0.008748 4.0200 -98.118\n- Age       1  0.009061 4.0203 -98.115\n- Weight    1  0.020656 4.0319 -97.982\n- Exercise  1  0.061106 4.0724 -97.523\n&lt;none&gt;                  4.0113 -96.218\n- Height    1  0.247630 4.2589 -95.463\n- Alcohol   1  0.280615 4.2919 -95.108\n\nStep:  AIC=-98.19\nChange ~ Height + Weight + Age + Smokes + Alcohol + Exercise\n\n           Df Sum of Sq    RSS      AIC\n- Age       1  0.008872 4.0229 -100.085\n- Smokes    1  0.009773 4.0238 -100.075\n- Weight    1  0.019557 4.0336  -99.963\n- Exercise  1  0.058622 4.0726  -99.520\n&lt;none&gt;                  4.0140  -98.187\n- Height    1  0.258061 4.2721  -97.321\n- Alcohol   1  0.302450 4.3165  -96.845\n\nStep:  AIC=-100.09\nChange ~ Height + Weight + Smokes + Alcohol + Exercise\n\n           Df Sum of Sq    RSS      AIC\n- Smokes    1  0.009335 4.0322 -101.979\n- Weight    1  0.020707 4.0436 -101.849\n- Exercise  1  0.063527 4.0864 -101.365\n&lt;none&gt;                  4.0229 -100.085\n- Height    1  0.270131 4.2930  -99.096\n- Alcohol   1  0.293626 4.3165  -98.845\n\nStep:  AIC=-101.98\nChange ~ Height + Weight + Alcohol + Exercise\n\n           Df Sum of Sq    RSS     AIC\n- Weight    1  0.020452 4.0527 -103.75\n- Exercise  1  0.055663 4.0879 -103.35\n&lt;none&gt;                  4.0322 -101.98\n- Height    1  0.263914 4.2961 -101.06\n- Alcohol   1  0.285822 4.3181 -100.83\n\nStep:  AIC=-103.75\nChange ~ Height + Alcohol + Exercise\n\n           Df Sum of Sq    RSS     AIC\n- Exercise  1   0.07307 4.1258 -104.92\n&lt;none&gt;                  4.0527 -103.75\n- Alcohol   1   0.28662 4.3393 -102.60\n- Height    1   0.39237 4.4451 -101.50\n\nStep:  AIC=-104.92\nChange ~ Height + Alcohol\n\n          Df Sum of Sq    RSS     AIC\n&lt;none&gt;                 4.1258 -104.92\n- Alcohol  1   0.25346 4.3792 -104.18\n- Height   1   0.43164 4.5574 -102.35\n\n#consider assumptions\nplot(pulse_final)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(pulse_final, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Change\n            Sum Sq Df F value  Pr(&gt;F)  \n(Intercept) 0.0434  1  0.4520 0.50500  \nHeight      0.4316  1  4.4987 0.03973 *\nAlcohol     0.2535  1  2.6416 0.11141  \nResiduals   4.1258 43                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(pulse_final)\n\n\nCall:\nlm(formula = Change ~ Height + Alcohol, data = pulse_class_copy)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62511 -0.17315  0.05539  0.15239  1.01992 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) -0.318699   0.474060  -0.672   0.5050  \nHeight       0.005658   0.002668   2.121   0.0397 *\nAlcohol2     0.173965   0.107035   1.625   0.1114  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3098 on 43 degrees of freedom\nMultiple R-squared:  0.1074,    Adjusted R-squared:  0.06585 \nF-statistic: 2.586 on 2 and 43 DF,  p-value: 0.08699\n\n#or\nlibrary(MuMIn)\noptions(na.action = \"na.fail\")\nauto &lt;- dredge(pulse_full)\n\nFixed term is \"(Intercept)\"\n\nlibrary(rmarkdown)\npaged_table(auto)\n\n\n  \n\n\noptions(na.action = \"na.omit\")\n\nI used step based approach (which requires nested models) and large search method above. Using the step approach only height and alcohol usage are retained in the final model, which explains 10% of the variation in pulse change. Model assumptions are also met. The search method finds the same optimal model but notes many other models (including a null model) perform similarly well.\n\n\n5\nFind one example of model selection from a paper in your field. It may be more complicated (see next question!) than what we have done, but try to identify the approach (F/AIC, top-down/bottom-up/not nested) they used. Review how they explained their approach (methods) and reported outcomes (results). Be prepared to discuss in class next week.\n\n\n6\nFind one example of a linear model selection (e.g., generalized linear models, mixed-effects models, beta regression) from a paper in your field. Be prepared to name the technique in class next week.",
    "crumbs": [
      "Solutions",
      "Combining numerical and categorical predictors"
    ]
  },
  {
    "objectID": "future_updates.html",
    "href": "future_updates.html",
    "title": "Future updates",
    "section": "",
    "text": "add notes on swirl to practice lessons/problems\nmaybe remove examples from solutions (just have answers)\nadd more examples\nglm\n\nchen et al 2023\n\nclearly show what to provide in all examples"
  }
]