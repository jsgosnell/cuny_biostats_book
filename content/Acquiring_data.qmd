---
title: Acquiring data
subtitle: Sampling and related issues
bibliography: references.bib
---

Let's start our statistics journey by thinking about the simplest scenario: We
want to know something about a group. An example might be the average (or mean,
we will define later if needed!) value for some trait, the minimum value, or the
maximum value. We could also wish to know about the distribution of values for
that trait in the group. These traits of the group are called *statistics:*

> the numerical facts or data themselves - *Dictionary.com*

This means we have a target trait we are focused on, and we have defined a group
of interest. We can call this group of interest a *population*. Note that while
the term *population* may have specific meanings in some fields (such as
ecology), here population is just the group of interest. It could be a
population of Goliath grouper in Florida, a population of flowers in Virginia,
or people from a certain country or demographic group. We could want to know
something about all of these groups!

As we've already noted, in a perfect world we know everything (or at least our
trait value) for every member of the focal population. However, we often don't
or can't measure every member of a population. It may be too difficult or
expensive to measure every member of the population. In fact, we may not even
know how large the population is!

In the cases where we can't measure every member of the population, we collect
data on the focal trait(s) from a *sample*. A sample is the subset of the
population of interest. Data can be collected from samples used in experimental
studies, where researchers manipulate something to see how it impacts the focal
trait. Researchers may expose organisms to different stimuli in a controlled
lab, field, or mesocosm study to see what happens. For example, researchers
interested in impacts of an invasive crayfish (*Pacifastacus leniusculus*) on
Mazama newts (*Taricha granulosa mazamae*) collected newts and crayfish.; they
then placed either just newts or newts and crayfish in in large tanks to observe
interactions @girdner2018.

[![Experimental mesocosms used to evaluate Mazama newt and signal crayfish
behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists
observed the interaction between newts and crayfish in tanks designed to mimic
natural
habitat.](https://www.nps.gov/common/uploads/stories/images/nri/20160414/articles/E3D75BF5-1DD8-B71B-0BAA0D9A58F1307A/E3D75BF5-1DD8-B71B-0BAA0D9A58F1307A.jpg){fig-alt="Image of people filling large black tanks on dock near lake."}](https://www.nps.gov/articles/parkscience32_1_5-12_buktenica_et_al_3815.htm)

Data can also be collected from observational studies, where researchers simply
measure outcomes and other traits without manipulating anything. For example,
scientists interested in impacts of climate change on species ranges surveyed
sites for species presence and abundance and compared it to historical data
(@sagarin1999).

Different types of studies change what we can use the data for. In general,
experimental studies are more commonly used to ascertain causation (something
makes something happen), whereas observational studies are used to assess
correlation (something happens when something else happens). However, these can
be hard to disentangle, especially since studies can only be observational since
experiments would be unethical or impossible to carry out. As XKCD puts it

[![XKCD: Correlation. Title text (text that pops up when you hover over the
comic): Correlation doesn't imply causation, but it does waggle its eyebrows
suggestively and gesture furtively while mouthing 'look over
there'.](https://imgs.xkcd.com/comics/correlation.png){fig-alt="Picture of two stick figures chatting.  One says, \"I used to think correlation implied causation. Then I took a statistics course. Now I don't.\" The other figure responds \"Sounds like the class helped.\", To which the first figure responds, \"Maybe.\""
fig-align="center"}](https://xkcd.com/552/)

> Correlation doesn't imply causation, but it does waggle its eyebrows
> suggestively and gesture furtively while mouthing 'look over there' - XKCD
> #552

Once we have the sample, we can measure the trait of interest in it, and use
that to estimate the statistic of interest for the actual population. This is
the science of statistics, which can actually be defined as

> the practice or science of collecting and analyzing numerical data in large
> quantities, especially for the purpose of inferring proportions in a whole
> from those in a representative sample. - *Oxford English Dictionary*

If the whole idea of statistics is to infer something about the population from
our sample, we need to make sure the sample is *representative* of the
population. That means it should not be *biased*. *Bias* occurs if the trait
values we measure in our sample differ from the population in a consistent way.
This can happen with samples of convenience, or when researchers select samples
that are easy to measure but may not be representative of the population.
Classic examples include estimating the amount of time students spend studying
by surveying students at a campus library.

Bias may also be related to issues of independence. In a good sampling design,
every member of the population has the same chance of being included in a
sample. Samples of convenience violate this premise, and often the underlying
issue is that the samples are not independent. A perfect solution is to randomly
choose members of the population to be in the sample, but that is often not
possible. Again, it requires knowing every member of the population! Indepence
also means each data point is not related to any others!

[![XKCD: Slope Hypothesis Testing. Don\'t worry, we\'ll come back to
significance - but what is the independence
issue?](https://imgs.xkcd.com/comics/slope_hypothesis_testing_2x.png){fig-alt="Comic strip where 2 figures discuss relationship between how loud students scream and exam grades."
fig-align="center"}](https://xkcd.com/2533/)

In some cases linkages among samples are impossible to avoid. We will cover ways
to address that using blocking factors or random effects later.

Notice in discussing bias we are not directly focusing on the quality of the
measurements! For that, we could discuss accuracy (how well we measure the
underlying trait in regards to its true value, which we typically don't know)
and precision (how repeatable our measurement technique is). Obviously we need
good data to make good estimates, but these ideas are different from our current
focus on picking a good sample.

Even if we have a proper way to measure a trait (accurate and precise) in a good
sample (not biased), we will still be producing an estimate of the population
statistic! This is due to \*sampling error\*. Sampling error refers to the fact
that every sample will produce a slightly different estimate of the statistic.
Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their
length, and use it calculate the average fish length. If we took a different
sample, do you think it would have exactly the same average?

We can demonstrate this in R - you won't understand the code below yet, so just
trust me for now, but this will let you start seeing code and thinking about how
to use it.

Let's generate a population of fish. We'll store their lengths in a vector
called \*lengths\* .

```{r}
lengths <- rnorm(n=1000, mean = 10, sd=1)
```

The average length of fish in this population is `r round(mean(lengths),2)` cm.
We can then simulate a sample from this population. In fact, let's simulate 2
and compare the means of each.

```{r}
sample_1 <- sample(lengths,50)
sample_2 <-sample(lengths, 50)
```

The mean length for fish in sample 1 is `r round(mean(sample_1),2)` cm, while
that in sample 2 is `r round(mean(sample_2))` cm (Note: if you view this on the
webpage you will see a number, but in the actual qmd file you see R code here -
this is an example of merging code and text!). These are both close to the true
value, but they are also both slightly different - this is sampling error!

Sampling error always exists, and a major part of statistics is to quantify it.
One thing that reduces sampling error is to have large samples! Remember, if we
measure every member of the population we don't even need statistics, so the
closer we get to that (implying larger samples) the better!

Now that we have data, we'll discuss summarizing it in the next section (and
actually define *mean* and some of the other terms we've started to use!).
