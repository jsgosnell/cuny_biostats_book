---
title: More ANOVAs
subtitle: Dealing with multiple group membership and interactions
bibliography: ../references.bib
---

<!-- COMMENT NOT SHOW IN ANY OUTPUT: Code chunk below sets overall defaults for .qmd file; these inlcude showing output by default and looking for files relative to .Rpoj file, not .qmd file, which makes putting filesin different folders easier  -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

In the last chapter we introduced the idea of comparing means among
populations (one-way ANOVAs, our first linear models). However, the
units that we measure may belong to multiple groups. We will extend our
analysis of variance to consider multiple group membership and
interactions in this chapter. As a starting point, consider that group
membership may be an inherent property of the unit we measure or we may
assign it.

## Example: Back to the birds

One of the last chapters practice problems focused bird feathers. While
studying feather color in Northern flickers (*Colaptes auratus*),
@wiebe2002 noted that \~25% of birds had one or more "odd" tail
feathers. They decided to compare the color of these odd and "typical"
feathers.

[![Northern Flicker. Mike's Birds, CC BY-SA 2.0
\<https://creativecommons.org/licenses/by-sa/2.0\>, via Wikimedia
Commons](/images/Northern_Flicker_(4508135578).jpg)](https://commons.wikimedia.org/wiki/File:Northern_Flicker_(4508135578).jpg)

Example and data provided by @mcdonald2014.

```{r, echo=FALSE}
Input = ("
 Bird    Feather_type   Color_index
 A       Typical   -0.255
 B       Typical   -0.213
 C       Typical   -0.19
 D       Typical   -0.185
 E       Typical   -0.045
 F       Typical   -0.025
 G       Typical   -0.015
 H       Typical    0.003
 I       Typical    0.015
 J       Typical    0.02
 K       Typical    0.023
 L       Typical    0.04
 M       Typical    0.04
 N       Typical    0.05
 O       Typical    0.055
 P       Typical    0.058
 A       Odd       -0.324
 B       Odd       -0.185
 C       Odd       -0.299
 D       Odd       -0.144
 E       Odd       -0.027
 F       Odd       -0.039
 G       Odd       -0.264
 H       Odd       -0.077
 I       Odd       -0.017
 J       Odd       -0.169
 K       Odd       -0.096
 L       Odd       -0.33
 M       Odd       -0.346
 N       Odd       -0.191
 O       Odd       -0.128
 P       Odd       -0.182
")

feather <-  read.table(textConnection(Input),header=TRUE)
```

```{r}
library(rmarkdown)
paged_table(feather)
```

## How do we analyze this data?

We may first note that we have a continuous measurement (feather color,
measured using color hues from a digital camera and another statistical
technique that we will not go into here) and a categorical variable
(feather type, with levels "typical" and "odd"). This hopefully reminds
you of an ANOVA/t-test!

We could plot the data

```{r}
library(ggplot2)
ggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type))+
  geom_jitter()+
  labs(y= "Color index",
       x= "Feather type",
       title="Comparing odd and typical feathers in Northern flickers")+
  guides(color=F)
```

Develop a set of hypotheses:

$$
\begin{split}
H_O: \mu_{\textrm{odd feather color}} = \mu_{\textrm{typical feather color}}\\
H_A: \mu_{\textrm{odd feather color}} \neq \mu_{\textrm{typical feather color}}\\
\end{split}
$$

and test them using a t-test:

```{r}
t.test(Color_index ~ Feather_type, data=feather)
```

or, using more generalizable functions, a linear model:

```{r}
library(car)
Anova(lm(Color_index ~ Feather_type, data=feather), type = "III")
```

We find a significant p value, **but we did not check assumptions**. For
linear models (remember, \$\epsilon \approx i.i.d. N(\mu,\sigma)\$, we
could use our visual checks

```{r}
plot(lm(Color_index ~ Feather_type, data=feather))
```

Which appears ok, but there is a problem.

Our data are not independent!

## Lack of Independence

Odd and typical feathers were measured on a single bird (note the *Bird*
column) in the dataset. We might assume feathers on a given bird are
more closely related in color than feathers on different birds. This
could be due to diet or other factors making all feathers on a given
bird brighter or darker than those on another. Regardless of reason (and
"good" p value), we know the measurements are linked in some way. Note
we could "connect" individual observations.

```{r}
ggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type, group=Bird))+
  geom_line(position = position_dodge(0.4), color="black") +
  geom_point(position = position_dodge(0.4)) +  
  labs(y= "Color index",
       x= "Feather type",
       title="Comparing odd and typical feathers in Northern flickers")+
  guides(color=F)
```

When this is true, we need to consider these connections.

## Blocking, two-way ANOVAs,and paired t-tests

In this case the connections may be considered artifacts of the data. We
didn't assign birds. We also made a choice to compare odd and typical
feathers from the same bird - why? In general, accounting for extra
variation in the data will give you a better answer about how a given
variable influences outcomes. This may be called *blocking*. Although
the motivation might therefore be to get a "better" p value, it should
be driven by experimental design (and thus we started with an example
where we didn't "need" to account for it to achieve significance).

In order to consider how color differs by bird *and* feather type, we
need to add both variables to our model. This is possible because, as we
noted earlier, we can subdivide variance among multiple levels. For each
variable we add, we also add a null (and corresponding alternative)
hypothesis. So we retain our focus on feather type:

$$
\begin{split}
H_O: \mu_{\textrm{odd feather color}} = \mu_{\textrm{typical feather color}}\\
H_A: \mu_{\textrm{odd feather color}} \neq \mu_{\textrm{typical feather color}}\\
\end{split}
$$

but also add a set of hypotheses focused on birds:

$$
\begin{split}
H_O: \mu_{\textrm{color of bird A}} = \mu_{\textrm{color of bird B}}....\textrm{for all birds}\\
H_A: \mu_{\textrm{color of bird A}} \neq \mu_{\textrm{color of bird B}}....\textrm{for all birds}\\
\end{split}
$$

We can analyze this using our linear model approach. Since both
variables are categorical, this is often called a two-way ANOVA. First,
let's make the object

```{r}
two_way_anova_example <- lm(Color_index ~ Feather_type + Bird, data=feather)

```

Then check the assumptions

```{r}
plot(two_way_anova_example)
```

Note, visually speaking, the residuals do appear to be closer to normal
now. Since assumptions look ok, we can analyze the outcome

```{r}
summary(two_way_anova_example)
Anova(two_way_anova_example, type= "III")
```

Note we see a significant difference in color among birds and feather
type. Although we may be tempted to (and could) use post-hoc tests to
consider which birds are different than which others, this is typically
not done for blocked variables. We did not assign these pairings and it
is not the focus of our efforts.

Since we only had 2 types of feathers, we also don't need post-hoc
tests. A significant p value means they differ from each other, and the
estimates provided by the *summary* command indicate the typical
feathers have a higher color index.

### t-test connections

When we have only two measurements per group (e.g., odd and typical
feathers from each bird), we can use a t-test approach to achieve
similar goals. This approach is known as a paired t-test. Instead of
focusing on the difference in means (like a 2-sample t-test), the test
focuses on the mean difference between paired measurements (which would
be 0 under the null hypothesis!). In this way, it is effectively a
one-sample test that is pairing the data to reduce variation (blocking).
We can do carry out the test:

```{r}
t.test(Color_index ~ Feather_type, data=feather, paired=TRUE)
```

and get the same results as above (note we don't even have to consider
corrections like the Welch approach since this a one-sample test).
Common examples of paired t-tests include before-after and twin studies.

In an earlier chapters we considered options for one- and two-sample
tests when t-tests assumptions were not met. For two-sample tests, one
of these approaches, the sign or binary test, is only valid for paired
data. The differences in paired observations are compared to a set value
(typically 0). Under the null hypothesis, half should be below the
proposed median and half should be above. Differences matching the
proposed value are ignored, thus reducing the sample size and making it
harder to reject the null hypothesis; this is actually an odd way of
accounting for them. The proportion of values below the proposed median
is then evaluated using a binomial test. For two sample, the *SIGN.test*
function in the **BSDA** package requires 2 columns of data and assumes
the order of the column represents paired data.

```{r}
library(BSDA)
SIGN.test(feather[feather$Feather_type == "Odd", "Color_index"], 
          feather[feather$Feather_type == "Typical", "Color_index"],
          md = 0)

```

### More than 2 measurements? Back to the linear model

We can also block for variation when we take more than 2 measurements
per unit. For example, imagine if these birds also had a special, long
tail feather.

```{r}
set.seed(25)
special <- data.frame(Bird = LETTERS[1:16], Feather_type = "Special", 
                      Color_index= feather[feather$Feather_type == "Typical", "Color_index"] +
                        .3 +runif(16,1,1)*.01)
feather_extra <- merge(feather, special, all = T)
feather_extra$Feather_type <- factor(feather_extra$Feather_type)
```

We could still block for variation using the linear model/ANOVA, but not
the t-test, approach. As another review, we create the model

```{r}
more_blocks <-lm(Color_index ~ Feather_type + Bird, data=feather_extra)
```

Check assumptions

```{r}
plot(more_blocks)
```

Check outcome (this time focusing on *Anova* output)

```{r}
Anova(more_blocks, type="III")
```

We still see feather type has a significant impact on color, but since
we have more than 2 groups we need to follow up this finding with a
post-hoc test.

```{r}
library(multcomp)
compare <- glht(more_blocks, linfct = mcp(Feather_type = "Tukey"))
summary(compare)
```

## Other ways to be in multiple groups

In the bird example, one of our categories (bird) was un-intential. We
chose to measure odd and typical feathers, and accounting for variation
among birds was an appropriate step given lack of independece in
measurements. However, we can also assign units to multiple groups.
Doing so can let us consider the **main effects** of multiple variables
and potential **interactions** among them in what is often called a
**factorial ANOVA**.

For example, @valdez2023 wanted to consider the impact of top-down
(snail grazing) and bottom- up (nutrient availability) on marsh plant
(*Spartina alterniflora*) growth. To do this, they assigned plots to one
of 3 grazer treatments and one of 2 nitrogen treatments.

[![Fig 1 from Valdez et al. 2003. Map and conceptual illustration of
experimental
design.](/images/journal.pone.0286327.g001.PNG){fig-alt="Map of study site on Hog Island, Virginia, USA and conceptual illustration of experimental design with the following treatments: 1) Nitrogen addition with ambient snails, 2) nitrogen addition with three times ambient snails, 3) nitrogen addition without snails, 4) ambient nitrogen with ambient snails, 5) ambient nitrogen with three times ambient snails, and 6) ambient nitrogen without snails. The figure also depicts cage controls and uncaged plots used to assess caging effects on marsh plants. The map in the figure was created in R using ggmap [33] from ©OpenStreetMap under a ODb license, with permission from OpenStreetMapFoundation, original copyright 2018. https://www.openstreetmap.org/copyright."}](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0286327)

This design is different from the bird example. No two measurements for
a given trait were taken on the same plot. In this case, we likely care
about the main effects, or impacts, of both variables. However, we may
also need to consider interactions among the variables. Interactions
occur when the impact of one variable depends on the level of another.
For example, snail removal might have major impacts on nitrogen-enriched
plots while having no impact on ambient plots. Due to this, we now have
even more hypotheses:

$$
\begin{split}
H_O: \mu_\textrm{plant growth, no fertilizer} = \mu_\textrm{plant growth, fertilizer}\\
H_O: \mu_\textrm{plant growth, snails removed} = \mu_\textrm{plant growth, control snails}= \mu_\textrm{plant growth, snails added}\\
H_O: \textrm{impact of snail grazing does not depend on nitrogen level}\\
\end{split}
$$

Fortunately, these are easy to consider in our linear model framework.
We simply add the interaction between two variables using the ":"
notation. We'll focus on below-ground biomass (standardized to m^2^) for
this example (the paper measured 9 response variables!)

```{r}
valdez_2023 <- read.csv("data/Spartina_alterniflora_traits.csv", stringsAsFactors = T)
bgb_model <-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023)
```

For shorthand, note that if we put *main effect \* main effect* in a
model, it automatically adds the interaction term.

```{r}
bgb_model_shorthand <-lm(below.biomass.g.meter.sq..m2..~Snail.Level * Nitrogen.level, valdez_2023)
summary(bgb_model)
summary(bgb_model_shorthand)
```

You may note a weird NA here (we'll come back to it) but we should
really check model assumptions before looking at output.

```{r}
plot(bgb_model)
```

These look ok. There may be a slight increase in variance with fitted
values, but we can work with this. Let's return to our summary and build
an ANOVA table.

```{r, error = T}
summary(bgb_model)
Anova(bgb_model, type="III")
```

But we got an error! What happened? Let's look at the data

```{r}
paged_table(valdez_2023)
```

A summary may help more. Note we can summarize across multiple factors.

```{r}
library(Rmisc)
summarySE(valdez_2023, measurevar = "below.biomass.g.meter.sq..m2..", groupvars = c("Snail.Level", "Nitrogen.level"))
```

Note the *uncaged* treatment only has *without* for the nitrogen impact.
It was a control! While we often need these in experiments, they can
create analysis problems. This is because we can't consider how nutrient
level depends on snail treatment for the control level! You could note
we have the same issue for our initial bird analysis:

```{r,error=T}
two_way_anova_example_int <- lm(Color_index ~ Feather_type * Bird, data=feather)
Anova(two_way_anova_example_int, type="III")
```

On a positive note, this means R will typically not consider
interactions when it shouldn't, but you need to know why in order to fix
it.

The NAs in the model summary

```{r}
summary(bgb_model)
```

Occur for the same reason. Interactions can not be calculated for some
levels.

To fix this (and deal with controls), we need to consider the data.
@valdez2023 used t-tests (why?) to consider differences between cage and
cage control plots (note %in% and the fact they did not focus on
above-ground biomass (maybe because uncaged plots had little..). %in%
allows you to subset data by matching items to list. Remember you can
always get help on functions using something like (we need the
quotations for operators!)

```{r, eval=F}
?'%in%'
```

```{r}
t.test(below.biomass.g.meter.sq..m2..~Snail.Level, valdez_2023[valdez_2023$Snail.Level %in% c("uncaged","control snails") & valdez_2023$Nitrogen.level == "without",])
```

To consider interactions, we can remove the controls

```{r}
bgb_model_cont_removed <-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != "uncaged",])
```

We can consider the assumptions

```{r}
plot(bgb_model_cont_removed)
```

and now note ...

```{r}
Anova(bgb_model_cont_removed, type="III")
```

...that the ANOVA table works.

### Intepreting interactions

#### When not significant

If interactions are not significant, they can be handled in 2 ways.

1.  We can remove the interaction from the model, re-run it, and
    interpret main effect

    ```{r}
    bgb_model_cont_removed_int_removed <- update(bgb_model_cont_removed, .~.-Snail.Level:Nitrogen.level)
    Anova(bgb_model_cont_removed_int_removed, type="III")
    ```

2.  We can leave the interaction in the model and interpret main effects
    immediately

The benefit of approach 1 is we "increase" the degrees of freedom
associated with the residuals, which ends up reducing the the MST. This
is because in 2-way ANOVA's we allocate degrees of freedom to
calculating main effects and interactions. This approach was likely used
in the original manuscript.

The second approach is to simply use the provided output and not perform
another series of tests, which may increase chances for a Type 1 error.
We will return to this discussion when we get to model selection.

Regardless, we can interpret main effects (though with possibly
different outcomes). Using the approach were we drop insignificant
interactions, we see both nitrogen and grazing levels impact below
ground biomass. Since there are 3 levels of grazing and no interactions,
we can consider the general impact of grazing levels:

```{r}
summary(glht(bgb_model_cont_removed_int_removed, linfct = mcp(Snail.Level = "Tukey")))

```

#### When significant

If the interaction term is significant, it means the main effects can
not be interpreted. This is because the impact of a given variable
depends on the level of another. When this happens, the data is
typically divided into subset and analyzed using one-way ANOVAs. Another
less-used approach is to interpret interaction terms.

For example, when @valdez2023 analyzed standing dead mass, they found a
significant interaction term:

```{r}
sdm_model <-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != "uncaged",])
plot(sdm_model)
Anova(sdm_model, type="III")
```

Following this, you could investigate impacts in plots with nitrogen,
where you find snail manipulation had a significant impact,

```{r}
sdm_model_fertilized <-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != "uncaged" & valdez_2023$Nitrogen.level == "Fertilized",])
plot(sdm_model_fertilized)
Anova(sdm_model_fertilized, type= "III")
summary(glht(sdm_model_fertilized, linfct = mcp(Snail.Level= "Tukey")))
```

and plots without added nutrients, where you find snail addition did not

```{r}
sdm_model_not_fertilized <-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != "uncaged" & valdez_2023$Nitrogen.level == "without",])
plot(sdm_model_not_fertilized)
Anova(sdm_model_not_fertilized, type= "III")

```

Since interactions were significant, we could also choose to compare all
groups. the **emmeans** package offers this approach (and was likely
used in the Valdez et al. 2023 paper).

```{r}
library(emmeans)
emmeans(sdm_model, pairwise ~ Snail.Level*Nitrogen.level)

```

## Other options

Bootstrapping and permutation tests options may also be used for two-way
ANOVAs when assumptions are not met, though there is implementation is
more complicated than single-sample designs due to the need to
randomize/permute interaction impacts.

Another option is to use weighted-least squares regression - this
approach specifically helps when residuals are not evenly distributed
among groups. For example, we could take the sdm_model (just as an
example of use! it's not needed here!) This approach assume you built
the model and then noted an issue with heteroscedasticity. If so, we can
calculate a weight for each residual that is based on its variance -
below makes a value that increases with low variance.

```{r}
wt_sdm <- 1 / lm(abs(sdm_model$residuals) ~ sdm_model$fitted.values)$fitted.values^2
```

We can then add a new argument to the *lm* function to use these
weights.

```{r}
sdm_model_wls <-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != "uncaged",], weights = wt_sdm)
```

We can then continue on our normal route:

```{r}
plot(sdm_model_wls)
Anova(sdm_model_wls, type="III")
```

If you compare the two models you notice slight differences - these are
minimal here due to lack of differences in variance.

```{r}
summary(sdm_model)
summary(sdm_model_wls)
```

Why not just always do this? Because weighted least squares implicitly
assumes we *know* the weights. We are actually estimating them, so small
datasets may lead to bad estimates and outcomes.

## Plotting outcomes

Results from two-way ANOVAs are often plotted similarly to one-way
ANOVAs, but with colors or other aesthetics representing the additional
group.

```{r}
sdm_summary <- summarySE(valdez_2023[valdez_2023$Snail.Level != "uncaged",], measurevar = "Standing.Dead..dry..m2.", groupvars = c("Snail.Level", "Nitrogen.level"))
sdm_summary
```

```{r}
sdm_summary$Snail.Level <- relevel(sdm_summary$Snail.Level, "removal")

ggplot(sdm_summary, aes(x=Snail.Level, 
                           y=Standing.Dead..dry..m2.,
                           fill=Nitrogen.level)) +
  geom_col(color="black", position=position_dodge()) +
  geom_errorbar(aes(ymin=Standing.Dead..dry..m2., ymax=Standing.Dead..dry..m2.+ci), position = position_dodge()) +
  labs(title="Grazing impacts depend on nitrogen levels",
       x= "Grazing level",
       y= expression(paste("Standing dry mass (" , g^{-1}, m^{-2}, ")")))
```

## Next steps

In the next chapters we will carry our linear model approach to consider
the relationship between continous outcomes and continuous predictor
variables.
