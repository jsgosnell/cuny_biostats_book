{
  "hash": "943740c1a1387cbcdfcf75cfb6befbb9",
  "result": {
    "markdown": "---\ntitle: Linear model extensions\nsubtitle: How to fix it when it's broken\nbibliography: ../references.bib\n---\n\n\n<!-- COMMENT NOT SHOW IN ANY OUTPUT: Code chunk below sets overall defaults for .qmd file; these inlcude showing output by default and looking for files relative to .Rpoj file, not .qmd file, which makes putting filesin different folders easier  -->\n\n\n\n\n\nThe past several chapters/lessons have focused on linear models. Here we\nexplore options for analysis when linear model assumptions are not met.\n\n## Sticking with the linear model\n\nLinear models are useful for a number of reasons. They are a great way\nto unify most/many tests from classical statistics. In fact, most of the\nranked tests we've developed can actually be run as linear models when n\n\\>15. For example, we can go back to our Wilcox-Mann Whitney U tests\n(for 2 populations) and Kruskal-Wallis (for 3+) from the [comparing\nmeans among groups\nchapter](Compare_means_among_populations.qmd){target=\"_blank\"} and note\nthe outcome from a *wilcox.test*\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntwo_species_subset <- iris[iris$Species!=\"setosa\",]\nwilcox.test(Sepal.Length ~ Species, two_species_subset)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.869e-07\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nis very close to a linear model predicting the signed rank of the data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nsigned_rank = function(x) sign(x) * rank(abs(x))\nAnova(lm(signed_rank(Sepal.Length) ~ Species, two_species_subset), type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: signed_rank(Sepal.Length)\n            Sum Sq Df F value    Pr(>F)    \n(Intercept)  64872  1 102.378 < 2.2e-16 ***\nSpecies      20967  1  33.089 1.003e-07 ***\nResiduals    62098 98                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nIn fact, we could run simulations and show that p values from these 2\napproaches are highly correlated (now you know what that means) with a\n$\\beta$ of almost 1 (from @lindelov).\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nLinear models are also extremely robust. Consider the basic assumptions\nof a linear model\n\n$$\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n$$\n\nAlthough the residuals are meant to be homoscedastic (equal or constant\nacross all groups), it turns out the model is robust of when the largest\ngroup variance is 4-10x larger than the smallest group variance and\nsample sizes are approximately equal [@blanca2018; @fox2015; @zuur2010],\nthough highly uneven group sizes begin to cause issues [@blanca2018].\n\nSimilarly, non-normal data is not an issue. This is partially because\nthe assumptions are focused on residuals, but also because the procedure\nis highly robust [@blanca2017]. This finding further supports the\ngraphical consideration of assumptions , especially since many tests for\nnormality are conservative (samples are almost never *perfectly* normal,\nand slight deviations are easier to pick up with larger sample sizes\ndespite the fact the central limit theorem suggests this is when the\nissue is least important) [@zuur2010; @shatz2023].\n\nThese issues have led some authors to argue violations of the linear\nmodel assumptions are less dangerous than trying new, and often\nless-tested, techniques that may inflate type I error rates [@knief2021;\n@warton2016]. However, new techniques (or sometimes old techniques that\nare new to a given field) may be more appropriate when assumptions are\nclearly broken [@warton2010; @reitan2016; @geissinger2022]. In this\nsection we explore common-ish approaches for analyzing data when the\nassumptions of a linear model are broken. Our goal here is to introduce\nthese methods. Each could be the focus of their own class, book, or much\nlarger study. Fortunately most can be viewed as extensions to our\nexisting knowledge, although many of the assumptions and techniques for\nthem are less developed/still being argued about.\n\nThe various assumptions related to linear models may be prioritized on\ntheir relative importance. One such order is provided (roughly) by\n@gelman2006.\n\n-   Model validity\n\n    -   As noted in the multiple regression chapter, we only should\n        investigate relationships we have a mechanism to explain\n\n-   Linear relationship and additive effects of predictor variables\n\n-   Errors are\n\n    -   independently distributed\n\n    -   identical (homoscedastic)\n\n    -   follow a normal distribution\n\nMany datasets will violate multiple of these assumptions simultaneously,\nso addressing issues is often best resolved by understanding *why* this\nis happening.\n\n## Linear relationship is inappropriate\n\nA central (and often overlooked assumption) of linear models is that the\nrelationship between the predictors and the outcome variable is linear\nand addtive. When the relationship is not linear, the resulting\nresiduals are often not appropriately distributed as well.This may occur\nfor a number of reasons. The outcome may not actually be continuous\n(e.g. counts. proportions) or may be related to the predictors in\ndifferent ways (e.g., logarithmic). When this occurs, several options\nexist.\n\n<details>\n\n<summary>What's linear anyway?</summary>\n\nTo be clear, the linear model only focuses on the linear and additive\nrelationship between the predictors and the outcome variable (this will\nbecome more important/obvious later in this section!). The model doesn't\n*know* what the variables are. For that reason, we can add predictor\nvariables to a model that are squares or cubes of predictors, or we can\ntransform the outcome variable. We just the $Y = X\\beta$ relationship to\nbe additive and linear.\n\n</details>\n\n### Transform the data (least advisable, sometimes)\n\nOne option is to transform the data (typically focusing on the dependent\nvariable) so that the resulting variable meets the linear model\nassumptions (and thus uses the strengths of linear models that we noted\nabove). As shown above, our rank-based approaches are using a similar\nmethod (not technically the same, but it works for larger sample sizes).\nThis approach was often used in the past(e.g., arc-sin transforms of\nproportion data @warton2010) and supported by various approacheac. For\nexample, Box-Cox transformation helped researchers find the best way to\ntransform data to reduce issues with the distribution of residuals; this\nmethod also tended to impact linearity and differences in variances.\n\nTwo things should be noted regarding this approach and transformations\nin general:\n\n-   The Box-Cox approach requires a model - it still focused on\n    transforming data so that *residuals* met assumptions. Data should\n    not be transformed before model assumptions are analyzed to ensure\n    it is necessary. For example, highly skewed data may arise due to\n    unequal sample sizes (which may pose their own problems, but not\n    outright). Non-normal data, however, may have normalized residuals.\n    However, normal data (or transformed data) does typically lead to\n    normal residuals, so if residuals are not normal transformations may\n    help.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(8)\nexample_skewed <- data.frame(Population= c(rep(\"a\",40),\n                                           rep(\"b\", 30),\n                                           rep(letters[3:4], each=15)), \n                             Growth = c(rnorm(40,1),\n                                    rnorm(30, 4),\n                                    rnorm(15, 7),\n                                    rnorm(15,10)))\nlibrary(ggplot2)\nggplot(example_skewed,aes(x=Growth))+\n  geom_histogram()+\n  labs(y=\"Some value\",\n       title=\"Example of skewed data appearing due to unequal sample size\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(lm(Growth~Population, example_skewed))\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-4.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-4-5.png){width=672}\n:::\n\n```{.r .cell-code}\nAnova(lm(Growth~Population, example_skewed), type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: Growth\n             Sum Sq Df F value    Pr(>F)    \n(Intercept)   38.75  1  32.436 1.344e-07 ***\nPopulation  1007.71  3 281.175 < 2.2e-16 ***\nResiduals    114.69 96                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n-   The transformed variable is *now* linear in respect to the\n    predictors. This highlights the actual assumption of the model.\n    Similarly, higher-terms (squares, cubes, etc) may be added to a\n    linear model. The model does not care what the data represent - it\n    only focuses on if linear relationships exist among them.\n\n-   Transformations can make model interpretation and prediction\n    difficult.\n\nIf the decision is made to transform the data, several approaches exist.\nSome are driven by the distribution of the data, and all depend on it.\nFor example, log and related root transformations are useful for\nright-skewed data, but some can only be carried out for non-negative\n(e.g., square root) or strictly positive (e.g., log) values. To address\nthis for log transformations, a small value is often added to 0\nmeasurements.\n\nLet's data (not residuals) to show what different types of data look\nlike and consider possible fixes (always fit a model first for real\nanalysis!). For example, we can return to our right-skewed blue jay data\n[from the summarizing data\nchapter](summarizing_data.qmd)(target=\"\\_blank)(idea from [@hunt]) .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nblue_jays <- round(rbeta(10000,2,8)*100+runif(10000,60,80),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nNote the right-skewed data shows a convex curve on the Q-Q plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(blue_jays)\nqqline(blue_jays)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nTo help you understand Q-Q plots, remember they are comparing the\nrelative spread of data (quantiles) from a target and theoretical\ndistribution. For right-skewed data, points are shifted right (both\nsmallest and largest observations are larger than you would expect from\na normal distribution).\n\nConversely, we could also return to our left-skewed cardinal data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\ncardinals <- round(rbeta(10000,10,2)*50+runif(10000,5,10),3)\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nand note a concave shape is seen in the Q-Q plot,as all points are\nshifted left.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(cardinals)\nqqline(cardinals)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n\nFor this type of data, power transformations (raising the variable to\nthe 2, 3, or higher power) may be useful.\n\nMeanwhile, our uniformly-distributed distributed robin data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nrochester <- round(c(runif(1000,75,85)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nshows as a s-shape on the Q-Q plot\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(rochester)\nqqline(rochester)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nbecause it is *under-dispersed* (has no tails). Alternatively, data may\nbe *over-dispersed*, like this (fake) finch data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nlibrary(VGAM)\nfinch <- rlaplace(1000,location=50, scale=4)\nggplot(data.frame(finch), \n       aes(x=finch)) +\n  geom_histogram( fill=\"cyan\", color=\"black\") +\n  labs(title=\"Weight of finches\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(finch)\nqqline(finch)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nOver- and under-dispersed data may mean there's a missing factor in your\nanalysis. For example, our bi-modal woodpecker data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(19)\nwoodpeckers <- round(c(rnorm(100,60,4),rnorm(100,80,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nis under-dispersed due the shape of the distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqqnorm(woodpeckers)\nqqline(woodpeckers)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nUnder-dispersion could also happen if data are bounded (e.g., by\npracticality or due to a measurement issue). Over-dispersion can\nsimilarly occur if the model does not account for variability (e.g.,\nmissing factors, non-linear relationship) and/or outliers, which might\nbe related to the underlying form of the data [@payne2017] (more to come\non this). In this way, over- and under-dispersion relate to both the\nlinear relationship.\n\n#### Generalized linear model approach: Different data, different approach\n\nThe linear relationship may be inappropriate because our data doesn't\nfit it! For example, if we are modeling proportions, estimates less than\n0 or below 1 do not make sense, but a linear model doesn't account for\nthat. The same issues arise for proportions and binary outcomes. While\nwe may be able to transform the response variable to make it linear,\nanother option is to translate the *link* function.\n\nAlthough we haven't fully explained it yet, a linear model contains\nthree components. There is always a random component that focuses on the\ndistribution of the data. There is also a systematic component, where a\nnumber of covariates and data points produce an estimate. Finally, there\nis the link function, which connects that estimate to the data\ndistribution (this maintains the linearity of the model).\n\nNotice this means the link connects to the distribution of the data, not\nthe data itself. So far we have focused on the *mean* of the data, and\nthe estimate is the mean, so the link has been implied. We can\n*generalize* this setup to include other distributions in the\nexponential family (and now others [@applied2022, ch. 15]).\n\nWhile we won't develop all the math, exponential family distributions\nall have a canonical parameter (the mean for Gaussian, or normal, data)\nand a dispersion parameter (the variance for normal data). Different\ndistributions have different relationships between these two parameters.\nFor normal data, there is *no* relationship, so the variance is\nconstant. This is not true for other families.\n\nWe can specify other families using *generalized linear models*(which\nare different than general linear models, which is another term used to\ndescribe our \"regular\" linear models). These models are also known as\nglm or glim (we'll use the glm jargon here). GLM make different\nassumptions (though everyone does not agree on what they are!). While we\nstill need independence of the residuals (or some extension, see below),\nthey no longer need to be normally distributed [@zuur2007, p. 86-87;\n@zuur2009, section 9.8.3] (though normality may hold at large sample\nsizes for Pearson [@agresti2007, p. 87] or deviance [@montgomery2012,\nsection 13.4.4]\n<!-- https://stats.stackexchange.com/questions/92394/checking-residuals-for-normality-in-generalised-linear-models; https://online.stat.psu.edu/stat504/lesson/6/6.1 -->\nresiduals, and some authors argue normality is required for testing\n[@feng2020] ) or constant (homogeneity). As noted above, non-Gaussian\nfamilies don't assume a constant variance, so homogeneity assumptions\nwould not be appropriate. However, we need to ensure the correct family\n(and thus mean-variance link) is chosen. In general, plotting the\nresiduals against\n\n-   the predicted values\n\n-   each explanatory variable in model\n\n<!-- -->\n\n-   each explanatory not retained/used in model\n\n-   against time and space\n\nwill be useful. Any patterns may suggest missing predictors or lack of\nindependence/correlation among measurements. Patterns in the residuals\nmay also indicate the incorrect family has been chosen [@zuur2009,\nsection 9.8.4]\n\n<details>\n\n<summary>What are residuals for a GLM?</summary>\n\nResiduals for a Gaussian/normal glm (what we've been doing) are easy to\ncalculate. We simply subtract the estimate for each data point (which is\nthe average for similar observations!) from the observed. However,\nthough these raw or response residuals exist for GLM, they rarely make\nsense. Variance may increase with mean for some distributions, for\nexample, or outcomes may be binary.\n\nTo account for this, we could divide the residuals by the square root of\nthe variance. This normalizes the residuals and leads to *Pearson\nresiduals*. Another option is based on something called deviance.\nDeviance is similar to sums of squares but based on likelihood (which we\nshortly see is what we use to test for significance in GLM); it can also\nbe considered the generalized form of variance or residuals sums of\nsquares. It is calculated as the difference of log-likelihods between\nthe focal model and the saturated model. Deviance residuals consider how\nimportant each point is to the overall deviance. You can also compare\nthe deviance of a model to a perfect fit (no deviance/saturated) model\nand an intercept-only model (worst fit, D~O~) and generate a pseudo-R^2^\nmeasure using the formula\n\n$$\n1-\\frac{D}{D_O}\n$$\n\n</details>\n\nThere are numerous types of GLMs. Here we outline some of the more\ncommon ones. Regardless of which ones you use, moving beyond the normal\ndistribution means the residuals do not need to be normally or\nidentically distributed\n\n##### Logistic regression\n\nLogistic regression focused on yes/no outcomes; data can be a single\nanswer (Bernoulli) or a collection (binomial).\n\n##### Beta regression\n\nBeta regression focuses on true porpiton data.\n\n##### Poisson regression\n\nPoisson regression focuses on count-based data.\n\n##### Non-linear options\n\n## Data are not independent\n\n### In respect to predictors\n\nA major issue for linear models is when predictors are co-linear.\nMathematically speaking, perfect collinearity occurs when any column of\nthe design (*X*) matrix can be derived by combining other columns.\nPerfect collinearity will lead to a message noting singularity issues,\nwhich is R's way of telling you the matrix isn't invertible (which it\nhas to be to solve the equation).\n\nEven partial collinearity will lead to an increase in Type II errors\n[@zuur2010]. To put it simply, partitioning variance among related\npredictors is hard. For this reason, a few approaches may be used.\n\n#### Check for issues\n\nThe first step is identifying issues. From the outset, relationships\namong predictor variables can be assessed using the *pairs* function in\nR. If two variables are highly correlated (r^2^ \\> .8 is a general\nlimit), only one should be included in the model. Similarly, variance\ninflation factors (vif) can be assessed for the final and other models\nto consider this issues (all this is covered in the [previous chapter\nthat introduces multiple\nregression](Combining_numerical_and_categorical_predictors.qmd){target=\"_blank\"}.\n\n### In respect to measured outcomes\n\nWhen outcome variables are linked together, a few options exist. Note\nthis issue may be obvious from checks of assumptions, but it also may be\ndue to experimental design.\n\nConsider this example. In order to investigate impacts of climate stress\non oysters, specimens are placed in individual tanks and held at normal\nsummer (calculated using recent data) temperature or at temperatures\npredicted under 2 IPCC --- Intergovernmental Panel on Climate Change-\nscenarios. Oysters were also exposed to predator cues by dropping in\nwater from tanks with 0, low (.25/m2), or high (2/m2) predators. After\ntwo months changes in oyster shell length (growth) was measured.\nTwenty-five oysters were measured for each treatment combination.\n\nYou hopefully recognize this as a factorial ANOVA experiment that you\nknow how to analyze. If you need a reminder, see the [chapter on ANOVA\nextensions](../chapters/More_ANOVAs.qmd){target=\"_blank\"}. Experiments\nlike this are odd, however, given the space they require. It is far more\ncommon to put lots of organisms in a single container given space and\ncosts. However, this means our measurements are connected; remember\n[blocking and paired\ntests](../chapters/More_ANOVAs.qmd){target=\"_blank\"})?\n\nThere are several ways to deal with this. Here we explore each for our\noyster example.\n\n\n::: {.cell}\n\n:::\n\n\n#### Ignore it (don't do this!)\n\nFirst, let's ignore the lack of independence. This is *not* an option,\nbut it let's you see the impact.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngrowth_lm <- lm(growth~predator_cue*temperature, experiment)\nplot(growth_lm)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-16-2.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-16-3.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-16-4.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(car)\nAnova(growth_lm, type=\"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnova Table (Type III tests)\n\nResponse: growth\n                          Sum Sq  Df F value    Pr(>F)    \n(Intercept)               15.576   1 16.3673 7.265e-05 ***\npredator_cue              22.085   2 11.6031 1.635e-05 ***\ntemperature               70.061   2 36.8090 1.753e-14 ***\npredator_cue:temperature  21.376   4  5.6154 0.0002558 ***\nResiduals                205.563 216                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\nWe find significant main effects and interactions using this *wrong*\napproach.\n\n#### Find average for each unit\n\nOne way of doing this focuses on the average for each unit\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Rmisc)\naveraged_experiment <- summarySE(experiment, measurevar = \"growth\",\n                             groupvars = c(\"predator_cue\", \"temperature\", \"container\"))\nlibrary(rmarkdown)\npaged_table(averaged_experiment)\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"predator_cue\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"temperature\"],\"name\":[2],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"container\"],\"name\":[3],\"type\":[\"chr\"],\"align\":[\"left\"]},{\"label\":[\"N\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"growth\"],\"name\":[5],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"sd\"],\"name\":[6],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"se\"],\"name\":[7],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"ci\"],\"name\":[8],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"high\",\"2\":\"ambient\",\"3\":\"c\",\"4\":\"25\",\"5\":\"0.7893411\",\"6\":\"0.7859693\",\"7\":\"0.1571939\",\"8\":\"0.3244322\"},{\"1\":\"high\",\"2\":\"elevated_scenario1\",\"3\":\"f\",\"4\":\"25\",\"5\":\"0.8200710\",\"6\":\"0.6938491\",\"7\":\"0.1387698\",\"8\":\"0.2864068\"},{\"1\":\"high\",\"2\":\"elevated_scenario2\",\"3\":\"i\",\"4\":\"25\",\"5\":\"2.8548160\",\"6\":\"1.0748246\",\"7\":\"0.2149649\",\"8\":\"0.4436658\"},{\"1\":\"none\",\"2\":\"ambient\",\"3\":\"a\",\"4\":\"25\",\"5\":\"2.0791580\",\"6\":\"0.7758511\",\"7\":\"0.1551702\",\"8\":\"0.3202556\"},{\"1\":\"none\",\"2\":\"elevated_scenario1\",\"3\":\"d\",\"4\":\"25\",\"5\":\"2.5724463\",\"6\":\"1.0918574\",\"7\":\"0.2183715\",\"8\":\"0.4506966\"},{\"1\":\"none\",\"2\":\"elevated_scenario2\",\"3\":\"g\",\"4\":\"25\",\"5\":\"2.9199695\",\"6\":\"1.1043899\",\"7\":\"0.2208780\",\"8\":\"0.4558697\"},{\"1\":\"normal\",\"2\":\"ambient\",\"3\":\"b\",\"4\":\"25\",\"5\":\"1.7124232\",\"6\":\"1.1511870\",\"7\":\"0.2302374\",\"8\":\"0.4751867\"},{\"1\":\"normal\",\"2\":\"elevated_scenario1\",\"3\":\"e\",\"4\":\"25\",\"5\":\"1.4993876\",\"6\":\"0.9759186\",\"7\":\"0.1951837\",\"8\":\"0.4028394\"},{\"1\":\"normal\",\"2\":\"elevated_scenario2\",\"3\":\"h\",\"4\":\"25\",\"5\":\"3.1388696\",\"6\":\"1.0096012\",\"7\":\"0.2019202\",\"8\":\"0.4167429\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nand use that for your analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\naverage_analysis <- lm(growth~predator_cue*temperature, averaged_experiment)\nAnova(average_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in Anova.lm(average_analysis, type = \"III\"): residual df = 0\n```\n:::\n:::\n\n\nbut that leads to an issue! Since we only get 9 average outcomes and our\nmodel requires 10 degrees of freedom (consider why), we are left with no\n\"noise\" to make the denominator for our F ratio! Even when this doesn't\nhappen, you have reduced your data to a much smaller number of points\nand are not getting credit for all your work! This is a good example of\nwhy you should analyze simulated data before you run an experiment, but\nthere are other options.\n\n#####Blocking\n\nThe blocking approach we've already covered works might seem appropriate\nhere.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nblocking_analysis <- lm(growth~predator_cue*temperature+container, experiment)\nAnova(blocking_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-error}\n```\nError in Anova.III.lm(mod, error, singular.ok = singular.ok, ...): there are aliased coefficients in the model\n```\n:::\n:::\n\n\nbut its not? Why? This error means now our model matrix has collinearity\nissues. WE can actually see where\n\n\n::: {.cell}\n\n```{.r .cell-code}\nalias(blocking_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel :\ngrowth ~ predator_cue * temperature + container\n\nComplete :\n                                                 (Intercept) predator_cuenone\ncontainerf                                        0           0              \ncontainerg                                       -1           1              \ncontainerh                                        0           0              \ncontaineri                                        1          -1              \npredator_cuenone:temperatureelevated_scenario1    0           0              \npredator_cuenormal:temperatureelevated_scenario1  0           0              \npredator_cuenone:temperatureelevated_scenario2   -1           1              \npredator_cuenormal:temperatureelevated_scenario2  0           0              \n                                                 predator_cuenormal\ncontainerf                                        0                \ncontainerg                                        0                \ncontainerh                                        1                \ncontaineri                                       -1                \npredator_cuenone:temperatureelevated_scenario1    0                \npredator_cuenormal:temperatureelevated_scenario1  0                \npredator_cuenone:temperatureelevated_scenario2    0                \npredator_cuenormal:temperatureelevated_scenario2  1                \n                                                 temperatureelevated_scenario1\ncontainerf                                        1                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                       -1                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 temperatureelevated_scenario2\ncontainerf                                        0                           \ncontainerg                                        1                           \ncontainerh                                        0                           \ncontaineri                                        0                           \npredator_cuenone:temperatureelevated_scenario1    0                           \npredator_cuenormal:temperatureelevated_scenario1  0                           \npredator_cuenone:temperatureelevated_scenario2    1                           \npredator_cuenormal:temperatureelevated_scenario2  0                           \n                                                 containerb containerc\ncontainerf                                        0          0        \ncontainerg                                        1          1        \ncontainerh                                       -1          0        \ncontaineri                                        0         -1        \npredator_cuenone:temperatureelevated_scenario1    0          0        \npredator_cuenormal:temperatureelevated_scenario1  0          0        \npredator_cuenone:temperatureelevated_scenario2    1          1        \npredator_cuenormal:temperatureelevated_scenario2 -1          0        \n                                                 containerd containere\ncontainerf                                       -1         -1        \ncontainerg                                       -1          0        \ncontainerh                                        0         -1        \ncontaineri                                        1          1        \npredator_cuenone:temperatureelevated_scenario1    1          0        \npredator_cuenormal:temperatureelevated_scenario1  0          1        \npredator_cuenone:temperatureelevated_scenario2   -1          0        \npredator_cuenormal:temperatureelevated_scenario2  0         -1        \n```\n:::\n:::\n\n\nthough the output is confusing. In general, the issue here is each unit\nonly contributes to one level of other traits..so if we know the average\nimpact of ambient temperatures, for example, and the impacts in two of\nthe treatments that were held at that temperature, we can predict the\nother. If instead each unit contributed to multiple levels, like in\n[feather experiment](../chapters/More_ANOVAs.qmd){target=\"blank\"}) this\nisn't an issue.\n\n#### Random effects\n\nOur final option takes a new approach. It considers the units we\nmeasured as simply a sample from a larger population. Using that\nbackground, we use the information from the units to consider the\ndistribution of sample effects we might see. The impact of unit is then\nconsidered a random-effect. For this to work, you probably want 5+\nlevels of the unit variable. This is because we are using the means to\nestimate variance (confusing?). For factors with \\<5 levels, random\neffects likely offer no benefit [@gomes2022].\n\nWhen models contain fixed (what we've done before) and random effects,\nwe call them mixed-effects models. Two common packages for carrying out\nthis analysis in R are the **nlme** and **lme4** packages. We will focus\non the lme4 package here. Random effects can be entered in the *lmer*\n(linear mixed-effects regression) function and specified as (1\\|Grouping\nUnit). One nice thing about **lme4** is it will handle crossed and\nrandom effects on it's own **as long as you don't repeat unit names**.\nFor example, we could note\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nmixed_analysis <- lmer(growth~predator_cue*temperature+(1|container), experiment)\n```\n:::\n\n\nOnce built, we need to consider assumptions. The main assumption we add\nhere is that the random effects are normally distributed. This should be\nchecked at each level of grouping. The *check_mixed_model* function\n(provided below) offers an automated approach for one level (also known\nas one-way random effects).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_mixed_model <- function (model, model_name = NULL) {\n  #collection of things you might check for mixed model\n  par(mfrow = c(2,3))\n  if(length(names(ranef(model))<2)){\n    qqnorm(ranef(model, drop = T)[[1]], pch = 19, las = 1, cex = 1.4, main= paste(model_name, \n                                                                                  \"\\n Random effects Q-Q plot\"))\n    qqline(ranef(model, drop = T)[[1]])\n  }\n  plot(fitted(model),residuals(model), main = paste(model_name, \n                                                    \"\\n residuals vs fitted\"))\n  qqnorm(residuals(model), main =paste(model_name, \n                                       \"\\nresiduals q-q plot\"))\n  qqline(residuals(model))\n  hist(residuals(model), main = paste(model_name, \n                                      \"\\nresidual histogram\"))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_mixed_model(mixed_analysis)\n```\n\n::: {.cell-output-display}\n![](Linear_model_extensions_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\nHere we have only 9 levels of units, so the spread is not perfect.\nHowever, we also know each of these is itself an average,and averages\nshould be normally-distributed under the central limith theorem, so we\ncan plow ahead.\n\nWe can consider the outcome using our *summary* command - note the\noutput denotes we have 225 observations and 9 grouping levels.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mixed_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: growth ~ predator_cue * temperature + (1 | container)\n   Data: experiment\n\nREML criterion at convergence: 631.3\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-2.68605 -0.79915 -0.02646  0.70023  2.72393 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n container (Intercept) 4.6171   2.1487  \n Residual              0.9517   0.9755  \nNumber of obs: 225, groups:  container, 9\n\nFixed effects:\n                                                 Estimate Std. Error t value\n(Intercept)                                       0.78934    2.15758   0.366\npredator_cuenone                                  1.28982    3.05129   0.423\npredator_cuenormal                                0.92308    3.05129   0.303\ntemperatureelevated_scenario1                     0.03073    3.05129   0.010\ntemperatureelevated_scenario2                     2.06547    3.05129   0.677\npredator_cuenone:temperatureelevated_scenario1    0.46256    4.31517   0.107\npredator_cuenormal:temperatureelevated_scenario1 -0.24377    4.31517  -0.056\npredator_cuenone:temperatureelevated_scenario2   -1.22466    4.31517  -0.284\npredator_cuenormal:temperatureelevated_scenario2 -0.63903    4.31517  -0.148\n\nCorrelation of Fixed Effects:\n             (Intr) prdtr_cnn prdtr_cnr tmpr_1 tmpr_2 prdtr_cnn:_1 prdtr_cnr:_1\npredatr_cnn  -0.707                                                            \nprdtr_cnrml  -0.707  0.500                                                     \ntmprtrlvt_1  -0.707  0.500     0.500                                           \ntmprtrlvt_2  -0.707  0.500     0.500     0.500                                 \nprdtr_cnn:_1  0.500 -0.707    -0.354    -0.707 -0.354                          \nprdtr_cnr:_1  0.500 -0.354    -0.707    -0.707 -0.354  0.500                   \nprdtr_cnn:_2  0.500 -0.707    -0.354    -0.354 -0.707  0.500        0.250      \nprdtr_cnr:_2  0.500 -0.354    -0.707    -0.354 -0.707  0.250        0.500      \n             prdtr_cnn:_2\npredatr_cnn              \nprdtr_cnrml              \ntmprtrlvt_1              \ntmprtrlvt_2              \nprdtr_cnn:_1             \nprdtr_cnr:_1             \nprdtr_cnn:_2             \nprdtr_cnr:_2  0.500      \n```\n:::\n:::\n\n\nWe can also still use *Anova* to get p-values. However, these are now\ncalculated by default using likelihood-associated $\\chi^2$ tests.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mixed_analysis, type = \"III\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald chisquare tests)\n\nResponse: growth\n                          Chisq Df Pr(>Chisq)\n(Intercept)              0.1338  1     0.7145\npredator_cue             0.1898  2     0.9095\ntemperature              0.6020  2     0.7401\npredator_cue:temperature 0.1837  4     0.9960\n```\n:::\n:::\n\n\nYou can also ask for F tests, but note the degrees of freedom associated\nwith these tests is not clear. It's somewhere between the \"average\" and\n\"ignore\" approach used above.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAnova(mixed_analysis, type = \"III\", test=\"F\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type III Wald F tests with Kenward-Roger df)\n\nResponse: growth\n                              F Df  Df.res Pr(>F)\n(Intercept)              0.1338  1 3230137 0.7145\npredator_cue             0.0949  2 3230137 0.9095\ntemperature              0.3010  2 3230137 0.7401\npredator_cue:temperature 0.0459  4 3230137 0.9960\n```\n:::\n:::\n\n\nNote this approach suggests we do not have enough data to reject the\nnull hypothesis. Ignoring the linkages among data led to *very*\ndifferent results. This issue (pseudopreplication) has been noted in\necology and other fields [@hurlbert1984; @heffner1996; @lazic2010].\n\n## Errors are not equal among groups\n\nAnother option is to use weighted-least squares regression - this\napproach specifically helps when residuals are not evenly distributed\namong groups. For example, we could take the sdm_model (just as an\nexample of use! it's not needed here!) This approach assume you built\nthe model and then noted an issue with heteroscedasticity. If so, we can\ncalculate a weight for each residual that is based on its variance -\nbelow makes a value that increases with low variance.\n\n`{r} wt_sdm <- 1 / lm(abs(sdm_model$residuals) ~ sdm_model$fitted.values)$fitted.values^2}`\n\nWe can then add a new argument to the *lm* function to use these\nweights.\n\n`{r} sdm_model_wls <-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], weights = wt_sdm)}`\n\nWe can then continue on our normal route:\n\n`{r} plot(sdm_model_wls) Anova(sdm_model_wls, type=\"III\")}`\n\nIf you compare the two models you notice slight differences - these are\nminimal here due to lack of differences in variance.\n\n`{r} summary(sdm_model) summary(sdm_model_wls)}`\n\nWhy not just always do this? Because weighted least squares implicitly\nassumes we *know* the weights. We are actually estimating them, so small\ndatasets may lead to bad estimates and outcomes.\n\n## Residuals are not normally distributed\n\nA very common concern regarding linear models is normality. I list it\nfirst here due to how often I see it noted, but in fact this assumption\nis one of the least important (and the assumption is based on residuals,\nnot data!). However, non-normal residuals are often (not always)\nconnected to other issues, namely linearity, as noted above.\n\n## Combinining these\n\n## Next steps\n\nThese methods can be extended to other models that are used when linear\nmodel assumptions are not met, which is the focus of the next chapter.\n",
    "supporting": [
      "Linear_model_extensions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\r\n<script src=\"../../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}